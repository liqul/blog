<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Liqun&#39;s Homepage</title>
  
  <subtitle>A place for knowledge</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="liqul.github.io/blog/"/>
  <updated>2018-12-01T02:11:51.057Z</updated>
  <id>liqul.github.io/blog/</id>
  
  <author>
    <name>Liqun Li</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>新闻纪录</title>
    <link href="liqul.github.io/blog/news/"/>
    <id>liqul.github.io/blog/news/</id>
    <published>2018-11-28T16:00:00.000Z</published>
    <updated>2018-12-01T02:11:51.057Z</updated>
    
    <content type="html"><![CDATA[<p>每天读新闻，学习思考一些基本的经济逻辑。</p><a id="more"></a><h3><span id="2018-11-29">2018-11-29</span></h3><blockquote><p>【亚股高开 日经涨0.8% 追随隔夜美股涨势】日股日经225指数开盘涨0.8%，至22,360.98点。日股东证指数开盘涨0.8%，至1,667.16点。 韩国首尔综指涨1.2%。 鲍威尔鸽派言论推动美股上涨，标普500指数涨2.3%创八个月最大涨幅，道指涨2.5%，纳指涨近3%。美联储主席鲍威尔称联储基准利率已接近中性水平，暗示未来加息次数可能较少。 （来自新浪财经APP）</p></blockquote><p>一字千金~如果加息开始变慢，那么根据以往经验倒计时半年，也就是2019年中可能会出现更大的波动。这是近距离观察一次债务周期的良机。</p><blockquote><p>【海通姜超：明年中国货币政策大概率将实际宽松 债牛料持续】海通证券固收分析师姜超等报告称，国内通胀下行、融资需求低增，为防止经济衰退，货币政策仍将宽松，利率债牛市仍将持续。2019年经济下行压力依然很大，预判实际GDP中枢将下降至6%。未来不排除降准、定向降息、下调OMO利率等，打开短端利率下行空间，届时收益率曲线有望平坦化下行。 （来自新浪财经APP）</p></blockquote><p>各种刺激就看有没有效果了。在经济大周期下，所有刺激也只是让经济不要过于“硬着陆”。</p><blockquote><p>【短期美债收益率大跌，美债收益率曲线在鲍威尔讲话偏各派之际趋于陡峭】周三（11月28日）纽约尾盘，美国10年期基准国债收益率上涨0.18个基点，报3.0590%；10月9日曾涨至3.2594%，为2011年5月4日以来盘中最高位，当年最高位在2月9日——3.7660%。两年期美债收益率跌2.43个基点，报2.8086%，盘中交投于2.8410%-2.7945%区间；11月8日曾涨至2.9732%——逼近2008年6月25日最高位2.9966%，当年最高位在6月13日——3.1140%。 （来自新浪财经APP）</p></blockquote><p>这里的逻辑关系我仍然看不明白。10年国债收益上涨（价格下跌），而两年国债收益下跌（价格上涨），似乎隐含着一部分人将原本长期不动的钱准备进行短期投资，进而意味着短期的资产行情可能会上扬。但这仍然是一个不明确的信号，还需要等待G20的新消息。</p><h3><span id="2018-11-28">2018-11-28</span></h3><blockquote><p>【宝宝类理财平均收益率2.86% 再创年内新低】据融360监测的数据显示，昨日，473只银行理财在线产品的平均预期年化收益率为4.45%，而72只宝宝理财产品平均预期年化收益率为2.86%。同时，上周（11月16日至11月22日）互联网宝宝理财产品收益率为2.86%，较前一周下降0.03个百分点，再创年内新低。（证券日报） （来自新浪财经APP）</p></blockquote><p>相比银行利率这种被政治垄断的指标，宝宝类的收益更加接近市场化，这是观察经济的一项好指标。</p><blockquote><p>房企借道信托紧急“输血” 4天签约规模400亿元】近日，包括泰禾集团、福晟集团、正荣地产在内的三家房企分别与信托公司签署战略合作协议，合作规模总计达400亿元。记者注意到，近期房企再融资利率水涨船高，最高年化利率接近14%。天风证券研报指出，若新房销售市场2019年持续低迷，则房企资金面或将面临三期叠加：占到位资金接近一半的销售回款2019年或将开始下滑；2019年上半年仍是债券到期高峰，房企借新还旧压力较大；同时，2019年也是非标到期高峰。（每日经济新闻） （来自新浪财经APP）</p></blockquote><p>地产如果出现风险，这些信托也是要跟着完蛋的。</p><h3><span id="2018-11-26">2018-11-26</span></h3><blockquote><p>【中金：如政策面不果断调整 不排除2019上半年M1负增长】中金发布报告称，目前中国名义增长和企业盈利面临进一步下行的压力，如果政策面不果断调整（尤其是财政和地产相关政策），不能排除2019上半年M1（狭义货币供应量）增速转负的可能。中金宏观团队在名为《M1增长是否会转负？》的最新报告指出，鉴于地产需求、投资以及企业盈利的领先指标均在走弱，M1增长可能继续承压。中金预计2019年商品房销售额同比下降10%、土地购置费同比下降15%。 （来自新浪财经APP）</p></blockquote><p>通缩压力增加，这对2019年的资产价格可不是好消息。</p><h3><span id="2018-11-17">2018-11-17</span></h3><blockquote><p>美国9月长期资本净流入 +308亿美元，前值 1318亿美元。美国9月国际资本净流入 -291亿美元，前值 1082亿美元。中国9月所持美国国债减少137亿美元，至1.15万亿美元，创逾一年新低。日本9月所持美债下降19亿美元，至1.03万亿美元。 （来自新浪财经APP）</p></blockquote><p>中国需要这笔钱来平衡汇率吧。</p><blockquote><p>【部分国家豁免于伊朗制裁抑制油价 致美沙关系紧张】据华尔街日报报道，美国对8个国家和地区豁免了伊朗制裁，一定量的伊朗油进入市场正在打压油价。这导致了沙特与华盛顿发生冲突，因沙特迫切需要减产来推升油价升至80美元/桶以上来支撑其经济。美国担忧部分国家被要求削减得更多而产生抱怨，因此与豁免国家就豁免产量保密，导致欧佩克难以估算产量。沙特官员表示，特朗普政府对制裁缺乏坦率，他们感到了背叛，并将制定更加独立于美国目标的石油政策。 （来自新浪财经APP）</p></blockquote><blockquote><p>美国中情局（CIA）得出结论：沙特王储Bin Salman下令刺杀记者Khashoggi。（华盛顿邮报） （来自新浪财经APP）</p></blockquote><blockquote><p>美国国务院发言人Nauert：关于特朗普政府已经在记者Khashoggi遇害案上得出最终结论的报道失实。在记者Khashoggi死亡事件上仍然存在没有解开的疑团。美国政府将继续征求国会山的意见。美方将继续探求真相，并维持与沙特之间重要的战略关系。 （来自新浪财经APP）</p></blockquote><p>美国与沙特之间的关系很有趣。原本沙特会与俄罗斯联手太高油价，但Khashoggi事件使得沙特不敢过于傲娇，还得乖乖听美国的话，大家一块提高产能压油价。这时候俄罗斯显然不会独自减产，因为如果这样会导致市场占有率下降。</p><p>另一方面，CIA的结论显然没有经过特朗普的同意，这也反映了美国政府内部的分裂。</p><blockquote><p>【杭州房贷利率全面松动，首套房、二套房均包括】二手房成交惨淡，新房排队摇号盛况不再，在刚刚过去的&gt;“金九银十”，杭州市场的传统旺季行情并未如期上演。楼市降温的同时，房贷利率也出现了松动。据了解，10月底，工商银行、中国银行部分支行率先下调房贷利率；最近，建设银行、农业银行、招商银行、汇丰银行等也相继回调。这不仅是针对刚需购买的首套房，甚至还包括二套房。（都市快报） （来自新浪财经APP）</p></blockquote><p>这可是个值得关注的信号。如果房市再次上行，那么加杠杆的时间就到了。</p><h3><span id="2018-11-15">2018-11-15</span></h3><blockquote><p>【英国首相May声明：脱欧协议获得内阁支持】英国首相May发布声明称，内阁进行了充满激情的讨论。这份脱欧协议获得内阁的支持，内阁认为政府应当同意这份脱欧协议。这些决定并非掉以轻心。将坚定不移地捍卫不列颠的利益。最新进展将有助于我们在脱欧问题上继续前行。我知道，未来还会出现艰难的处境。预计英国脱欧会面临严格的审查，这是正确的做法。 （来自新浪财经APP）</p></blockquote><p>英国感觉仍然是200年前的那个英国，但这个世界已经是200年后的世界了。脱欧的英国应该不会再加入了，而欧盟的未来也有一些不确定因素。民粹主义思潮还会持续一段时间吧，而仅靠法德支撑的欧盟也不免有些摇摇欲坠。最近，默克尔下台了。</p><blockquote><p>【美联储主席鲍威尔：缩减资产负债表进展“非常好 ”】美联储主席鲍威尔在达拉斯联储举行的活动上发表讲话称，对经济状况感到非常满意；通货膨胀正中目标；挑战包括进一步加息的幅度和步伐；目标是维持经济增长的同时保持低通胀；努力避免加息太慢或太快；认真对待这两种风险因而逐步提高利率；有关中性利率的讨论旨在突出风险管理。 （来自新浪财经APP）</p></blockquote><p>石油价格的下跌进一步抑制了通胀，而美联储越来越找不到理由加息了。</p><blockquote><p>【外汇局：10月银行结售汇逆差203亿元人民币】国家外汇管理局15日披露统计数据显示，2018年10月，银行结汇10751亿元人民币（等值1552亿美元），售汇10953亿元人民币（等值1581亿美元），结售汇逆差203亿元人民币（等值29亿美元）。其中，银行代客结汇9862亿元人民币，售汇10103亿元人民币，结售汇逆差241亿元人民币；银行自身结汇888亿元人民币，售汇850亿元人民币，结售汇顺差38亿元人民币。 （来自新浪财经APP）</p></blockquote><p>用钱投票的是真选择。</p><h3><span id="2018-11-13">2018-11-13</span></h3><blockquote><p>【10月金融数据3个创出新低 降息降准等更多措施可期】10月社会融资规模增量、广义货币（M2）、狭义货币（M1）3个金融数据均创出不同期限新低。数据公布后，债市应声上涨，利率债收益率下行幅度立即扩大。市场普遍认为，考虑到当前错综复杂的内外部形势，未来降准降息都有空间。海通证券分析师姜超认为，货币宽松预期增强，降准等政策仍有很大操作空间。（券商中国） （来自新浪财经APP）</p></blockquote><p>货币一直是宽松的，只是有些地方虽然紧但却仍然流不进去，比如民营企业。这是制度上的根本原因决定的。</p><blockquote><p>布伦特原油日内跌幅达2%，报68.72美元/桶；WTI跌幅也扩大至2%，报58.73美元/桶。 （来自新浪财经APP）</p></blockquote><p>石油一直都不是一种普通商品。虽然贸易战使人们对未来需求的预期不高，但也还不能解释这么短时间这么大幅度的下跌。中东的局面还是错综复杂，沙特、美国、俄罗斯三方的态度决定了油价的高低。对于油价的估计对散户来说实在太难。</p><blockquote><p>中国10月M2同比增8％，预期8.4％，前值8.3％。 （来自新浪财经APP）</p></blockquote><p>连续几个月M2增长不及预期，距离通缩并不遥远了。</p><blockquote><p>中国10月新增人民币贷款 6970亿元人民币，预期 9045亿元，前值 13800亿元。中国10月社会融资规模增量 7288亿元人民币，预期 13000亿元，前值 22054亿元。 （来自新浪财经APP）</p></blockquote><p>显然不是银行没有钱，只是“找不到”理想的借款人而已。</p><blockquote><p>中国10月M1货币供应同比 2.7%，预期 4.2%，前值 4%。中国10月M0货币供应同比 2.8%，预期 2.8%，前值 2.2%。 （来自新浪财经APP）</p></blockquote><p>巨大差距。</p><h3><span id="2018-11-07">2018-11-07</span></h3><blockquote><p>【580亿！险资纾困专项产品规模创新高】继5日太平资产发起设立目标规模80亿的纾困专项产品后，昨日人保资产也设立专项产品，目标总规模达300亿。上周一，国寿资产成立保险业首只目标规模200亿的纾困专项产品。至此，保险业已有3只专项产品，目标总规模合计达到580亿元。（证券时报） （来自新浪财经APP）</p></blockquote><p>这也算是金融创新了。几百亿的规模还是比较小的，应该没有特别的影响。</p><blockquote><p>【10月境外投资者 加仓人民币债券2.53亿元】据21经济报，10月债券托管量较9月份仅仅增加2.53亿元，创下过去20个月以来的单月增加额最低值。在新兴市场策略师Timothy Ash看来，海外投资机构之所以增持人民币债券的兴趣骤降，一是中美利差持续缩水；二是人民币兑美元汇率走低导致汇率风险对冲操作成本持续增加。不过，随着人民币国际化进程与境内金融市场对外开放步伐双双加快，境外投资机构对人民币债券的投资需求并没有出现明显下降。 （来自新浪财经APP）</p></blockquote><p>中期选举临近，美元的波动性会加剧，这时候中国是一个不错的选择。但这跟国际化有啥关系呢？这些编辑真是啥都能随便联系起来。</p><blockquote><p>中国10月外汇储备 30531亿美元，预期 30585亿美元，前值 30870亿美元。中国10月外汇储备环比减少339亿美元，上月减少227亿美元。 （来自新浪财经APP）</p></blockquote><p>继续减少在将来一段时间仍然是改变不了的。</p><h3><span id="2018-11-05">2018-11-05</span></h3><blockquote><p>【外汇局：前三季度我国经常账户逆差128亿美元】外汇局公布数据显示，按美元计值，2018年三季度，我国经常账户顺差160亿美元，其中，货物贸易顺差1008亿美元，服务贸易逆差822亿美元。资本和金融账户逆差160亿美元，其中，资本账户逆差2亿美元，非储备性质的金融账户逆差188亿美元，储备资产减少30亿美元。前三季度，我国经常账户逆差128亿美元，其中，货物贸易顺差2561亿美元，服务贸易逆差2295亿美元。资本和金融账户顺差625亿美元，其中，资本账户逆差4亿美元，非储备性质的金融账户顺差1100亿美元，储备资产增加471亿美元。 （来自新浪财经APP）</p></blockquote><p>经常账户逆差将成为一个常态。货物贸易顺差越来越难弥补服务贸易逆差以及资本外逃的影响。不过随着美联储措辞上的放宽，2019年的形势变得不太明朗，对资本外逃有一定的缓解。</p><h3><span id="2018-10-26">2018-10-26</span></h3><blockquote><p>【刘元春：进一步降准应提上议事日程】中国人民大学副校长刘元春接受采访时表示，未来一段时间，我国的房地产金融风险、汇率风险、局部地区政府债务风险、流动性风险等需重点防范。刘元春建议从优化社会融资结构、提升直接融资占比、抑制政府信用和类政府信用过度膨胀等方面化解风险、提振民营企业信心。货币政策方面，建议适度提高M2增长速度，降准应提上议事日程。（中证报） （来自新浪财经APP）</p></blockquote><p>外汇储备持续下降，降准是应对之策。但汇率恐怕就要let it go了。</p><blockquote><p>【为避开美国制裁，欧盟伊朗将建立易货体系】路透报道援引3位欧盟外交官的话称，通过这个被称为“特殊目的实体(SPV)”的体系，欧洲在购买伊朗石油后可以用等价的商品和服务支付。但SPV并不能保住所有欧盟和伊朗的生意往来。欧盟外交官表示，该组织想向伊朗表明，尽管面临美国制裁，欧盟在努力保留伊核协议，但也只能以这种速度做到这么多。（环球时报） （来自新浪财经APP）</p></blockquote><p>SPV的进展是个非常值得关心的情况。</p><h3><span id="2018-10-25">2018-10-25</span></h3><blockquote><p>【美债收益率大跌，投资者在股市大跌和美国国会中期选举之前寻求避险】周三（10月24日）纽约尾盘，美国10年期基准国债收益率下跌6.41个基点，报3.1035%，美股收盘前一刻曾跌至3.0922%，为10月3日以来盘中最低位；10月9日曾涨至3.2594%，为2011年5月4日以来盘中最高位，当年最高位在2月9日——3.7660%。两年期美债收益率跌4.85个基点，报2.8305%，美股收盘前一刻曾跌至2.8224%；10月22日曾涨至2.9123%、逼近2008年6月25日最高位2.9966%，当年最高位在6月13日——3.1140%。 （来自新浪财经APP）</p></blockquote><p>美债收益大跌对股市是个很好的消息。</p><h3><span id="2018-10-24">2018-10-24</span></h3><blockquote><p>【美联储10个地区联储在9月支持上调贴现利率】美联储发布的贴现利率政策会议纪要显示，在美联储的12个地方联储中，有10家地方联储在9月份支持将贴现利率上调25个基点，至2.75%。明尼阿波利斯联储主席Kashkari反对美联储加息，倾向于将贴现利率维持在当前2.50%的水平不变。纽约联储主席（往往要等到其他地方联储都批准之后才做决定）也没有投票支持加息。许多地方联储主席报告称，美国消费者开支强劲，零售增长；部分联储主管则指出，制造业增速强劲。许多地方联储主席称薪资上涨，（企业）输入成本上升，或者这两方面都推高终端商品价格。大多数地方联储主席担忧贸易政策会影响到特定行业的活动、并更大范围地影响美国经济的增速。 （来自新浪财经APP）</p></blockquote><p>未来预料加息会逐步进行，目前美国经济并未遇到严峻的问题。</p><h3><span id="2018-10-21">2018-10-21</span></h3><blockquote><p>【广州楼市“放开”限价 刚需高首付时代结束？真相来了】根据传出来的内容，一句话概括：从广东南沙、增城、花都开始，即将取消限价；未来逐步扩大实施范围。中介、销售将其解读为价格上涨的利好。自媒体解读为政府救市，打响限价松动第一枪。随后，广州住建委紧急回应，发布《关于我市进一步规范房地产市场管理作出说明》，强调严禁开发企业拆分价格报备，并将对新建商品住房预售和网签价格指导机制进行优化。（中国基金报） （来自新浪财经APP）</p></blockquote><p>如果这是真的，那么其影响不容小觑。如果未来十年中国仍然把经济增长赌在房地产，那么将造成极其恶劣的影响。最近看到很多减税的消息，等到什么时候能开始缓慢加息，我才认为快到底了。</p><blockquote><p>【美股回调给苹果提供了重要的买入机会】 美股回调的一个很好的副作用是它们提供了买入机会，这意味着一些华尔街最大的股票出现了一些有吸引力的价格波动。苹果在2018年一直是一只耀眼的股票，自今年1月以来总回报率上涨了近32%。与标普500指数其他成分股约5.96%的总回报率相比，苹果的出色表现更加令人印象深刻。更妙的是，在上周的回调之后，正面临一个重大的买入机会。（TheStreet） （来自新浪财经APP）</p></blockquote><p>这种论调还在的情况下，vix必然会下降吧，又会有一次好的做空机会。</p><h3><span id="2018-10-18">2018-10-18</span></h3><blockquote><p>中国9月外汇占款余额减少1,193.95亿元人民币，至21.4万亿元，降幅较上月明显扩大。 （来自新浪财经APP）</p></blockquote><p>这说明中国的经常账户估计还是要负。</p><h3><span id="2018-10-17">2018-10-17</span></h3><blockquote><p>【中国连续3个月抛售美债 持仓规模创去年6月来新低】当地时间10月16日美国财政部公布的数据显示，8月中国所持美国国债规模连续3个月下跌，环比减少59亿美元至1.1651万亿美元，创下去年6月以来的新低。报告显示，日本8月减持56亿美元至1.0299万亿美元，为2011年10月以来新低，但仍仅次于中国为美债第二大持有国。报告还显示，巴西和沙特的8月增持规模分列前两位。巴西成为最大的买家，8月巴西持仓环比增长181亿美元，晋升美债第三大海外持有地区。（澎湃） （来自新浪财经APP）</p></blockquote><p>我所理解的基本逻辑：中国抛售美债 -&gt; 美债收益率上涨；中国获得美元；市场上美元变少 -&gt; 美元走强；美债对全球美元的吸引力加大 -&gt; 中国货币贬值。但我还是觉得这个逻辑里有不对的地方，进一步观察和学习，看看这些事件的相关性吧。</p><h3><span id="2018-10-12">2018-10-12</span></h3><blockquote><p>按照这篇<a href="https://mp.weixin.qq.com/s/NAN8w7asj7s1eIFqma5tWQ" target="_blank" rel="noopener">文章</a>的观点：于是乎，有一部分对冲基金竟然另辟蹊径，选择了中国等高等级新兴市场的国债来避险，认为中国国债被下调评级的风险比较小，而且中国现阶段的货币政策至少比美国松得多，国债不会承压。还有，中国作为新兴市场，国债收益率还是较高的。这就是为什么昨天下午开始有大量外资涌入境内申购人民币债券，这波资金小幅推涨了人民币汇率。</p></blockquote><p>这个还是有些不好理解，毕竟目前美元十年国债收益率与中国相比已经比较有吸引力了，这时候“另辟蹊径”还是有一些风险的吧。</p><h3><span id="2018-10-09">2018-10-09</span></h3><blockquote><p>【全球债市再遭大幅抛售 美国10年期国债收益率续创七年新高】全球债市再遭大幅抛售，意大利30期国债收益率涨破4%关口，10年期国债收益率涨近11个基点，均创四年新高；美国10年期国债收益率一度升破3.26%关口，续创七年新高。德国10年期国债收益率转涨近3个基点，逼近逾4个月高位。 （来自新浪财经APP）</p></blockquote><p>原来收益率攀升是出于国债的大批抛售。但这会进一步导致美元走强？我还是理解不到位。</p><h3><span id="2018-10-07">2018-10-07</span></h3><blockquote><p>中国9月外汇储备30870.2亿美元，预期31050亿美元，前值31097.2亿美元。中国9月外汇储备环比减少227亿美元，上月减少82.3亿美元。中国9月末外汇储备2.212万亿SDR，8月末为2.219万亿SDR。 （来自新浪财经APP）</p></blockquote><p>在加息的预期下，外汇储备减少果然超预期了。按照分析加息对应的外汇流出约1000亿美金，所以对应降准1个百分点刚好对冲这部分消失的货币。</p><blockquote><p>【地方新增专项债发行全面提速 规模已达万亿】在刚刚过去的9月，地方政府专项债发行全面提速。数据显示，截至9月24日，地方政府专项债9月以来发行量已达约5000亿。此前，8月地方政府新增专项债发行规模约4200亿元，为7月发行量的3倍多。业内预计，8、9两个月新增专项债发行规模达到约万亿，全年剩下不到3000亿的额度将在10月全部发完。（经济参考报） （来自新浪财经APP）</p></blockquote><p>原来是影子银行破灭以后，万亿的债务不过是小case。</p><h3><span id="2018-10-06">2018-10-06</span></h3><blockquote><p>【高盛：股票回购将在2019年成为标普500指数成分股企业现金利用的一大部分】高盛表示，标普500指数成分股公司将在2019年将现金支出增加13%至3万亿美元，股票回购预计将再次成为他们现金支出中庞大的部分。高盛所预计的2019年现金支出中，标普500指数成分股公司将配置51%的资金用于投资增长，包括资本支出、研发和现金收购，49%的资金将通过回购和派息的方式向股东返还现金。2018年，标普500指数成分股公司现金支出增幅为19%，自2011年以来最大增幅。 （来自新浪财经APP）</p></blockquote><p>不知道加息会什么时候反转这个趋势。</p><blockquote><p>Refinitiv数据显示：美国10年期、五年期、以及七年期国债收益率均创2月份以来最大单周涨幅。两年期美债收益率创最近三周最大单周涨幅。30年期美债收益率创2016年11月份以来最大单周涨幅。三年期美债收益率创4月份以来最大单周涨幅。 （来自新浪财经APP）</p></blockquote><p>关注这个变化。</p><h3><span id="2018-10-05">2018-10-05</span></h3><blockquote><p>美联储：调查结果发现，金融杠杆利用情况几无变动。如果美债收益率曲线出现倒挂，融资条件将会收紧。 （来自新浪财经APP）</p></blockquote><p>没有去杠杆…</p><blockquote><p>【美元兑新兴市场货币在周四升值】据外媒，由于投资者越来越关注美国政府债券收益率上升，周四美元兑新兴市场货币上涨。美元兑土耳其里拉上涨2.4%，兑南非兰特上涨1.7%。兑阿根廷比索也升值2.4%。美国收益率的上升令固收多头的新兴市场资产吸引力减弱。10年期美国国债收益率是全球风险情绪的领头羊，最近收于3.183%，为2011年7月以来的最高水平。投资者将在周五的非农报告中找到关于美国经济增长前景的全新线索。 （来自新浪财经APP）</p></blockquote><p>新兴市场会再受一波攻击。</p><blockquote><p>【为什么美国中期选举将提振股票?】据华尔街日报报道，无论美国中期选举的结果如何，美股投资者都会赢得胜利。即使总统所在的党在国会中失去席位，但历史上股票往往会上涨：事实上，中期选举之后的一年往往是总统四年任期内最好的一年。其中一个原因是，总统的政党通常会失去部分权力，然后推动旨在促进经济发展的立法。根据Strategas Securities的数据，自1946年以来，无论选举结果如何，标普500指数平均上涨了15%，其平均年增长率为8.8%。 （来自新浪财经APP）</p></blockquote><p>这个理由很有趣。拭目以待，如果再次能提振股价，那么也就会造就一个完美的做空机会。</p><h3><span id="2018-10-04">2018-10-04</span></h3><blockquote><p>【长期美债收益率飙涨30年期美债收益率将近十年来首次站上3%，美国经济数据向好支持美联储可预见的未来加息的可能性】周三（10月3日）纽约尾盘，美国10年期基准国债收益率上涨11.82个基点，报3.1813%，美股盘后一度涨至3.1851%，逼近2011年7月1日盘中高位3.2206%、当年最高位在2月9日——3.7660%。两年期美债收益率涨6.11个基点，报2.8720%，逼近2008年6月25日高位2.9966%、当年6月13日曾涨至3.1140%——为当年最高位。 （来自新浪财经APP）</p></blockquote><p>这是为什么呢？我还没找到原因，为什么最近一个月会上涨这么快。</p><blockquote><p>美联储主席鲍威尔：对美国经济非常高兴。美国失业率处于最近20年最低位。美国通胀恰好处于美联储2%的目标。美国经济形势显然偏正面。我们正致力于让经济保持扩张，预计经济扩展银行还将持续相当一段时间。菲利普斯曲线尚未消失，而可能保持静止状态。渐进式加息确保通胀保持温和。预计薪资将继续渐进式增长。 （来自新浪财经APP）</p></blockquote><p>美联储关注的点始终在通胀，以及为下次危机准备弹药（加息）上。</p><h3><span id="2018-09-26">2018-09-26</span></h3><blockquote><p><a href="https://media.weibo.cn/article?id=2309404288058957667162&amp;from=timeline" target="_blank" rel="noopener">中国经济2018 — For if the dusking day declined</a></p></blockquote><p>这可能是2018年中国经济总结的最有干货的文章了，读完这篇基本就能理解很多逻辑了。btw，我还没读完Dalio的书…惭愧</p><blockquote><p>【中证报头版：OMO利率上调既无机会也没条件】美联储加息，人民银行会否上调公开市场操作（OMO）利率?答案是：不会！一则，周内已不大可能再开展公开市场操作，也就没有调整利率的机会。二则，当前中美经济与政策周期不同步，我国货币政策不具备转向基础，OMO利率与市场利率价差很小，后续“追加调整”的可能性同样很小。 （来自新浪财经APP）</p></blockquote><p>肯定不会。</p><h3><span id="2018-09-24">2018-09-24</span></h3><blockquote><p>【港元1个月期Hibor创2008年以来最大涨幅】在周二假期前夕，港元1天期Hibor攀升2个百分点至3.85286%；1周期港元HIBOR大涨1.4个百分点，创2008年9月以来最大上涨；港元1个月期Hibor大涨28个基点至2.16929%，创2008年12月以来最大涨幅。 （来自新浪财经APP）</p></blockquote><p>央行不敢加息，只能靠动动流动性来调整汇率了。</p><h3><span id="2018-09-22">2018-09-22</span></h3><blockquote><p>【印度股市因金融股暴跌而剧烈波动】周五，印度股市剧烈波动，随着Yes Bank和Dewan Housing Finance暴跌，印度金融类股纷纷抛售。Yes Bank股价跌至2016年以来最低水平，而Dewan下跌43%，创下历史最大跌幅。标普BSE Sensex支出一度上涨1%，后又跌3%，创逾4年来最大单日跌幅，收盘下跌0.8%。周五的暴跌显示，在Infrastructure Leasing &amp; financial Services 最近违约动摇了印度金融类股的信心之后，投资者仍对印度金融股感到不安。 （来自新浪财经APP）</p></blockquote><p>原本我以为印度是地缘政治的幸存者，但仔细一看发现这家伙的金融风险并不比中国低，反倒高不少。所以印度股市的繁荣也不过是一种暂时的现象而已。</p><blockquote><p>【3788.85亿元 本周地方债发行额创历史新高】据Wind数据，本周有14省/自治区/市发行了地方政府债券，实际发行总额为3788.85亿元，超过2015年11月2日至8日当周的3627.31亿元，创下我国历史上地方债单周发行规模的新纪录。算上国债，则本周政府债券发行总额为4788.85亿元，为近1年新高。（中证网） （来自新浪财经APP）</p></blockquote><p>如果地方政府没有中央兜底，估计早就穿了。</p><blockquote><p>【EPFR：全球股票基金单周大幅“吸金”138亿美元 全球货币基金“失血”270亿美元】全球资金流向监测机构EPFR于22日提供的数据显示，在截至9月19日的当周，全球股票型基金吸引138亿美元资金净流入，全球债券型基金吸引7.33亿美元资金净流入，全球货币型基金则出现270亿美元的资金净流出。（中证网） （来自新浪财经APP）</p></blockquote><p>股市和货基应该是好基友的。。为啥呢？因为货基收益高意味着贸易繁荣，对应股市走高。现在这俩背道而驰，感觉是要出事。</p><h3><span id="2018-09-19">2018-09-19</span></h3><blockquote><p>【李克强对侵犯知识产权者发重声】李克强总理9月19日在2018年天津夏季达沃斯论坛开幕致辞中表示，中国近年对外支付的知识产权使用费位居世界前列。中国政府坚决依法保护知识产权。这不仅是履行国际规则，也是中国创新发展的内在需要。李克强说，中国将实施更加严格的知识产权保护制度，对侵害中外知识产权的行为坚决依法打击，加倍惩罚。让侵权者付出难以承受的代价，让创新者放心大胆去创造。 （来自新浪财经APP）</p></blockquote><p>当不再有拼多多们的时候才是真正重视知识产权的时候。</p><blockquote><p>【李克强阐释中国为什么主动扩大开放】李克强总理9月19日在2018年天津夏季达沃斯论坛开幕致辞中表示，中国将以更大力度扩大开放，这是我们作出的自主选择：既可以促进国内产业转型升级，也可以给国内广大消费者更多选择机会，同时，这也是用实际行动维护经济全球化和贸易自由化的规则。总理说，今年以来中国大幅放宽了包括服务业特别是金融业在内的市场准入，这些政策正在加快落实。清理进口环节不合理收费。在前期分批次降低药品、部分日用消费品等进口关税的基础上，进一步降低部分商品进口关税。 （来自新浪财经APP）</p></blockquote><p>中国已开放，静候华尔街的响应。</p><blockquote><p><a href="https://mp.weixin.qq.com/s?__biz=MzU0MDUyMjczMA==&amp;mid=2247487592&amp;idx=1&amp;sn=215a043f33339a02ead7b232bc964713&amp;chksm=fb36b1edcc4138fb991229549b75e41bb7d0a81542f55d6491a5631543a9d14d4351a8e012a9&amp;scene=0&amp;ascene=7&amp;devicetype=android-24&amp;version=26070239&amp;nettype=cmnet&amp;abtest_cookie=AwABAAoACwATAAMAJJceAEyZHgBhmR4AAAA%3D&amp;lang=zh_CN&amp;pass_ticket=hmv8h4hXx7eKyIuUeYdQXSHh9TPpCdhbZSSV9p06NPB5c2zBYnpHx22kLkJRsTmD&amp;wx_header=1" target="_blank" rel="noopener">投研帮：小散到底如何抵御即将到来的滞胀寒冬？</a></p></blockquote><p>里面提到了上海出口集装箱运价指数，类似波罗的海干货指数。这个指数可以在<a href="http://www.eworldship.com/app/data?catid=2326" target="_blank" rel="noopener">这里</a>查到。这个指数反应了中国出口的繁忙程度。</p><p>这篇文章还不错，提出了在滞涨的情况下大宗商品是王道。可惜我们并没有什么手段，所以在我看来，小散换点美子可能是唯一能做的了。</p><blockquote><p>土耳其总统埃尔多安：（向在土的美国商界人士表示）我相信，土美战略伙伴关系将在投资和贸易的促进下得到强化。土耳其留意到，商业活动不会受到土方对美贸易措施的伤害。近期形势表明，土耳其经济趋于平衡。土耳其不会在自由市场原则上妥协。 （来自新浪财经APP）</p></blockquote><p>这很有趣，究竟美国商界人士与政府的行为是一体两面，还是说这是独立的行为。土耳其是美国中东战略的关键点，但也是矛盾点。观察未来土耳其的变化挺关键的。</p><blockquote><p>【负债成本上升 银行存款增长持续放缓】近期多项数据显示，人民币存款增速正持续放缓。 包括大行在内，绝大部分存款同比增速维持低位，平均为4.96%。业内人士表示，未来存款增速不会有太大的增长空间，增长持续放缓将是常态，银行资产规模扩张或进入停滞期。（经济参考报） （来自新浪财经APP）</p></blockquote><p>人民并没有足够的钱来储蓄了，这非常正常。</p><blockquote><p>【李克强：下决心进一步开放金融服务业】关于中国金融业开放，国务院总理李克强表示，一国金融业的开放程度，与其发展阶段、经济水平、监管能力密切相关。在保持金融稳定的同时，我们下决心进一步开放金融服务业，全面实施“准入前国民待遇+负面清单”模式，有序推进全牌照开放和全股比开放，目前对银行已放开股比限制，未来保险、证券也将取消股比限制。 （来自新浪财经APP）</p></blockquote><p>中国的开放实际上是不得不的行为。</p><h3><span id="2018-09-18">2018-09-18</span></h3><blockquote><p>【北京最严公积金政策出台 房贷资金不足城市或会跟随】恒大研究院副院长夏磊表示，北京的公积金新政，本质是落实‘租购并举’，鼓励先租后买、先积累再住房消费，客观上也考虑了北京市公积金中心资金不足的实际。北京公积金政策有明显的示范效应，对于一些贷款资金不足的城市，可能会跟随，但不必理解为房地产调控再度收紧。易居研究院智库中心研究总监严跃进认为，北京政策多少是有信号意义的，所以后续不排除全国各地公积金等方面政策还是会有收紧的动作。这或也意味着今年9月份又会有部分城市进入新一轮的调控体系中。（证券日报） （来自新浪财经APP）</p></blockquote><p>本质是公积金不够了…为啥老喜欢掩饰呢？</p><blockquote><p>美国7月国际资本净流入 522亿美元，前值 1145亿美元。美国7月国际资本净流入 +522亿美元，前值 +1145亿美元修正为 +1897亿美元。美国7月长期资本净流入 748亿美元，前值 -365亿美元。美国7月中国所持美国国债减少 77亿美元，至1.17万亿美元，创1月份以来新低。美国7月日本所持美债增加 51亿美元，至1.04万亿美元。 （来自新浪财经APP）</p></blockquote><p>美国资产现在就指着收割全球的美金来提高资产价格。</p><h3><span id="2018-09-17">2018-09-17</span></h3><blockquote><p>【 EPFR数据显示全球股票基金上周大幅“失血” 】资金流向监测机构EPFR最新发布的报告指出，在截至9月12日当周，该机构追踪的全球股票型基金出现55亿美元的资金大幅净流出。全球货币型基金出现高达145亿美元的资金净流出，而全球债券型基金则净流入2.71亿美元。EPFR指出，主要受全球风险偏好一度回落影响，资金大幅流出股票市场，小幅回流债券市场。（中证报） （来自新浪财经APP）</p></blockquote><p>人们似乎一直看多股市，但资金已经在流出了。</p><blockquote><p>【腾讯在港拿下基金牌照！携手高瓴设立高腾国际，进军海外资管业务】由腾讯和高瓴联合战略投资的高腾国际资产管理有限公司，近日获得香港证监会颁发的4号及9号牌照（公募），可在香港或其他合格境外地区设立投资于海外市场的基金，在香港开展公募、私募基金管理和证券投资咨询业务。这意味着，腾讯和高瓴两大巨头联手进军海外资管市场了。（中国证券报） （来自新浪财经APP）</p></blockquote><p>出海不见得是一件好事，而中国企业对国际事务也缺乏实际经验。</p><blockquote><p>【段永基：只给民营企业番号 既不给粮草也不给弹药】四通控股董事长段永基称，“如果国有企业是八路军，至少民营企业应该是新四军，可老把民营企业当忠义救国军，就给番号，既不给粮草，也不给弹药”。他认为这是思想不解放造成的现象，“思想不解放就阻碍了深化改革，希望经济学家在这方面多做一点重量级的呼吁”。 （来自新浪财经APP）</p></blockquote><p>这个比喻很有趣，也很形象。</p><h3><span id="2018-09-15">2018-09-15</span></h3><blockquote><p>【外汇占款结束七连涨 跨境资金流动保持稳定】8月末央行外汇占款21.5万亿元人民币，环比7月份减少23.95亿元人民币，结束七连涨。专家表示，外汇占款小幅减少或是一些扰动因素所致，尚不能说明有资金大幅流出，目前跨境资金流动总体保持基本稳定。未来在美国经济稳步向好、美联储加息、部分新兴经济体动荡以及贸易冲突的情况下，人民币仍有贬值压力，跨境资金流动波动可能会加大。（证券日报） （来自新浪财经APP）</p></blockquote><p>这不是个好的信号…由于关税问题，很多企业已经提前把下半年的贸易给完成了，而外汇占款减少似乎正说明了拐点到来，麻烦麻烦。</p><blockquote><p>【特斯拉被纳入衍生品指数】特斯拉已经被加入面向垃圾评级企业的主要信用违约掉期指数，表明投资者越来越多地利用衍生品来防范特斯拉发生债务违约的风险。摩根大通在2018年4月份上线交易与特斯拉相关的CDS交易，成交量迅速增长，使得该衍生品以3095亿美元净未平仓成为市场上交投最为活跃的1000种交易之一。IHS Markit表示，纳入特斯拉将有助于改善关于CDS指数的“相关性”。新指数将从9月27日开始交易。（英国金融时报） （来自新浪财经APP）</p></blockquote><p>不得不佩服美股的创新能力。</p><blockquote><p>阿根廷央行拍卖2亿美元外汇储备，以控制本币比索下跌；阿根廷央行称：9月19日开始，将把准备金要求提高5个基点。（路透） （来自新浪财经APP）</p></blockquote><p>要想稳汇率就只能牺牲外汇储备了，这不是长久之计。</p><blockquote><p>【任泽平：从8月份经济金融数据可以看出未来中国经济的九大特点和趋势】一、美元强势周期叠加全球贸易摩擦，全球市场动荡。二、国内，金融周期步入下半场，中央坚定去杠杆。三、固定资产投资持续回落，主要受金融去杠杆、财政整顿等影响。四、地产销售投资已于8月前后明显见顶回落。五、制造业投资筑底回升，产能出清新周期得到验证。六、消费持续低迷需要重视。七、抢出口导致出口数据异常大增。八、高度关注民企生存困境。九、中美贸易战往纵深发展。 （来自新浪财经APP）</p></blockquote><p>这个总结感觉是比较深刻和全面的。最近好多需要“共度时艰”的政策出来，作为老百姓，真的要小心自己的钱袋子啊。</p><blockquote><p>【俄德再次力挺“北溪2号”天然气项目】今日俄罗斯14日报道，俄罗斯和德国再次强调“北溪2号”天然气项目的重要性。俄方表示该项目完全是一个商业项目，能加强欧洲的能源安全。德国也是该项目的支持者并希望推动该项目在欧盟进一步实施。今日俄罗斯称，美国一直批评该项目，目的是让欧洲购买美国的液化天然气。（微天下） （来自新浪财经APP）</p></blockquote><p>德国要摆脱美国的控制，就必须能源独立，而靠拢俄罗斯是最好的选择，因为中东、美国是穿一条裤子的。</p><h3><span id="2018-09-13">2018-09-13</span></h3><blockquote><p>【 突发！美国主动邀请中方进行新一轮贸易谈判 】 美国《华尔街日报》刚刚援引消息人士说法称，美国财政部长姆努钦已向中方团队发出邀请，希望中方派出部级代表团在特朗普对华加征新一轮关税前与美方进行贸易谈判，地点将在北京或者华盛顿，时间是“未来几周”。（环球网） （来自新浪财经APP）</p></blockquote><p>按照特朗普的个性，想必在中期之前是没有什么进展的吧。将错就错或许还算有点骨气和颜面。</p><h3><span id="2018-09-12">2018-09-12</span></h3><blockquote><p>【美国飓风和伊朗制裁导致油价大涨】周二纽约市场原油和汽油价格创下6月底来最大涨幅，因飓风“佛罗伦斯”威胁美国东海岸燃油市场并且制裁开始限制伊朗的石油出口。隔夜纽约商业交易所10月份交割的西德克萨斯中质油合约大涨2.5%，报69.25美元/桶；伦敦ICE欧洲期货交易所11月交割的布伦特合约上涨1.69美元，收于79.06美元。 （来自新浪财经APP）</p></blockquote><p>美国的飓风果然与油价有着紧密的关联。</p><h3><span id="2018-09-11">2018-09-11</span></h3><blockquote><p>HIBOR近期走势</p></blockquote><p><iframe src="https://d3fy651gv2fhd3.cloudfront.net/embed/?s=hongkongintrat&v=201809110831x&d1=20080101&d2=20181231&h=300&w=600" height="300" width="600" frameborder="0" scrolling="no"></iframe><br>source: <a href="https://tradingeconomics.com/hong-kong/interbank-rate" target="_blank" rel="noopener">tradingeconomics.com</a></p><p>从这些情况来看，可以显著发现货币的流动性在收缩。</p><h3><span id="2018-09-07">2018-09-07</span></h3><blockquote><p>美国10年期国债收益率触及2.926%，为8月10日来最高。 （来自新浪财经APP）</p></blockquote><p>观察近期10年国债收益率的变化，自从5月17到达3.1%的高峰后随即处于以波动的状态。感觉全球的美金在一波波流入美国，而期间股市一直处于上涨的状态，这种波动还能持续多久呢？等到下一次收益率突破3%的时候需要观察。</p><blockquote><p>【上市公司“炒房”首破万亿：7公司上半年炒房赚超亿元】统计显示，今年上半年持有投资性房地产的A股上市公司数量及合计持有金额双双创历史新高，1680家上市公司（仅统计报告期前上市的企业），合计持有投资性房地产首破万亿元，达到10477.12亿元。此外，这是A股公司持有投资性房地产连续第9个季度环比增。而就在上半年，有7家公司通过投资性房地产赚超亿元，同期没有公司亏损过亿，这一定程度上释放出房价仍处于上涨态势之中。（证券时报） （来自新浪财经APP）</p></blockquote><p>操蛋的A股企业，A股不值得投资。</p><blockquote><p>【马斯克剖析缘何不喜欢Instagram，以及社交媒体对心理健康带来的负面影响】据Bisinessinsider报道，马斯克在电视节目“The Joe Rogan Experience”有声杂志中现身，并讨论了他认为Instagram之类的社交媒体并不是真实生活的反映的原因。马斯克表示，有一些看起来很快乐的人其实现实生活中是最悲伤的。在将近3个小时的节目中，马斯克与喜剧演员Joe Rogan谈论了有关事业，人工智能，虚拟现实等话题。马斯克认为，社交媒体的一个问题是，人们看起来比实际生活好得多。人们会上传自己开心时的照片，会美化照片或选择最好的光线，最好的角度使自己看起来更漂亮，这可能会对粉丝的心理产生负面影响。尽管马斯克是重度推特使用者，但他对社交媒体的整体评价并不好。 （来自新浪财经APP）</p></blockquote><p>马斯克陷入了糟糕的境地。</p><h3><span id="2018-09-01">2018-09-01</span></h3><blockquote><p>From <a href="https://www.bloomberg.com/view/articles/2018-08-31/why-china-tech-stocks-are-falling-behind-u-s-peers" target="_blank" rel="noopener">Why China Tech Stocks Are Falling Behind U.S. Peers - Bloomberg</a><br>While U.S. companies like Amazon and Netflix Inc. still believe in entering new markets on their own, China Inc. seems to have decided that a strategic investment in a startup is a more attractive option. The Chinese firms may be taking their cue from long-time patrons: Small investments two decades ago by South Africa’s Naspers Ltd. and Japan’s SoftBank Group Corp. became $130 billion-plus stakes in Tencent and Alibaba, respectively.</p></blockquote><p>这个看法与我一致。国外的公司在投资和收购上往往围绕其核心业务，试图扩大自己的护城河。中国的科技企业往往四面出击，比如阿里、腾讯、网易、京东等等，尤其还有所谓“没有边界”的王兴。似乎人人都是顶尖的战略家，有着不凡的布局能力。让时间来考验他们吧。</p><blockquote><p>From <a href="https://www.bloomberg.com/news/articles/2018-09-01/hna-s-debt-declines-for-first-time-shrinking-by-8-3-billion" target="_blank" rel="noopener">HNA’s Debt Declines for First Time, Shrinking by $8.3 Billion - Bloomberg</a><br>Total debt fell 9.5 percent to 541.6 billion yuan ($79 billion) at the end of June, down about $8.3 billion from the record high set at the end of last year, according to figures derived from a half-year report dated Friday. Prior to this, HNA’s debt had always risen, based on public data stretching back to 2005.</p></blockquote><p>难怪要出“翻墙死”了…安邦、万达、海航，债务三巨头，可惜生不逢时啊！</p><h3><span id="2018-08-31">2018-08-31</span></h3><blockquote><p>特朗普：许多人认为谷歌、Facebook与亚马逊存在反托拉斯问题。拒绝置评谷歌等是否应当被分拆。注：据CNN报道，前白宫首席策略师 Steve Bannon此前称，大型科技股必须被拆分。 （来自新浪财经APP）</p></blockquote><p>如果真正遭遇反垄断，那么Google、FB和Amazon够喝一壶的了…</p><blockquote><p>特朗普威胁称若WTO表现不好，美国可能退出。注：自2017年入主白宫以来，特朗普政府至少已经退出了联合国教科文组织、TPP、巴黎气候协议等多个地区乃至国际组织。 （来自新浪财经APP）</p></blockquote><p>特朗普不遗余力制造波动性。</p><blockquote><p>【特朗普表示考虑将资本利得税与通胀挂钩】据外媒报道，今日美国总统特朗普表示考虑通过发布资本利得税与通胀挂钩的规定以实现资本利得税的减免。资本利得的变化将通过调整通货膨胀的原始购买价格来降低投资者在出售股票或房地产等资产时的税单。 该变动一直是美国国家经济顾问库德洛的长期目标，他认为此项措施将会刺激就业创造与经济发展，因为人们不会因虚幻的收入而缴税。该议题自7月以来备受关注，美国财长努钦当时表示财政部门寻求绕过国会，发布允许资本利得与通胀挂钩的规定。 （来自新浪财经APP）</p></blockquote><p>特朗普的团队解决问题的方式总是那么“奇葩”，不是蠢就是坏。</p><blockquote><p>【美国证券监管部门希望更多的投资者参与私人交易】美国证券交易委员会（SEC）主席Clayton表示，SEC希望个人投资者更加容易投资私人公司，包括部分全球最火热的投资，而许多人并不能接触到这些投资。SEC希望采取措施，让更多的个人投资者对多年来一直避免上市的公司进行抨击，这些公司包括优步、Airbnb，它们一直避开公开市场而支持像投机资本家的私人投资者。SEC现在考虑对规则进行大修，以保护那些经验不足的投资者，为他们开辟新的选项。SEC计划在未来数月发表一篇名为“概念发布”的论文，将征求公众对如何改革融资流程的意见，包括通过扩大私人股本销售渠道。（华尔街日报） （来自新浪财经APP）</p></blockquote><p>这真是个好的政策，希望中国也会有这种机会。</p><blockquote><p>“股神”巴菲特：相比30年期国债和其他固定收益资产，股票仍然更具吸引力。对股票持乐观态度，今天早上还在买股票。6月以来，买入“略微”更多的苹果股票。 不要关注苹果的季度销量。苹果公司正真的价值在于客户与苹果公司深切的联系。 iPhone的用处对于人们来说被极大低估。 （来自新浪财经APP）</p></blockquote><p>显然目前的国债收益率不够理想。</p><h3><span id="2018-08-25">2018-08-25</span></h3><blockquote><p>【央行昨放水逾千亿元 缓冲地方债发行冲击】昨日，中国人民银行开展中期借贷便利（MLF）操作1490亿元。中信证券固定收益首席分析师明明表示，“在流动性仍然宽松的环境下，央行继续开展流动性净投放，维持资金利率低位的意图明显。”在明明看来，本次MLF操作的目标除对冲逆回购到期因素外，近期地方政府专项债券加速发行对流动性的冲击也得到央行的关注，通过中长期流动性投放，宽松的货币政策配合积极的财政政策，缓冲地方债发行的市场冲击。（证券日报） （来自新浪财经APP）</p></blockquote><p>是啊，这样的情况下还如何加息呢？搬石头砸自己的脚？那么汇率该怎么收场呢？</p><h3><span id="2018-08-24">2018-08-24</span></h3><blockquote><p>【城投债面临万亿级到期洪峰】彭博数据显示，自今年三季度起，在岸城投债到期规模将会连四个季度超过3000亿元，季度均值达到3436亿元，较2017年季度平均水平增长约40%，并在明年一季度达到记录峰值。城投债存量规模里，AA及以下评级占到了四分之一。 （来自新浪财经APP）</p></blockquote><p>城投债的违约已经是央行的信号了。</p><blockquote><p>【华尔街大空头:美股不久就会现原形 企业债蕴藏杀机】Gluskin Sheff首席经济学家David Rosenberg认为美股繁荣存在人为支撑。不过随着全球央行收紧政策，他预期一切可能会现出原形。他周三（8月22日）称，经济扩张处于历史上最低迷时期，牛市却打破了历史纪录。他在7月末曾预测信用利差走阔可能会终结牛市，而现在他仍坚持这个观点。 （来自新浪财经APP）</p></blockquote><p>小心观望。</p><blockquote><p>【与美国唱反调！欧盟同意向伊朗提供1800万欧的援助】美国总统国家安全事务助理博尔顿22日刚刚表示，美国不打算停止并可能采取其他措施向伊朗施压。一天后，欧盟就高调与美国唱起了反调。欧盟周四（23日）同意向伊朗提供1800万欧元（约合2060万美元）的援助，其中包括对伊朗私营部门进行援助，以帮助抵消美国对其制裁的影响，挽救2015年达成的伊核协议。路透报道称，该声明反映出，欧盟对美国总统特朗普今年5月放弃的伊核协议进行了高调支持。（环球网） （来自新浪财经APP）</p></blockquote><p>有趣的事情，二战过去也已经很多年了，欧洲终于要开始硬气了？</p><blockquote><p>【加拿大帝国商业银行：预计鲍威尔演讲影响较小 立场可能偏鹰派】今年的杰克逊霍尔年会将是鲍威尔作为美联储主席的首秀，他的演讲对市场影响可能是有限的，讲话立场的鹰派可能性大于鸽派，原因有三。首先，联邦基金利率仍低于2.75%（美联储官员认为的中性利率区间上限），且10年期美债收益率仍低于3%，没有必要在此时打压对利率的预期。其次，近期“挑战”美联储的阵营主要是担忧美联储加息过多、过快。第三，在美国总统特朗普已经对美联储加息表示不满的情况下，如果鲍威尔要维护美联储的独立性，那此时就绝不应该转向更鸽派立场，以免让人觉得他向特朗普屈服。鲍威尔的鹰派立场可能推升短期美债收益率，且短暂温和地拉升美元。 （来自新浪财经APP）</p></blockquote><p>目前美元观察到停止加息的信号。</p><blockquote><p>【特朗普：在美墨边境建墙已经花了35亿美元 】美国总统特朗普在接受福克斯新闻频道采访时说：“我们正在修建隔离墙。施工已经开始，已经耗资35亿美元，我们希望今年获得50亿美元的预算拨款。”特朗普表示，他希望工程进度能快一些，但与民主党人打交道很困难。7月下旬，特朗普在美国佛州坦帕与支持者见面时表示，美墨边境隔离墙的修建工作已经开始。 （来自新浪财经APP）</p></blockquote><p>特朗普是个有趣的人。</p><h3><span id="2018-08-23">2018-08-23</span></h3><blockquote><p>【两万亿地方债来袭 市场呼吁央行仍需积极注水以维系宽松环境】据彭博，中金、中债资信等机构分析师均预计，8-9月间将有约两万亿地方债供给，将是去年同期发行规模的2.4倍。8月迄今已发行超7000亿元，至少是约一年高位。市场人士指出，从维稳资金面、维持低利率角度考虑，央行后续需加码宽松，可选政策选项包括继续大量投放MLF和降准。 （来自新浪财经APP）</p></blockquote><p>中国金融如果出现问题，必然在地方债和国企债中爆发出来。</p><blockquote><p>美联储会议纪要：利率更加接近中性利率；通胀中期内稳定在2%附近；主席暗示资产负债表将继续下降；部分成员认为财政面临上行风险，部分官员认为，强大的经济动能属于上行风险；许多美联储官员预计下次加息可能很快到来时合适的；主席鲍威尔暗示，将在秋季继续讨论资产负债表问题； 许多委员指出，在“不太遥远的未来”可能适合在谈到货币政策立场时不再用宽松一词； 普遍预期美国GDP增速会在下半年放缓， 但仍高于趋势水平；官员们讨论了收益率曲线趋平的影响。美联储官员讨论了银行逆周期资本缓冲。 （来自新浪财经APP）</p></blockquote><p>加息估计正常进行。</p><blockquote><p>【于学军：中国经济以2008年为界大致可划分为两个阶段】 中国银监会国有重点金融机构监事会主席于学军在中国银行业发展论坛表示，在2008年金融危机发生之前，中国保持了巨大的比较成本优势。从2014年二季度开始，人民币出现贬值压力，外汇储备增长放缓，随后又出现趋势性减少。政府出台更多刺激性政策拉动经济增长，主要手段是投资，尤其是公益性的基础设施投资。增加投资的背后是货币性的大量投放，也就是所谓“放水”行动，其结果必然造成货币超发的局面，使资产泡沫化更加严重，宏观杠杆率水平快速上升。人民币的增持购买力大幅缩水，从而面临着对外贬值、对内通胀压力加大这样一种局面。 （来自新浪财经APP）</p></blockquote><p>这个评价比较中肯。</p><h3><span id="2018-08-22">2018-08-22</span></h3><blockquote><p>【美国2000亿关税听证会 首日61人发言只3人赞同】听证会首日的情形也证明了美国业界的焦虑之情。据在听证会现场的记者核查，61个发言人共被分成八组，其背景涵盖了箱包、服装、食品加工到半导体、自行车、化工等多个产业，赞同征税者寥寥，仅有3位。（一财） （来自新浪财经APP）</p></blockquote><p>如果哪天突然说贸易战不打了，会带来什么影响呢？可能股市会涨几天吧，仅此而已。而且，随后要观察究竟哪些领域的对外开放真正意义上加大了。</p><h3><span id="2018-08-20">2018-08-20</span></h3><blockquote><p>【264只个股破净 估值底能否成为市场底】上周A股市场继续寻底，成交继续缩量，上证综指周跌幅为4.52%，8月17日盘中最低探至2666点创7月初以来新低，逼近2016年1月底的2638点。在此情势下，市场上出现了估值底、政策底、资金底和情绪底等各种“底部论”，而本周策略报告中，各大券商探讨最多莫过于估值底。其中，天风证券表示，较低的估值能提供一定安全边际，但不能作为见底的充分条件；而海通证券认为，A股处于第五次历史大底磨底中，换手率低至143%，情绪扭转至少需两大信号之一：一是去杠杆拐点，二是改革加速。（证券时报） （来自新浪财经APP）</p></blockquote><p>如果你的公司净值100亿，可现在市场对其估值90亿，那你会怎么办？当然是借钱也要买自己的股票！但现在的全年回购仅600多亿，去年一年的回购87亿，想想不觉得好笑么？可见估值的水分之大，难以评估。</p><h3><span id="2018-08-19">2018-08-19</span></h3><blockquote><p>鸿学院有关土耳其问题的讨论。</p></blockquote><p>在2018年3月就发生了刘鹤访问美国的事件，但没有达到化解“贸易战”的效果。后来，6月美国商务部长罗斯访问中国，仍然没有达成实质性的结果。在3月到6月期间，中方有意无意的发布了一系列的消息和对外开放政策，外界解释为中方对美方示好，尤其是中国的负面清单里在一些重要领域选择了对外开放，但美方一直表现出强硬的态度，包括两轮已经生效的加税。8月底，中国应邀派出商务部副部长赴美谈判。</p><p>宋鸿兵认为这次访问有几大特点：</p><pre><code>1. 美国邀请2. 低调开展3. 低层次沟通</code></pre><p>可能是实质性的沟通。自古以来，政治决定很少是在镁光灯聚焦之下完成的。因为人都是好面子的，而谈判必然存在冲突，所以在围观群众面前，大家都更加希望维护自己的面子，而很难达成实质性的妥协。接下来，需要密切关注本轮谈判释放出来的消息。</p><p>从商人的角度，希望达到最大的权益。如果真弄得老死不相往来，本质上丢掉了本该能获得的利益，这是不符合其根本利益的。我观察到，本次冲突中，由于民粹主义抬头，制造业回流就成了一个重要的目标。所以，特朗普的恐吓并非完全站在商业帝国的立场，最终两方利益肯定会达成一个折中。</p><p>宋鸿兵认为贸易战中国受到的影响有限，其依据是关税受伤的主体是美国，而中国由于出口只占31%，所受的影响有限。另外，美元必须长期逆差才能做到影响全球金融的目的，所以所谓的贸易顺差与华尔街利益背道而驰，必然无法真正达到顺差的状态。我同意这种看法，中国最大的问题还是来自内部而不是外部，这方面的讨论会另外开一个页面。贸易战对此而言只是一种舆论上的导火索。</p><p>需要理解冲突的本质是利益，从而关键在于谈判的底牌在哪里。</p><p>土耳其是以色列和美国国家利益派的矛盾体现。以色列希望以库尔德人独立来达到快速颠覆伊朗政权的目的，而美国希望通过经济制裁来缓慢达到目的。但以色列显然在美国更占优势，所以土耳其在这个问题上无法容忍，必然会激烈反抗美国。土耳其在伊朗问题、欧洲难民问题、借债问题上与欧洲利益一致，所以美国的压力会促使土耳其与欧洲和俄罗斯走的更近。</p><blockquote><p>7月结售汇由顺差转逆差 远期售汇额同比增3.7倍</p></blockquote><p>美元流出的预期难以简单消除。</p><h3><span id="2018-08-18">2018-08-18</span></h3><blockquote><p>周五（8月17日）纽约尾盘，美国10年期基准国债收益率下跌0.55个基点，报2.8605%，本周累跌1.27个基点；5月18日曾涨至3.1261%，逼近2011年7月8日盘中高位3.1805%。两年期美债收益率跌1.05个基点，报2.6059%，本周累涨0.47个基点；7月26日曾涨至2.6856%，逼近2008年7月24日高位2.8309%。 （来自新浪财经APP）</p></blockquote><p>美国国债最近一直在下跌，股市却在上涨，而且货币收紧的预期并没有减弱，那么这些美元是从哪里来的呢？想必对新兴市场的抽血还没有停止。</p><blockquote><p>【专家预计央行9月份加息概率大】中信证券固定收益首席分析师明明表示，6月份央行出于内部环境稳增长和防风险的考虑没有跟随美联储加息，面对美联储9月份的加息，出于保汇率和稳经济的考虑，央行大概率还是会选择跟随加息。（证券日报） （来自新浪财经APP）</p></blockquote><p>个人看法与之相反。</p><blockquote><p>美国证券交易委员会（SEC）：采用简化和更新上市企业信息披露要求的修正提议。修正案将在联邦登记处公告30天之后生效。 （来自新浪财经APP）</p></blockquote><p>的确有利于企业开展经营活动。</p><h3><span id="2018-08-14">2018-08-14</span></h3><blockquote><p>【消费品市场上半年增速放缓】中国商业联合会和中华全国商业信息中心联合发布了今年上半年消费品市场运行情况，上半年消费品市场增长9.4%，回落幅度有所加大；其中网上实物商品零售额增速同比增长29.8%，增速有所加快。消费品市场增速放缓幅度加大原因包括：居民收入增速放缓，2018年上半年，全国人均可支配收入同比增长8.7%，实际增长6.6%，分别比2017年同期回落0.1个和0.7个百分点；社会消费品零售总额基数已非常巨大等。（北京商报） （来自新浪财经APP）</p></blockquote><p>可支配收入增速和消费增速回落是一致的，问题变得越来越困难。</p><blockquote><p>【中资银行7月份公司债减持幅度创17个月之最】尽管央行近期出台的宽松措施鼓励银行增持公司债，但是国内的商业银行，为应对海量地方政府债发行，7月份大幅减持了公司债。据彭博援引中国债券信息网和上海清算所数据，国内商业银行的商业票据、中期票据及信用债持有量7月份环比减少670亿元人民币（97亿美元）至1.8万亿元，创出了2017年2月以来的最大减幅。 （来自新浪财经APP）</p></blockquote><p>由于银行本质上受制于政府，所以最终必然会增持公司债。既然这些债务并不“可口”，那么政府还需要对应的机构来帮助银行消化。借鉴美国次贷危机的经验，这种消化应该就是逆回购这些债务，然后将其证券化。且看事情是不是如此发展下去。</p><h3><span id="2018-08-13">2018-08-13</span></h3><blockquote><p>【货币基金7日年化收益率降至3.4% 短期内下行趋势可能仍将延续】受到货币市场利率下行影响，8月份以来，货币基金收益率出现回落，货币基金7日年化收益率平均3.4%水平，较6、7月份下滑了近0.5个百分点。“余额宝”等理财宝宝的收益率也在走低。如天弘余额宝8月10日的7日年化收益率为3.34%，与腾讯理财通合作的货币基金收益率也较前期走低，基本都下滑至3.5%左右。另有人士认为，货币基金收益率中短期内的下行趋势可能仍将延续，而“互联网宝宝”的收益走势也不乐观，继续下降的概率较大。(证券时报) （来自新浪财经APP）</p></blockquote><p>遇到这种情况，先看M2的增速。</p><blockquote><p>【经济参考报头版评论：中国经济发展不会再走也不可以再走“经济房地产化”老路】房地产去杠杆需要打消民众对房价上涨的预期。如果大部分人都认为未来房价将横盘或者回调，那么加杠杆的动力才会减弱。加速长效机制落地，释放投资者、投机者持有成本增加信号，让投资人群有所畏忌，促使房地产真正回归只住不炒已时不我待。中国经济不能再走“老路”，房地产调控也不能再走“回头路”。降低地方对房地产的依赖，同时有效调整市场预期，促进房地产调控长效机制落地成为房地产调控的关键所在。 （来自新浪财经APP）</p></blockquote><p>增强和打消民众对房价上涨的预期同样是那么痛苦。</p><h3><span id="2018-08-12">2018-08-12</span></h3><blockquote><p>土耳其总统埃尔多安在土耳其与美国关系危机情况下表示，土耳其准备同中国、俄罗斯、伊朗及乌克兰这样的大贸易伙伴国改为本国货币结算。 （来自新浪财经APP）</p></blockquote><p>可能性太小，谁会要你的货币呢？除非这种货币是以石油背书的，而且需要保证土耳其政府不至于崩溃了。</p><h3><span id="2018-08-10">2018-08-10</span></h3><blockquote><p>【阿根廷通胀高企 民众以物换物节省开支】阿根廷央行预计今年本国通胀率可能超过30%。生活成本的升高让民众开始寻找节省开支的办法。比如，不再用钱买东西。在这些物物交换市场上，大都是交换一些柴米油盐的生活用品。人们事先通过社交网络沟通好需求，再来到市集交易。 （来自新浪财经APP）</p></blockquote><p>回到了以物易物的时代。</p><blockquote><p>【专家称输入性通胀有望抬头】摩根士丹利华鑫证券首席经济学家章俊称，今年国内成品油价格已经连续9次上调，7月份汽油和柴油价格同比上涨22.7%和25.1%，合计影响CPI上涨约0.42个百分点。目前来看，全球经济复苏虽然进入尾声，但对能源的需求依然比较旺盛，但供给端受到欧佩克限产、美国原油增产低于预期，以及伊朗等地缘政治风险等因素影响而存在很大的不确定性，因此油价存在较大上行风险。鉴于目前中国原油对外依存度达70%，如果原油价格出现跳升，则输入性通胀可能会再次抬头，成为拉升通胀的重要推手。（证券日报） （来自新浪财经APP）</p></blockquote><p>对我国而言这个“经济复苏虽然进入尾声”不知作何感想。</p><h3><span id="2018-08-08">2018-08-08</span></h3><blockquote><p>【货币利率跌到“地板价” 实体融资困局仍未缓解】2.0%、1.8%、1.6%……进入8月，货币市场隔夜利率继续“断崖式”下跌。上海银行间同业拆放利率隔夜资金价格创下自2015年8月12日以来的历史新低。今年市场利率中枢下行，但实体端的融资利率仍偏高。银行的钱堆积在利率债和货币市场上，没有流入实体经济。”民生银行首席研究员温彬告诉记者。（上证） （来自新浪财经APP）</p></blockquote><p>问题的本质在于实体经济赚不到钱，而且风险在逐渐增加，那么银行就没有意愿把资本借到实体经济中去。有趣的是，其对外表现出来的形势看起来却与货币宽松类似。</p><blockquote><p>【美23日起将对160亿美元进口中国产品征收额外关税】美国贸易代表办公室公布第二轮关税计划，对价值160亿美元的进口中国产品征收25%的额外关税，8月23日生效。据CNN报道，美国贸易代表办公室于美国当地时间周二，公布了一份价值约160亿美元的中国产品清单，并称从8月23日起，将针对清单上产品征收25%的额外关税。该清单包含了6月15日公布的拟议清单中最初的284个关税细目中的279个。（中国日报） （来自新浪财经APP）</p></blockquote><p>继续观察。</p><blockquote><p>【沙特和加拿大争端升级 沙特将抛售加拿大资产】据英国金融时报报道，两位知情人士表示，沙特央行和国家养老基金已指示其海外资产管理的经理，“无论成本如何，都要抛售加拿大股票、债券和现金持有”。高管们表示，据估计，第三方基金经理被授权向全球市场投资逾1000亿美元的沙特基金。一位知情人士表示，尽管投资于加拿大资产的比例“以绝对值计算“相当小，但资产抛售却传递了一个强烈的信号。这轮抛售始于周二，突显出沙特正展示其金融和政治实力，警告外国不要干涉其主权事务。 （来自新浪财经APP）</p></blockquote><p>加拿大在国际上的存在感如此的渺小。</p><blockquote><p>【铁矿石有望突破70美元 中国转向支持经济料刺激需求】新交所AsiaClear期货价格周二上涨至每吨70美元，创下3月以来的最高盘中水平。根据我的钢铁网，在现货市场上，品位62%的基准铁矿石周一触及69.55美元。品位65%的优质矿石表现更好，飙升至96.20美元，为11个月新高。 （来自新浪财经APP）</p></blockquote><p>铁工基的刺激能力有限，不知道还能坚持多久。如果不能同时进行大刀阔斧的利益再分配，实在没有什么真正变革的希望。</p><h3><span id="2018-08-07">2018-08-07</span></h3><blockquote><p>【美国对伊朗重新实施的第一轮制裁生效】美国重启对伊朗金融、金属、矿产、汽车等一系列非能源领域制裁。据报道，此次制裁将涉及伊朗政府购买美元；黄金等贵金属交易；工业用石墨、钢、铝、煤炭和软件；与伊朗货币相关交易；与伊朗政府发行主权债务相关活动；伊朗汽车行业。 （来自新浪财经APP）</p></blockquote><p>美元是美国经济制裁的刺刀。</p><h3><span id="2018-08-02">2018-08-02</span></h3><blockquote><p>【中证报：“六稳”透露调控新信号】中国证券报头版刊文称，中共中央政治局日前召开会议，分析研究当前经济形势，部署下半年经济工作。其中，“稳”是一个关键词，“六稳”即稳就业、稳金融、稳外贸、稳外资、稳投资、稳预期是保持经济平稳健康发展的具体要求，直接反映了稳增长将被放在更加重要位置。在稳增长重要性抬升背景下，政策组合的前瞻性、灵活性、协调性将提高，去杠杆力度和节奏会更加务实。这将有利于从供求两端稳定实体经济的融资需求及增长预期。可以期待的是，监管部门将在实现“六稳”方面出台一些具体政策。 （来自新浪财经APP）</p></blockquote><p>这六个“稳”的顺序很有意思，个人感觉是按照优先级由高到低排列的。首先，稳就业是第一位的，因为就业不稳则社会动荡；然后是稳金融，因为金融业是经济的血液；稳外贸和外资都表明希望外来资本能以稳定的形势保证金融安全，而其中外贸比外资更重要，因为那是劳动所得，而外资流动性和波动性更大；稳投资是在外资无法补足经济增长空缺的情况下，通过本国货币政策来填补空白；最后稳预期就比较虚了，也无法简单理解其内在的含义。</p><h3><span id="2018-07-26">2018-07-26</span></h3><blockquote><p>美国总统特朗普与欧盟委员会主席容克举行联合新闻发布会，特朗普称：与容克关系进入新阶段。我们同意致力于零关税。欧盟将提高购买美国大豆的力度。欧盟将进口更多的美国液化天然气（LNG）。（已经达成的）协议将有利于强化战略能源合作。在谈判进行期间，我们不会违背贸易协议所约定的精神。将启动贸易谈判，化解钢铝关税和报复性关税问题。 （来自新浪财经APP）</p></blockquote><p>美国的霸主地位意味着无论何时他都有机会选择坐下来谈。与欧洲前段时间看似水深火热，但根本上其它的利益还是无法撼动两者合作的凝聚力。接下来恐怕美国对伊朗的压力还会加大，对中国仍然继续保持一种高压的状态。石油想必会上涨，而A股恐怕还是逃不开下跌的命运。</p><h3><span id="2018-07-25">2018-07-25</span></h3><blockquote><p>【特朗普向美农民提供120亿美元紧急援助】商务部网站消息，据《美国之音》7月25日消息，美国农业部长桑尼-珀度称，美国农业部将对受关税影响的美国农牧场主提供120亿美元的支持。这些项目将包括直接向农民付钱、贸促措施以及购买食物。按照《商品贸易公司宪章法》，这些项目已经获得授权，无需国会专门批准。珀度说，这些项目是短期解决方案，以便让特朗普有时间谈判达成贸易协议。 （来自新浪财经APP）</p></blockquote><p>从这样的做法来看，基本上美中之间的贸易战没那么容易结束。中国对外开放农场品市场，悄无声息就把中国农民的利益出让了，但明面上说的冠冕堂皇，什么加大对外开放是基本国策。天天说特朗普不好，但美国农民受损的利益是可以得到实实在在补偿的。</p><blockquote><p>【经参：我国事实上面临着较大的经济下行压力】 一方面，经济走稳的支撑经不住细抠，体现为：上半年房地产投资居高不下，主要是靠拿地，地方政府依旧不改土地财政依赖症；4月起PPI连续第三个月回升，但价格回升主要来自供给收缩并非需求恢复。此外，上半年贸易坚挺但有“抢跑”的成分，基建投资和消费则明显走坏。另一方面，美国挑起的这轮贸易纠纷有愈演愈烈之势。据有关测算，基于中美拟加征关税的规模，将导致我国GDP增速放缓0.1至0.5个百分点。换言之，如果不出台对冲举措，我国GDP增速有可能跌至6%甚至更低。经济高速增长已经不是硬要求，但这并不意味着当前可以容忍经济失速下行。本次国务院常务会议提出“保持经济运行在合理区间”，就是旨在稳增长。具体到经济对策，主要还是财政政策和货币政策双管齐下。 （来自新浪财经APP）</p></blockquote><p>评价相对中肯，下半年面临的最大问题估计是外部贸易战的压力和内部经济继续下行的压力，而真正的难处实际在内部。在经济减速的时候，往往是社会矛盾激化的时候，如何保持国内稳定的局面同时不断深化改革是一件非常非常困难的事情，拭目以待并时刻准备吧。</p><h3><span id="2018-07-24">2018-07-24</span></h3><blockquote><p>【全面宽松基本确认！国常会刚刚一锤定音，不搞大水漫灌强刺激，将影响股市债市】刚刚召开的国务院常务会议一锤定音，释放了全面宽松的信号。金融研究院院长管清友表示，政策面正式变化，但不会再度出现2014那种大水漫灌。中信固收称，货币宽松政策再确认。解读一：积极的财政政策，或利好基建。解读二：货币宽松政策再确认，或迎降准。解读三：扩内需政策明确方向。解读四：保障融资平台合理融资需求，利好城投债。解读五：地方政府专项债发行为基建筹集资金。解读六：开展有效投资，框定多个区域。解读七：股市方面，中信证券债券研究团队认为，宽货币向宽信用转变是利好，未来可能得到宏观数据进一步支撑；利率债目前机会不大。（券商中国） （来自新浪财经APP）</p></blockquote><p>股市请开始你的表演。不过越是真的想解决问题，可能股市压力越大，否则股市房市还是会像过去一样。</p><h3><span id="2018-07-20">2018-07-20</span></h3><blockquote><p>【上交所地方债发行突破7000亿元】随着7月20日安徽省269.5751亿元政府债券成功通过财政部上海证券交易所政府债券发行系统公开招标发行，今年上交所地方债累计发行规模已经突破7000亿元。据了解，在发行常态化的基础上，上交所正在积极推动地方债交易机制完善与地方债产品创新，提升二级市场的流动性，有助于不断提升地方债的投资价值与配置价值，促进地方债市场健康发展。(证券日报) （来自新浪财经APP）</p></blockquote><p>对于债务的流动性，在信息不对等的情况下，一方面是公有资产外流，另一方面是垃圾债务转移。</p><h3><span id="2018-07-19">2018-07-19</span></h3><blockquote><p>日本石油企业考虑暂停进口伊朗石油。日本对伊朗石油进口最早可能在10月份降至零，沙特和阿联酋都名列潜在的替代性供应方。（日经新闻） （来自新浪财经APP）</p></blockquote><p>在基本利益面前，国家之间是没有什么“情谊”的，简单明了。带有感情的外交是幼稚的。这样来看石油价格上涨趋势仍然保持不变。</p><blockquote><p>央行窗口指导银行增配“AA+”以下信用债。（一财） （来自新浪财经APP）</p></blockquote><p>国家开始托债市，否则中小企业的生存就存在明显问题了。中国的信用评级形同虚设，有没有政府兜底才是放贷的最最最重要标准。</p><h3><span id="2018-07-18">2018-07-18</span></h3><blockquote><p>【央行连续释放流动性 专家预计9月份或再降准】继央行16日超预期放水3000亿元之后，17日共释放2400亿元流动性。东方金诚首席宏观分析师王青表示，预计下半年央行还将有1次至2次降准操作，其中9月份可能实施下半年的首次降准。适时降准有助于稳定市场情绪，控制金融体系流动性风险。（证券日报） （来自新浪财经APP）</p></blockquote><p>密切关注央行降准的政策，同时关注美联储的加息政策。</p><blockquote><p>【俄罗斯不再是美国国债的大型持有方】美国5月国际资本净流入 +699亿美元，前值 +1387亿美元修正为 +2331亿美元。美国5月长期资本净流入 +456亿美元，前值 +939亿美元修正为 +940亿美元。中国5月所持美国国债 +12亿美元，至1.18万亿美元。日本5月所持美债 +176亿美元，至1.05万亿美元。 （来自新浪财经APP）</p></blockquote><p>国债规模没有大的变化，说明并没有急于控制汇率。</p><h3><span id="2018-07-16">2018-07-16</span></h3><blockquote><p>【货币政策或有放松空间 未来两个月央行再次降准概率较大】6月社会融资规模增量为1.18万亿元，较上年同期减少5902亿元。人民币贷款增加1.84万亿元，同比多增3054亿元。6月M2货币供应同比增8%，增速创历史新低。业内人士表示，整体来看，6月份信贷放量符合预期，但社融、M2同比均不及预期，表内信贷难以承接表外融资的局面仍在继续，货币仍有进一步放松的空间，未来两个月央行再次降准概率较大。多位业内人士表示，货币结构性宽松趋势有望延续。（经参） （来自新浪财经APP）</p></blockquote><p>在宽松的情况下货币贬值的预期就形成了。</p><h3><span id="2018-07-15">2018-07-15</span></h3><blockquote><p>【社科院张明：房产税的到来可能比预想的还要早】社科院张明于2018国际货币论坛上称，一线城市房价有三种可能：一是不得不放开刚需市场，但由于没有库存，再次暴涨。二是政府会“憋一个大招”，“房产税的到来可能比预想的还要早。”第三种就就是拖，但这不是一个长期的手段。 （来自新浪财经APP）</p></blockquote><p>无疑，应该是第二个选择。</p><blockquote><p>【王国刚：经济降杠杆比较难 甚至稳都稳不住】社科院学部委员王国刚在2018国际货币论坛表示，中国经济去杠杆去不了，降杠杆也比较难，甚至稳都稳不住。王国刚建议，应该优化金融机构和“去杠杆”举措，增加长期负债，减少短期负债，加大长期公司债券发行数量，推进准资本性资金的形成。王国刚建议用负债总额/资产总额计算杠杆率。 （来自新浪财经APP）</p></blockquote><p>有句话叫“解铃还须系铃人”，中国的杠杆是怎么加上去的呢？一方面是在政府、国企、银行之间的默契下加上去的；另一方面则是在美元催动的货币潮水中加上去的。后者已经在通过IPO给自己转杠杆了，这个也不劳国家费心，国家就只要搞好地方债和国有企业债务就好了。最近的定向降准支持债转股，以及允许地方债在二级市场流通都是这个趋势下的结果。其实还有些没存在感的中小民企，入不了大家的法眼，想必日子过得就很不好了。</p><h3><span id="2018-07-14">2018-07-14</span></h3><blockquote><p>面对房地产的调控政策的层层加码，土地市场的火热形势仍然延续。今年上半年，数量众多的三四线城市卖地行情继续向好，成为支撑全国土地出让收入大涨的主要原因。对地方政府而言，一次性卖地收入，是比财政收入更主要的收入来源。仅今年上半年卖地收入就与去年全年地方一般公共预算收入相当（占比超过90%）的城市数量多达14个，绝大部分为非省会的三四线城市。 （来自新浪财经APP）</p></blockquote><p>土地财政最后的疯狂。</p><h3><span id="2018-07-13">2018-07-13</span></h3><blockquote><p><img src="/blog/assets/20180713.png" alt="debt"></p></blockquote><p>融资不够债来补。</p><h3><span id="2018-07-11">2018-07-11</span></h3><blockquote><p>离岸人民币兑美元快速走低， 连续跌破6.65、6.66、6.67、6.68四道关口 ， 目前报6.6839， 刷新7月6日以来新低。</p></blockquote><p>意料之中。</p><blockquote><p>我国对美国大豆加征25%进口关税，将使美国大豆进口成本增加700—800元/吨，较巴西大豆高300元/吨左右。由于加征关税后失去竞争优势，国内企业将大幅减少美国大豆的采购。实际上，截至6月28日，我国已经3周没有新增采购美国大豆，同期累计取消了61.5万吨美国大豆订单。过去20年，全球大豆贸易增幅的85%来自我国，未来我国需求依然是推进全球大豆贸易增加的主要来源，美国豆农将无缘分享我国大豆需求增长带来的红利。</p></blockquote><p>中国也只能承担涨价带来的生活成本增加。</p><blockquote><p>7月8日、9日的两场上市公司座谈会分别由证监会主席刘士余、副主席阎庆民主持召开。在第一天会议上，共有15家上市公司的代表出席，既有中国人寿、中国建筑、中国石油等央企，也有海螺水泥、三一重工等老牌行业龙头，更有科大讯飞、科陆电子等新型产业的代表。有一些央企或是行业龙头集团企业在发言时，表示自己企业一切平稳，并不存在市场所担忧的行业、资金和股权质押问题。然而有少数民营企业则在发言时直诉痛点，表示在新一轮的市场环境之下，企业已经需要直面生存问题。证监会此次收集的上市公司反馈的意见和建议，不排除后续汇报给上层以推动相关政策落地。（21）</p></blockquote><p>无耻的政治。</p><blockquote><p>7月11日，中国社会科学院财经战略研究院专家邹琳华在经济参考报撰文指出，随着棚改货币化安置比例的下降以及三四线城市加入调控行列，2018年下半年二三四线城市房价总体仍将惯性上涨，但涨速将有所下降，局部房价可能出现微降。部分一线城市止跌企稳，在跷跷板效应的作用下，资金可能重回北京等一线城市。北京等一线城市房价有再度上涨的风险，房价调控压力将增大。</p></blockquote><p>言之有理。</p><blockquote><p>特朗普：刚刚与辉瑞首席执行官讨论了我们的药品定价。辉瑞正在抑制价格上涨，因此美国病人不需要支付更多的钱。我们赞赏辉瑞的这一决定，并希望其他公司也这么做。这对美国人民来说是个好消息！（推特）</p></blockquote><p>面对药品公司，川建国也只能认怂。</p><h3><span id="2018-07-10">2018-07-10</span></h3><blockquote><p>商务部、外交部、发展改革委等20部门昨日联合发布《关于扩大进口促进对外贸易平衡发展的意见》，提出在稳定出口国际市场份额的基础上，充分发挥进口对提升消费、调整结构、发展经济、扩大开放的重要作用，推动进口与出口平衡发展。这一重磅文件主要是落实6月13日国务院常务会议提出的相关要求。分析人士认为，由20个政府部门联合发文提出扩大进口意见的做法非常罕见，后续各部委还会陆续出台更加具体细化的政策。（上证报）</p></blockquote><p>中国对外开放已经是趋势了。</p><blockquote><p>央行主管的金融时报刊文称，近期上市公司股权质押风险个案频频出现，其背后大都凸显了个别公司股东激进扩张和“加杠杆”的不当行为，这种现象在当前资本市场属于个案，未呈现风险集中的趋势。从总体上看，股权质押压力最大的上半年时点已过，潜在风险总体可控，各方要理性科学对待这一现象。</p></blockquote><p>一般新闻里提到就已经有所风险了。</p><blockquote><p>证券日报刊文称，现在的A股市场已经处于历史底部，这已是民间和监管层达成的共识，当前的A股市场是信心底。近期监管层对A股市场的表态，就是估值底的由来，也是信心底的重要依据。恢复A股市场的信心不会一蹴而就，这需要时间。监管层喊话有助于市场恢复信心，但扎实推进改革开放发展才是提振市场信心的根本举措。监管层只要按照自己划定的道路前进：统筹考虑研究拟定长远性、基础性制度建设举措，进一步丰富资本市场投资主体，拓宽资金入市渠道，优化资本市场结构，提高资本市场对外开放程度和国际化水平。如此，一个稳健发展的A股市场在不久之后就会呈现在国内外投资者面前。</p></blockquote><p>A股的底是由中国生产力的增长和人民币的坚挺为基础的。</p><blockquote><p>数据显示，6月共有61家信托公司发行了972款集合信托产品，环比微降。与此同时，共有49家信托公司成立了995款集合信托产品，环比上升10.8%，共募集资金1206.76亿元（不包括未公布募集规模的产品），环比劲增38.41%。此外，房地产信托依然是发行市场的绝对生力军。从6月以来的新发行信托产品看，收益率最高的产品中有超过50%是投入到房地产市场的。（证券时报）</p></blockquote><p>房地产的债务基本进入垃圾债的范畴了。</p><blockquote><p>中国人民银行参事盛松成日前参加活动表示，稳健中性的货币政策边际上不应再趋紧。随着金融去杠杆的边际力度下降，预计今年M2增速将高于去年，“我相信会高于8.5%。”对于未来货币政策的走向，盛松成认为，从财政政策来看，今年积极的财政政策并未更加宽松，甚至比去年要紧。（一财）</p></blockquote><p>在债务违约风险加剧的时刻，中国没法执行趋紧的货币政策，也正因此中国的汇率稳定就很难保证了。</p><blockquote><p>据了解，国开行对棚改贷款的收紧只是开始，其他金融机构也将对棚改贷款收紧。（经济观察报）</p></blockquote><p>如果棚改再不收手，那么后果将会换来中国未来20年的失落。</p><h3><span id="2018-07-09">2018-07-09</span></h3><blockquote><p>中国6月外汇储备 31121.3亿美元，预期 31028亿美元，前值 31106.2亿美元。</p></blockquote><p>外汇储备基本保持不变，当然前提是中国仍然对其国民有较严格的外汇管制。</p><blockquote><p>一家名为“中精国投”的私募基金公司，出现严重兑付危机，涉事资金超过18亿元。更令人忧心的是，这家私募背后的实控人“外滩控股”已经人去楼空。而“外滩控股”又系上市公司雷科防务的第二大股东，此前曾爆出股权质押风险。种种迹象表明，事态发展并不乐观。（券商中国）</p></blockquote><p>中国的债务问题在今年应该会有一波<a href="https://www.bloomberg.com/news/articles/2018-07-02/china-heads-for-record-defaults-and-downgrades-tip-further-pain" target="_blank" rel="noopener">爆发</a>。</p><blockquote><p>8日下午，海南省委常委、常务副省长毛超峰率调研组到海航集团调研暑期航空业运行情况，并以电视电话会议形式与海航集团系统进行了座谈。海航集团董事局主席、董事长陈峰就海航集团近期的工作情况和下一步工作计划作了汇报。毛超峰指出，希望海航集团专注航空主业，精益求精、深耕细作，把航空业进一步做大做强。作为海南本土企业，海航集团要抢抓机遇，积极投身海南自由贸易区和中国特色自由贸易港建设。海南省委、省政府对海航集团发展有信心，希望海航集团上下同心，按照既定方案解决集团目前遇到的发展问题。（海南日报）</p></blockquote><p>反过来说，海航还真是不务正业，但这样的企业有多少呢？只有海航一家么？</p><h3><span id="2018-07-08">2018-07-08</span></h3><p>根据最近理解的一些事件和逻辑整理的图。<br><img src="/blog/assets/20180707.png" alt="summary"></p><h3><span id="2018-07-06">2018-07-06</span></h3><blockquote><p>美国东部时间7月5日，美联储公布了其6月货币政策会议纪要，纪要显示与会者总体认为，美国经济已非常强健， 中期来看，通胀将持续处于2%左右，在通胀处于或略高于预期的背景下，适合继续渐进加息。但美联储大多数与会者也表达了对于美国目前贸易政策的担心。很多人提到，贸易政策相关的不确定性和风险可能对商业信心和投资支出有负面影响。（央视记者 王威）</p></blockquote><p>只要市场没有大反应，加息是必然的事件。</p><blockquote><p>经历过2015年及2016年的疯狂、2017年的惨淡后，北京楼市在2018年的“前半场”喜忧参半。虽然新房、土地、房企销售等各项指标仍处于较低水平，但是作为北京楼市风向标的二手房市场，触底反弹，交易量连续四个月超过万套，让寒冷多时的北京房地产市场多了些暖色。（新京报）</p></blockquote><p>回过头来看，这想必也是棚户货币化的结果之一，毕竟最为坚挺的始终是一线城市的房价。</p><h3><span id="2018-07-05">2018-07-05</span></h3><blockquote><p>刚刚过去的6月份，银行理财收益并没有出现“年中反弹行情”，整体表现较为平稳。融360数据显示，6月份银行理财的平均收益率为4.81%，较2月份的最高点4.91%下降了0.1个百分点。分析认为，7月份降准正式实施之后，市场资金流动性将进一步宽松，下半年银行理财的收益率继续走低的概率较大。（经参）</p></blockquote><p>原本以为逆回购利率会比3月更高，但实际观察发现并没有那种反弹出现，基本上可以确定近期货币政策的基调是松的。</p><blockquote><p>美国6月30日当周首次申请失业救济人数 23.1万人，预期 22.5万人，前值 22.7万人；美国6月23日当周续请失业救济人数 173.9万人，预期 171.8万人，前值 170.5万人。</p></blockquote><p>比预期稍微多点。</p><blockquote><p>中国人民银行党委书记、中国银保监会主席郭树清在接受采访时表示，上市公司盈利能力提升，平均估值水平在主要经济体中居于低位。国际投资界普遍认为，中国资本市场已显示出较好的投资价值。上半年，境外资金净流入股票市场1313亿元，境外机构投资者净买入中国政府债3089亿元。信用债市场略有波动，但违约率远低于国际市场平均水平，总体风险完全可控。</p></blockquote><p>结合最近的一些分析，境外直接投资已经成为外汇储备增长的主要动力。这一点与其它新兴市场国家相比越来越接近了，一旦资本流动加快就必然会有牺牲汇率稳定的代价。<a href="https://zh.tradingeconomics.com/china/foreign-direct-investment" target="_blank" rel="noopener">这里</a>有具体数据。</p><p>外商注册的企业数量增加<a href="http://www.ndrc.gov.cn/fzgggz/wzly/wstz/wstzgk/201805/t20180528_887441.html" target="_blank" rel="noopener">迅猛</a>，是一个值得思考的问题。</p><h3><span id="2018-07-04">2018-07-04</span></h3><blockquote><p>因提早收市的美国股市下滑，引发对美国国债的避险买需，令收益率曲线处于近十一年来最平水准。交易商和分析师表示，对全球贸易战全面爆发的担忧引发投资者押注。全球经济增长和通胀放缓，这意味着即使美联储提高短期利率，但美国长债收益率将不会大幅上涨。当前对国债的避险需求缩窄了短期和长期国债收益率之间的差距。一些投资者担心，短债收益率可能高于长债收益率，这现象被称为收益率曲线倒挂，发生在过去五次美国经济衰退之前的大约12至18个月。（路透）</p></blockquote><p><img src="/blog/assets/yield_curve_20180714.png" alt="yield_curve_20180714"><br>从图上看的确在过去的一年里美债收益率曲线在慢慢变平。扁平化的本质是2年收益率上升而10年收益率下降，意味着人们更加倾向购买10年期的国债，而不买短期国债。换句话说，就是资金不看好未来短期的经济形势，所以选择了更为长期的国债作为避险方式。<a href="https://www.thebalance.com/inverted-yield-curve-3305856" target="_blank" rel="noopener">这里</a>讲的更加清楚，提到：</p><blockquote><p>If they believe a recession is coming, they expect the value of the short-term bills to plummet sometime in the next year. They know that the Federal Reserve lowers the fed funds rate when economic growth slows. Short-term Treasury bill yields track the fed funds rate.</p></blockquote><blockquote><p>据国际清算银行的数据显示，欧洲各银行在其资产负债表上隐藏了数千亿美元的高风险交易，仅在报告日期前几天将其转移。同样的问题不会发生在英国或美国的银行身上，因为它们有更好的设计规则。但自从欧洲引入新的、结构糟糕的规则以来，这个问题变得越来越严重。欧洲的银行在报告日期之间增加了在货币市场上的借款，把这些钱在短期内借出以快速获利。在本季度末和年底，当必须拿出自己敞口的快照时，它们就会关闭交易，使它们向欧洲监管机构报告的杠杆水平低于实际水平。</p></blockquote><p>这也可能是促进英国脱欧的原因之一。不得不承认英国有着相当丰富的金融经验，所以更加能防范金融风险。从这个角度，英镑有着比欧元更好的投资价值。</p><blockquote><p>今年以来，美股上市公司正在以前所未有的加速度回购自家股票。上半年美国上市公司累计回购了逾6700亿美元股票，回购规模已超过2017年全年创下的5300亿美元纪录，再创历史新高。在回购等多重利好的刺激下，今年以来，美国三大股指不断刷新历史高位。 值得关注的是，公司通常会在股价较低时回购股票，而美股今年的大幅回购却发生在股价走高时。对此市场分析人士指出，在看好后市的同时，这也是公司试图提振股价的做法之一，后市要警惕回购带来的流动性和债务风险，并密切关注回购放缓后的美股表现。（中国证券报）</p></blockquote><p>这也是经济形势不够景气的体现之一。虽然回购不会对公司业绩有积极正面的促进作用，但也好过盲目投资造成产能过剩，再不济也那些A股公司啥也不作为，或搞搞内幕交易强百倍。</p><blockquote><p>美联储：将于7月13日披露递交给国会山的货币政策报告，美联储主席鲍威尔将出席国会听证会。</p></blockquote><p>密切关注。</p><h3><span id="2018-06-30">2018-06-30</span></h3><blockquote><p>有分析人士称，人民币贬值，主要是因为美元走强，并伴随市场风险偏好和外汇供求力量变化。央行未跟随美国上调公开市场利率，表明人民币贬值依旧可控，风险不会太大，因此央行也选择不干预。当前人民币有效汇率事实上已经贴近均衡汇率，高估压力得到有效释放。四季度人民币汇率可能迎来反转，2018年全年人民币对美元汇率的中枢将稳定在6.3-6.4的位置，双向波动的区间有望在6.2-6.7之内。（证券日报）</p></blockquote><p>这种分析不过混淆视听。</p><h3><span id="2018-06-29">2018-06-29</span></h3><div class="tip"><br>    1. 不再投资正股，除非30%以上的收益<br>    2. 已持有的正股在合适的时机抛出<br>    3. 逢低做多vix<br>    4. 配置一定石油<br></div><h3><span id="2018-06-28">2018-06-28</span></h3><blockquote><p>今年以来，影响类别资产表现的主要因素是量化紧缩，今年是曾经助推资产价格攀升的全球流动性大潮的转向年。据估算，美联储、欧州央行及日本央行今年迄今的证券购买量仅有1250亿美元，远不及2017年1.5万亿美元的规模。此情此景表明，由于决策机构的改弦易辙，市场将会失去大约1.38万亿美元的流动性注入。策略师们预计，未来六到八个月，流动性将会全面萎缩，这也是他们为什么即便在经历了近来的市场下挫后依然对全球股市前景表示悲观的原因之一。</p></blockquote><p>那么正股的风险变得越来越大，而波动性的风险越来越低，只有超过30%的吸引力才足够投资吧。</p><blockquote><p>英国央行副行长Cunliffe：英国央行预计未来几年利率将逐步上行。</p></blockquote><p>流动性下降是全球的趋势。</p><h3><span id="2018-06-27">2018-06-27</span></h3><blockquote><p>报道称美国要求盟友11月4日前将伊朗石油进口量降至零，带动WTI原油大涨3%至70美元/桶关口上方，刷新一个月高位。之前美国制裁要求伊朗原油进口国每六个月把伊朗原油进口量降低20%，现在的要求要严格多了。伊朗每天出口原油约240万桶，主要流向欧洲、中国、印度和土耳其，之后欧洲和土耳其可能会在压力下顺应美国的要求，但中印可就不一定了。若美国计划实现，油市供应将大量减少。目前WTI原油已站上70美元/桶，跨过所有重大技术阻力位，似乎正“走向春天”。</p></blockquote><blockquote><p>法国巴黎银行资深石油策略师Harry Tchilinguirian撰写报告称，在美国输油管限制在2019年得到解决和美国出口扩张到通常由OPEC海湾国家供应的亚洲市场之前，布伦特油价可能会达到80美元/桶之上；未来六个月油价仍将获得支撑；OPEC+的净供应增加仍然不足以改变世界石油市场短缺的局面；由于美国的制裁，伊朗80万桶/日的石油出口可能会在年底之前退出市场。</p></blockquote><p>虽然石油看起来在涨，但情况似乎变得越来越复杂。如果考虑沙特、俄罗斯这两大产油国的态度，估计上涨的概率要低于下跌，可以适当配置一定的石油资产。</p><blockquote><p>据Techcrunch媒体报道，苹果今天凌晨为教师推出一款免费的应用程序——Schoolwork。获悉该款基于云计算的应用程序允许教师在课堂上使用iPad建立以及分发讲义与作业，与学生单独协作，跟踪学生的进步。最值得注意的是，该程序允许教师在各种教育类程序中布置特别的活动。</p></blockquote><p>Ipad从最初一种尴尬的存在，到现在逐渐成为课堂的必备，这是一个不断寻找killer application的过程。pad这种电子产品走到今天，大部分的厂家都已经不赚钱，卖不下去了，而ipad却能找到这个把握年轻人的很好的机会，不得不佩服苹果的洞察力。long apple~</p><blockquote><p>预计年内人民币兑美元汇率或将发生贬值加大的过程，年内破7的概率存在；这一水平符合中国经济阶段需求，人民币兑美元汇率基点在6.6元附近，有利于外贸发展对实体经济以及市场信心的稳固，人民币高估风险需要防范。人民币破7不是坏事，但时机、节奏很重要。人民币升值破6.2不是好事，这一价位不利于中国外贸与经济稳定、持续发展。（中新经纬）</p></blockquote><p>从这里可以清楚看到这就是主动的贬值。</p><h3><span id="2018-06-25">2018-06-25</span></h3><blockquote><p>截至06月24日，上交所融资余额报5581.96亿元，较前一交易日减少26.13亿元；深交所融资余额报3612.69亿元，较前一交易日减少21.95亿元；两市合计9194.65亿元，较前一交易日减少48.07亿元。</p></blockquote><p>最近融资额一直在下降，因此股市也一直在下跌。</p><blockquote><p>快讯：离岸人民币兑美元亚市早盘跌逾150点，报6.5256，连续八天下跌。</p></blockquote><p>人民币的贬值应该是刻意为之。虽然政府严格控制资本流动，但水是堵不住的，压力在不断上涨。7月份是个关键的月份，届时情况可能更加复杂，也可能更加明朗。</p><blockquote><p>日本央行发布6月14-15日政策会议纪要：一位日本央行政策委员称，适宜推进强有力的宽松举措。一位政策委员称，实现通胀目标仍有很长距离。</p></blockquote><p>日本央行没有加息。</p><h3><span id="2018-06-24">2018-06-24</span></h3><blockquote><p>为进一步推进市场化法治化“债转股”，加大对小微企业的支持力度，中国人民银行决定，从2018年7月5日起，下调国有大型商业银行、股份制商业银行、邮政储蓄银行、城市商业银行、非县域农村商业银行、外资银行人民币存款准备金率0.5个百分点。鼓励5家国有大型商业银行和12家股份制商业银行运用定向降准和从市场上募集的资金，按照市场化定价原则实施“债转股”项目。支持“债转股”实施主体真正行使股东权利，参与公司治理，并推动混合所有制改革。定向降准资金不支持“名股实债”和“僵尸企业”的项目。同时，邮政储蓄银行和城市商业银行、非县域农商行等中小银行应将降准资金主要用于小微企业贷款，着力缓解小微企业融资难融资贵问题。 人民银行将继续按照党中央、国务院的统一部署，实施好稳健中性的货币政策，把握好结构性去杠杆的力度和节奏，为高质量发展和供给侧结构性改革营造适宜的货币金融环境。</p></blockquote><p>这次降准是为了两个目标：1. 债转股；2. 微小企业。这两者都很重要，但不知道怎么才能真正实现，而又如何阻止这笔钱流入房地产这样的领域。看有评论说这还是会利好房地产，看看最近几天的股市表现就知道了。另外，贬值是真的，所以配置更多美元资产是一个手段。</p><h3><span id="2018-06-21">2018-06-21</span></h3><blockquote><p>据证券日报，厚生智库研究员赵亚赟称，既要去杠杆，又要防止出现金融危机，央行的选择并不多。6月份是纳税和还贷大月，流动性会吃紧，所以央行会大量释放流动性，严控金融风险。由于贸易战等原因，很多企业奉行现金为王的政策，市场资金压力会非常大，央行近期的货币政策应该会比前几个月更加偏宽松，不排除再次降准。</p></blockquote><p>选择真的不多。。。逆回购可以薅点羊毛，但小钱还是算了。</p><blockquote><p>推迟A股CDR发行之后，小米决定分步先在港交所上市。据接近小米人士获悉，小米很可能于6月21日早上八点在港交所披露更新后的招股书。有消息称，小米计划发行21.8亿股股票，融资规模最多为61亿美元，IPO定价区间在17港元/股至22港元/股。不过以上消息并未得到小米方面确认。有小米内部人士表示，“我们目前还不清楚。”（证券日报）</p></blockquote><p>小米的价格比较公道。</p><blockquote><p>券商统计显示，如果将预警线和平仓线分别设定为150%和130%，截至6月19日收盘，共有619家公司股价接近预警线，其中564家公司跌破预警线；共有425家公司股价接近平仓线，其中353家公司跌破平仓线。整体来看，A股股权质押当前平仓线以下市值规模约为9351亿元。不过，研究机构也指出，目前A股市场股权质押风险整体可控，并不存在系统性风险。（经参）</p></blockquote><p>股权质押这种方式本来就是高风险的，尤其考虑影子银行的操作方式。</p><blockquote><p>据一位券商人士透露，头条新一轮融资正在进行中，云峰基金和KKR正在与头条接洽，不包括抖音，头条估值350亿美元，抖音将独立融资。“目前，抖音估值在80亿美元到100亿美元之间。</p></blockquote><p>抖音的消息据说是谣传，头条估值感觉高了，而抖音感觉还凑合。但抖音这样的公司其护城河是什么呢？感觉只要稍微撒点儿金币，谁都能成长起来。</p><blockquote><p>根据美国财政部6月15日披露的最新数据，持有美国国债的外国当局在今年4月间纷纷减持，在前十大“债主”中，只有巴西和开曼群岛没有减持美国国债。第一和第二大“债主”中国和日本在4月间分别减持58亿和123亿美元，英国、印度、加拿大、韩国、墨西哥、瑞士、爱尔兰等国也加入减持行列。俄罗斯持有美国国债的规模从今年3月的961亿美元下降到4月的487亿美元，一个月内减持超过49.5%。（每日经济新闻）</p></blockquote><p>从二月以来的确在上涨，但似乎影响还是比较有限的。如果这是个趋势，还是应该引起重视。<br><img src="/blog/assets/us10y.jpg" alt="US 10-year Treasury"></p><h3><span id="2018-06-20">2018-06-20</span></h3><blockquote><p>国务院办公厅发布关于调整国务院促进中小企业发展工作领导小组的通知，组长为国务院副总理刘鹤。<br>这意味着有点开始重视中小企业了。</p></blockquote><blockquote><p>美联储主席杰罗姆·鲍威尔表示，从美国经济的角度来看，“联邦基金利率仍然处于宽松的位置，委员会成员们认为，可能比中性利率的估计中值低100个基点”。<br>那么中性利率大概在3.5%左右？</p></blockquote><h3><span id="2018-06-19">2018-06-19</span></h3><blockquote><p>特朗普称，若中国拒绝改变做法，关税举措将生效；上述拟议关税是对中国上周五针对美国关税计划宣布的对500亿美元美国商品征税的回应。特朗普威胁称若中国再次加征关税美国将进一步加征关税。</p></blockquote><p>有趣，周而复始，最终的结果我很好奇！</p><blockquote><p>地方债新增发行已放量。财政部公布最新数据显示，5月份，全国发行地方政府债券3553亿元。其中，新增债券171亿元，置换债券3382亿元。由于全年发行量压力不小，机构普遍预计，二季度将迎来地方债发行高潮。</p></blockquote><p>屋漏偏逢连夜雨，还能说什么呢？必须看好自己的钱袋子。如果你不学习经济，那就等着被别人收割吧。</p><blockquote><p>在岸人民币兑美元跌破6.48关口，最新报6.4815元，创1月份来新低，较上周五夜盘收盘跌465点。离岸人民币兑美元跌破6.49关口，现报6.4915元，创今年1月份来新低，日内跌约370点。</p></blockquote><p>股市、债市、汇市三杀？别人恐惧的时候，你该怎么样呢？</p><h3><span id="2018-06-18">2018-06-18</span></h3><blockquote><p>彭博汇总的数据显示，海外资金正在以2008年全球金融危机以来最快速度撤离亚洲六大新兴股市，今年以来从印度、印度尼西亚、菲律宾、韩国、台湾和泰国撤离的资金总额已达190亿美元。</p></blockquote><p>新兴市场是真的被洗劫了，但这又该怪谁呢？</p><blockquote><p>联合石油数据库JODI：沙特4月原油库存跌99.3万桶至2.3442亿桶；沙特4月原油产量环比跌3.9万桶/日，至986.8万桶/日；沙特4月原油出口增加19万桶/日，至731.2万桶/日；沙特4月对原油产品需求下降15.8万桶/日，至204万桶/日；沙特4月对原油产品出口量下降8.7万桶/日，至166.4万桶/日。</p></blockquote><p>石油价格看起来有点不明朗，沙特和俄罗斯都有限产的意愿，但这会造成一些国家通胀无法控制，所以在政治上可能不允许。注意，石油永远不是一种普通的商品，而是一种政治工具。</p><blockquote><p>近期以来，阿根廷、土耳其和巴西等国的货币出现动荡；阿根廷寻求IMF的援助，巴西因高油价引发了全国范围的罢工。而美联储正在加息路径上，对这些高负债国家构成实质压力，其货币相对美元出现贬值的情况下尤为如此。潜在伴随而来的经济衰退可能会降低对石油的需求；此外，石油的需求端也存在不稳定因素；今年5月，因为油价高企，国际能源署将石油需求下调了10万桶/日。同时，新兴市场的经济可能出现放缓，这可能拖累石油需求增长。</p></blockquote><p>受伤的总是新兴市场国家。</p><blockquote><p>OPEC据悉讨论将产量提高30-60万桶/日，沙特、俄罗斯致力于达成永久性石油联盟。（彭博）</p></blockquote><p>在利益面前哪里有永远的敌人。</p><h3><span id="2018-06-14">2018-06-14</span></h3><blockquote><p>① 从2019年1月开始，将在每次FOMC政策会议结束时举行新闻发布会，以改善沟通。 ② 前两轮周期是因为金融稳定性而结束，而不是因为通胀的缘故。 ③ 通胀处于2%目标附近，希望观察这是否具有可持续性；承诺维持2%的通胀目标。 ④ 不寻求美联储在贸易政策上发挥作用。 ⑤ 主要结论是，美国经济形势“非常不错”。 ⑥ 预计减税将带来三年“实质性支撑”。 ⑦ 现在变更前瞻指引正当其时。 ⑧ 不会置评金融风险是否高于正常水平。</p></blockquote><div class="tip"><br>联邦公开市场委员会(The Federal Open Market Committee )，简称FOMC。<br></div><p>鲍威尔真是个政治家，从而他的发言很少有真正有价值的内容。实际上美联储就考虑三个方面：1. 股市不暴跌；2. 失业率不飙升；3. 通胀不低于2%，就会加息。</p><blockquote><p>近期信用债市场违约事件增多，多家上市公司现身其中，引发各方关注。在业界看来，“打破刚兑”已逐渐成为债市参与各方的共识，但在信用债违约处置方面，“最后一公里”仍待打通。（经参）</p></blockquote><p>债市违约正是金融风险的一项指标。</p><blockquote><p>恒大研究院任泽平发文称，5月金融数据显示，M1同比增6%，环比再降1.2pct，M2同比增8.3%，环比持平。M1增速创2015年7月以来新低，印证企业融资压力，M2增速继续保持8.3%水平。存款方面，表外回表趋势下，银行存款增速基本保持平稳，5月存款新增1.3万亿元，同比多增1900亿元，存款余额同比增8.9%，存款准备金相对保持充沛，为后续降准留有充足空间。</p></blockquote><p>M1和M2增速用同比，而存款用同比，这其中是有什么不方便说的么？8.3%的M2增速，和6.5%的GDP增速预期之间存在什么关联呢？又与通货膨胀有什么关联呢？</p><blockquote><p>国家统计局新闻发言人毛盛勇在发布会上表示，固定资产投资1-5月份增长了6.1%，比1-4月份回落了0.9个百分点。固定资产投资回落主要是基础设施投资所致。1-5月份制造业投资增长5.2%，加快0.4个百分点；房地产投资增长10.2%，小幅回落0.1个百分点；基础设施投资增长9.4%，回落3个百分点。现在三大攻坚战当中要防范化解重大风险，包括对不合规、不合法项目要进行规范和清理，要求地方融资行为、举债行为更加规范，因此，对资金的空间，以及有些项目因为不合规不合法停建、缓建带来了一些影响。</p></blockquote><p>房地产的投资增长亮眼！天天喊要各种规范，而法规政策在哪里呢？如果地方政府没有动力减少房地产收入，靠什么真正去压制房价呢？</p><blockquote><p>这些突出问题是：一是自我革命本身意味着存在许多特有的困难。这就需要刮骨疗伤，壮士断腕的态度。二是道德风险根深蒂固。相当多的金融机构仍然存在“垒大户”情结，不少企业高度依赖债务投入，各类隐性担保和“刚性兑付”没有真正打破，“预算软约束”“投资饥渴症”问题仍然比较突出，特别是市场化、法治化破产机制远未形成。三是一些地方部门、银行和企业缺乏应有的紧迫感和危机意识，对去产能、去杠杆心存侥幸。四是平衡各方利益面临很多制约。随着改革不断向纵深推进，兼顾多重利益的难度越来越大，调整越来越困难，有待于各个方面付出更大的努力。</p></blockquote><p>刮别人的骨，断别人的腕？难道要机构自己去主动承担风险吗？之所以垒大户，还不是因为一旦户大了就有国家在兜底么？Too big to fall!</p><blockquote><p>一位拒绝透露姓名的国有银行经理向中国日报表示，其所在银行已获得额外配额，预计资金将于6月底前发放，以支持非金融部门。</p></blockquote><p>呵呵，看来牌桌下还有只看不见的手。</p><blockquote><p>证监会副主席方星海：从国际竞争格局看，也要加快上海国际金融中心建设，我们设想一下，如果全球的企业都到上海来融资，那么今后谁制裁谁都很难说了。</p></blockquote><p>引用新浪财经上网友的评论：睁着眼睛说瞎话！为啥全球的企业要来上海融资？是上海的资金量很充沛？还是资金进出中国很方便？</p><blockquote><p>今日在“2018年陆家嘴论坛”上，中国人民银行党委书记、中国银行保险监督管理委员会主席郭树清示，今年来针对房地产贷款、地方政府债务和互联网金融等系统性风险隐患较大的领域，设定了审慎监管指标，开展压力测试，加强清理规范，及早介入干预，有效遏制了风险的累积。</p></blockquote><p>在金融风险面前，任何手段都不如倒腾房地产，这在过去10年里已经无数次被证明了。那么，现在该买哪只股票呢？你猜。</p><blockquote><p>郭树清: 不必担忧金融业开放会冲击中国金融市场。治理金融风险隐患必须考虑市场承受能力。银行体系内逾期90天以上的贷款占比从120%降到了100%。</p></blockquote><p>中央的新闻总是要反着看会比较真实。</p><blockquote><p>欧洲央行声明：每月300亿欧元的资产购买规模将持续到9月份；QE将在12月份结束。10月份至12月的月度购债规模为150亿欧元。将保持利率不变至少至2019年夏天。</p></blockquote><p>年底欧洲会退出QE，那么接下来会发生什么事情呢？当潮水退下，那个没有穿底裤的人会是谁？从而想到为啥国内的各种科技公司都在加快上市的节奏呢，因为需要有人来接盘了。</p><blockquote><p>小米将于6月23日举行全球发售股份的新闻发布会；一般情况下，新股新闻发布会下一个交易日将启动招股，即6月25日起招股。（香港经济日报）</p></blockquote><p>需要密切关注小米的IPO。</p><h3><span id="2018-06-11">2018-06-11</span></h3><blockquote><p>6月14日即将公布美联储议息会议最新利率决议，市场普遍预期此次美联储加息的可能性较大。苏宁金融研究院宏观经济中心主任、高级研究员黄志龙表示，不排除美联储加息之后，中国央行可能跟进调整公开市场操作利率，以维持美元升值趋势下人民币汇率的相对稳定，管控人民币贬值预期进一步加大。另外，从国内经济来看，降准、加息的政策操作组合可能会成为下半年央行保持稳健中性货币政策选项之一。（证券日报）</p></blockquote><p>美联储的下一次加息即将到来，但市场上对于多次加息的反应已经越来越麻木，仿佛这并不意味着任何特别的事情，这正是问题所在。</p><blockquote><p>尽管降准并没有在预期中到来，但各界坚信，当下实体经济稳中向好的态势以及金融市场生态环境的改善都需要央行在货币政策层面给予适时适度的支持。也就是说，降准可能会迟到，但绝不会缺席。高企的存款准备金率仍有进一步下调空间，但央行下调的过程将是谨慎的。未来流动性将会继续注入小微企业、绿色经济等领域。今年以来金融市场、资本市场波动加大，也需要货币政策给予必要的支持。在全国经济一盘棋、金融市场与资本市场联动的大框架下，货币政策应该更敏感一些，反应更快速一些。</p></blockquote><p>加息和降准本就是两面，在单方面降准改成加息的时刻，却去讨论这样的话题，不知道其心究竟想达到什么样的特殊目的呢?</p><h3><span id="2018-06-09">2018-06-09</span></h3><blockquote><p>兴业银行、华福证券首席经济学家鲁政委和兴业研究公司研究员何津津表示，中国央行6月份仍将大概率跟随美联储加息，但对市场利率影响或有限，需要关注金融市场的波动可能对具体政策落地时间点的影响。预计中国年内仍会有降准操作，同时MLF操作仍会延续。（证券日报）</p></blockquote><p>央行也终于要开始加息了，这对于本来就脆弱的金融市场可绝对不是一件好事，拭目以待，开始保持低仓位，没有好的标的绝不轻易出手。</p><h3><span id="2018-06-08">2018-06-08</span></h3><blockquote><p>记者调查发现，个别银行已在全北京范围内将首套按揭房贷利率抬升至基准利率的1.3倍，另有至少5家股份制银行的网点员工透露“额度不多”、“今年基本暂停接单”，甚至直接建议询问国有大行。业内人士分析称，中小银行减少房贷业务是因资金成本偏高，个人申请房贷利率仍有上行空间。（北京商报）</p></blockquote><p>在中国总有个特色，如果一件事情非常难做到，那么那必然意味着利润，房子也是这样的。</p><blockquote><p>截至昨日，内地及香港上市房企中已经有22家公司公布了前五月的销售数据。1-5月，销售金额合计达到1.69万亿元，同比上涨约35%。5月份，大部分龙头企业销售业绩乐观，22家房企销售收入达到了3515.7亿元。（中证报）</p></blockquote><p>去库存进入尾声，按照过去的经验，这将是下一轮调控和涨价。</p><blockquote><p>美国总统特朗普发布推文称，为什么欧盟和加拿大没有告诉公众，多年来他们对美国采用了大规模的贸易关税和非货币贸易壁垒，这对我们的农民，工人和公司是完全不公平的。取消你的关税和障碍，否则我们会比你更多！</p></blockquote><p>美国与加拿大难得如此互相指责。</p><blockquote><p>据悉，中兴通讯董事长、CEO、CTO都将更换，可能还要更换部分执行副总裁（EVP）。中兴很有可能将成为中国首个国企体制，但美国政府监督的全球科技公司。（《财经》）</p></blockquote><p>新时代的买办公司。</p><blockquote><p>【深交所：进一步完善重大违法强制退市实施制度】深交所表示，进一步完善重大违法强制退市实施制度，优化财务类和市场类退市指标体系，对持续经营能力存疑或存在重大不确定事项的高风险公司加大风险警示力度，不断夯实制度基础，防范系统性金融风险，促进深市多层次资本市场健康稳定发展。</p></blockquote><p>越是要加强金融风险控制，不正是意味着风险较大么？综合各个方面的指标和政策，个人觉得危机已经快来临了，当然这个快也并不是一两个月，而是可能在未来的一两年内。</p><h3><span id="2018-06-07">2018-06-07</span></h3><blockquote><p>在今日商务部召开例行新闻发布会上，外媒记者向发言人提问：“华尔街日报的消息说，中国提出来，如果美方放弃新的进口关税，中方愿意购买近700亿美元的农业制造和能源产品，请问这个消息是不是真的？”对此，商务部新闻发言人高峰表示：中美双方在上周末的磋商中，就一些具体的贸易合作领域，特别是农产品、能源领域进行了深入、具体的探讨；中方愿意在相向而行的前提下，扩大自美进口。</p></blockquote><p>这个消息恐怕是真的。</p><blockquote><p>美国商务部部长罗斯表示，美国与中兴达成协议；将对中兴通讯罚款10亿美元；中兴通讯必须30天内更换董事会和管理层；美国将会挑选人员进入中兴通讯的合规团队。（万得）</p></blockquote><p>中兴成为了一个被美国直接监管的国企。</p><blockquote><p>“股神”巴菲特：自己现在是股票市场的净买入者；打赌欧元将在未来十年继续存在；对股市的决策应该独立于当前的商业前景；毫无疑问，美国将在未来10年、20年和30年遥遥领先。</p></blockquote><p>美国的确有资格引领未来的10年、20年，但未必是30年，而且这个差距必然是在缩小的。</p><blockquote><p>桥水基金开始做空大批金融资产，认为金融危机已经快来临了，其核心指标如下：</p></blockquote><div class="tip"><br>1.资金正在以2008年金融危机以来前所未见的速度从股市中抽离；<br><br>2.穆迪$(MCO)$警告，垃圾债券违约的大浪潮正在来临。垃圾债券通常可以视作是大的金融危机到来前的预警信号；<br><br>3.联邦存款保险公司（FDIC）数据显示，一个被市场密切关注的指标——银行不良资产规模在2018年第一季度扩大了3倍，这意味着一些较大规模的银行正处在资产不良的区间；<br><br>4.今年美国债券的开局表现是大萧条以来的最糟糕的一次；<br><br>5.抵押贷款利率创出了7年新高，同时这一利率正在以50年来最快的速度增长，这对于房地产行业而言绝对是一个灾难；<br><br>6.零售行业债务违约率在2018年创了历史新高；<br><br>7.目前正处在零售商店关闭情况最糟糕的一年；<br><br>8.全球最大的两个经济体贸易摩擦仍在继续；<br><br>9.世界第九大经济体意大利正面临着金融体系的崩溃，事实上这还不是最糟糕的，因为不排除意大利困局的负面影响可能会传导至欧元区的其他国家；<br><br>10.意大利的银行类股近期出现了大幅的下跌；<br><br>11.意大利10年债券收益率创出了2014年以来的最高水平；<br><br>12.德国银行巨头德意志银行$(DB)$近期宣布将会裁员7000名以寻求扭亏为盈，事实上德意志银行已经连续亏损多年，如果2018年德意志银行破产的话从本质上而言只是让市场见证了另一雷曼兄弟倒闭。<br></div><blockquote><p>德意志银行计划今年把员工数量裁减至93000人以下。</p></blockquote><p>果然德意志银行存在问题。</p><h3><span id="2018-06-06">2018-06-06</span></h3><blockquote><p>近期碧桂园、富力地产、合生创展等多家房企发债中止，引发市场在流动性紧张背景下的担忧。专家预计，今年下半年会有较多的中小房企违约风险事件发生，中小房企或加速退出市场，行业集中度提升速度料进一步加快。与此同时，众多房企亦在探索新融资模式。（中证报）</p></blockquote><p>房地产的上涨不是政府能随意操控的，释放出的几万亿如洪水猛兽，无法简单的遏制。正如当年大禹治水，不能靠堵，而是要疏导。而这个疏导的出口在哪呢？是非常有价值的问题！</p><h3><span id="2018-06-05">2018-06-05</span></h3><blockquote><p>可以断言，房产税一旦开征，整个社会对于楼市未来走向的预期必然逆转。拥有大量房产的人一定会积极抛售多余的房子，而有了房子的人再也不会把房子当做最佳投资品而想着要去多买几套。楼市供求格局大变也就势在必然。政策与其抡起大棒直接朝房价砸下去，还不如尽快把房产税推出来。</p></blockquote><p>得出这样的结论，不是蠢就是坏！房产税的拐点在于税收的量可以超过今天靠卖地的土地财政，而不是为了平均分配房子。</p><h3><span id="2018-06-03">2018-06-03</span></h3><blockquote><p>今日，今日头条官方表示，腾讯利用垄断地位以各种理由、多次进行不正当竞争的行为。针对其中的“腾讯QQ空间拦截、屏蔽头条网页链接” “腾讯安全管家作为安全软件拦截、屏蔽头条网页链接”，今日头条已经起诉腾讯，目前两案都已于6月1日获得海淀区人民法院立案相关证据都已经提供给法院，详见起诉状。</p></blockquote><p>如果头条可以成功，那么阿里为什么不这么做呢？而且头条的形象还不如阿里正面，感觉在今天的中国，这只是引起人们注意的一种方式而已。</p><h3><span id="2018-05-31">2018-05-31</span></h3><blockquote><p>消息人士透露，美国有99.9%的可能性将对加拿大、墨西哥和欧盟征收钢铝关税，决定将很快做出。（CNBC）</p></blockquote><p>有趣，这是在声东击西吗？这个西又是什么呢？</p><h3><span id="2018-05-30">2018-05-30</span></h3><blockquote><p>白宫周二在声明中表示，美国将对500亿美元含有“重要工业技术”的中国进口商品加征25%的关税，包括与“中国制造2025”相关的技术。最终清单将在6月15日之前公布，关税将在此后不久施行。</p></blockquote><p>美国政府的内部似乎已经很难达成一种相对一致的意见，这在过去一段时间内已经充分体现出来了。</p><h3><span id="2018-05-25">2018-05-25</span></h3><blockquote><p>朝鲜副外相金桂冠称，朝方愿意在任何时候与美国对话。特朗普取消美朝峰会的决定与全世界的希望相悖。朝鲜最高领导人金正恩已尽最大努力，来与特朗普会谈。（朝中社）</p></blockquote><p>朝鲜问题如果圆满解决，那么美国在日韩驻军的合法性就存在问题了，那么现在美国掌权的保守主义还能开心吗？所以即使特朗普非常希望在自己的政绩上加上一笔，但也要那些人点头才行。</p><h3><span id="2018-05-24">2018-05-24</span></h3><blockquote><p>俄罗斯能源部长：将在6月讨论逐步恢复原油产量，预计2018年油价均价将在60美元/桶上方。</p></blockquote><p>俄罗斯原本是希望油价上涨的，但在一些其它目标的驱动下主动放弃了短期的利益。</p><h3><span id="2018-05-23">2018-05-23</span></h3><blockquote><p>据香港经济日报报道，香港改革上市制度后，再有巨型新经济企业拟到港上市。内地最大网约车平台“滴滴出行”最快下半年启动上市，已初步决定落户香港，并考虑不同上市架构，不排除以同股不同权形式上市。消息称，滴滴正积极寻觅主要投资者，询价相当约估值约550亿美元，与去年底最新一轮融资时估值相若，预计滴滴最终上市时市值或能达700亿至800亿美元，随时超越全球另一网约车龙头Uber的约700亿美元估值。</p></blockquote><p>这是个做空的好机会。</p><blockquote><p>我国养老保险基金支出规模仍在快速增加。人社部21日发布的《2017年度人力资源和社会保障事业发展统计公报》显示，2017年职工基本养老保险基金总支出38052亿元，同比增长19.5%，相比2013年的18470亿元增长106%，这意味着近四年职工养老保险基金支出翻了一倍多。此外，基金征缴收入与基金支出缺口持续扩大，制度对于财政补助资金的依赖程度不断提高。</p></blockquote><p>必须自己考虑自己的养老问题。</p><blockquote><p>据华尔街日报：改革多德弗兰克法案的议案以258-159的票数获得众议院通过。改革多德弗兰克法案的议案旨在减少金融危机后对小型银行与社区银行所实施的监管限制。</p></blockquote><p>民粹主义开始流行起来了，金融危机的伏笔各种显现。</p><blockquote><p>房企供应链ABS井喷，规模已达782亿元，至少14家公司涉足以解资金之渴。近日有消息称，恒大拟于5月23日左右发行供应链ABS，由深交所发行。据悉，恒大已获100亿元储架发行额度，期限不超过1年，第一期规模约10亿元。</p></blockquote><p>房企没钱了，但后续会怎么发展呢？</p><blockquote><p>阿根廷央行维持七天回购利率在40.00%不变。</p></blockquote><p>阿根廷金融危机已经爆发。</p><blockquote><p>欧盟委员会：若当前宽松货币政策立场逆转，意大利可能出现风险。由于最近的政策措施和不利的人口趋势，意大利的长期财政可持续性也在减弱。意大利的中期可持续性风险仍然很高，因结构性初步盈余不足以促成公共债务迅速减少。短期内意大利面临的再融资风险似乎有限，主要因市场流动性充裕以及外部环境改善。</p></blockquote><p>意大利总是火药桶的角色。</p><blockquote><p>土耳其里拉兑美元下跌超过3%，跌破4.81里拉。<br>土耳其10年期国债收益率升至15.30%</p></blockquote><p>土耳其经融危机已经爆发。在美元环流的影响下，这些当年无节制借钱的国家很快就尝到苦果了。</p><blockquote><p>意大利5年期信用违约掉期（CDS）升至152个基点，触及近12个月以来最高。</p></blockquote><p>违约掉期上涨意味着大家一致觉得会出现违约。</p><h3><span id="2018-05-21">2018-05-21</span></h3><blockquote><p>央行《一季度货币政策执行报告》在宏观杠杆率、未来货币政策侧重点、金融监管思路转变等方面的表述，与以往有着“明显”不同。宏观杠杆率方面，提出“宏观杠杆率增速放缓，金融体系控制内部杠杆取得阶段性成效”，一改以往强调积极推进“去杠杆”的表述；未来货币政策侧重点方面，将“去杠杆”调整为“调结构”；金融监管思路转变方面，删去“统筹政策力度和节奏，防止叠加共振”，新增“全面清理整顿金融秩序”。“这不免让一些金融机构认为，随着去杠杆接近尾声，各部门金融严监管政策协调力度相对减弱，货币政策侧重点开始转向调结构促经济发展，未来货币政策存在趋松空间，资金流动性较一季度更加宽裕。”某股份制银行信贷部主管表示。</p></blockquote><p>去完杠杆是否会走入下一轮调控？这个恶性循环能否被打破？</p><h3><span id="2018-05-20">2018-05-20</span></h3><blockquote><p>《中美联合声明》<br>   双方同意，将采取有效措施实质性减少美对华货物贸易逆差。为满足中国人民不断增长的消费需求和促进高质量经济发展，中方将大量增加自美购买商品和服务。这也有助于美国经济增长和就业。<br>　　双方同意有意义地增加美国农产品和能源出口，美方将派团赴华讨论具体事项。<br>　　双方就扩大制造业产品和服务贸易进行了讨论，就创造有利条件增加上述领域的贸易达成共识。<br>　　双方高度重视知识产权保护，同意加强合作。中方将推进包括《专利法》在内的相关法律法规修订工作。<br>　　双方同意鼓励双向投资，将努力创造公平竞争营商环境。<br>　　双方同意继续就此保持高层沟通，积极寻求解决各自关注的经贸问题</p></blockquote><p>按照宋鸿兵的解读：美方真正获得利益方首推华尔街金融业，其次是制药公司，再是农业。中国的金融开放如何避免风险？这将是未来一段时间要观察的要点。农业的打击可能很深远，这对中国社会将会产生什么影响？制药公司会不断制造焦虑，中国人真是多灾多难，在任何一个最基础的需求上挣扎着。</p><h3><span id="2018-05-19">2018-05-19</span></h3><blockquote><p>【易方达基金詹余引：接近50%的公募基金投资者持有时间在一年以内】 易方达基金公司董事长詹余引19日在“2018清华五道口全球金融论坛”上表示，现在公募基金的投资者持股是比较短期的，有数据显示，持有单只基金超过5年的投资者大概只有12%左右，有45%到50%的投资者持有时间只在一年以内，投资者的结构会影响基金投资理念的发挥。（中国证券网）</p></blockquote><p>这个统计无情的批判着各种价值投机者。银行螺丝钉的粉丝自从指数下降以后明显就不热情了，之前可是各种价值投资理论烂熟于胸的。</p><blockquote><p>【央行研究局局长徐忠：防范金融风险和经济转型，要提高资产回报率】中国人民银行研究局局长徐忠表示，未来3-5年，中国经济主要把握两条主线：一是经济转型，要从高速增长向高质量发展，要提高全要素生产率；二是防范金融风险。发达国家货币政策也在做结构性改革，全球金融危机以后十年，主要经济体谁的结构性改革走到前面谁走的好，可能对今后二十年全球经济格局的演变有非常重要的作用。提高资产的回报率、提高全要素生产率，是经济转型的需要，也是防范风险的需要。（21世纪经济报道）</p></blockquote><p>“提高资产回报率”这不正好是要投资资产的机会吗？</p><h3><span id="2018-05-18">2018-05-18</span></h3><blockquote><p>近期有关部门召集部分券商进行座谈，就股票质押式回购业务风控、两融绕标套现融资等具体问题展开了讨论。据悉。有关部门在会上叫停了两融绕标套现融资的操作模式，再次强调了股票质押违约处置的流程，要求各家公司控制集中度，并督促各家券商谨慎开展股票质押式回购业务，不得低价竞争，促进行业良性发展。（上证报）</p></blockquote><p>影子银行的控制只能通过座谈？</p><blockquote><p>法国总统马克龙：将维护法国企业的合法权益。欧洲将采取报复措施来捍卫自己的利益。即将召开关于伊朗导弹项目和地区活动的会谈。确认欧洲将维护伊核协议的成果。</p></blockquote><p>马克龙还需要真正做点事情。</p><h3><span id="2018-05-15">2018-05-15</span></h3><blockquote><p>人民日报海外版头版评论文章称，中国将继续坚持对外开放基本国策，坚定不移地推进经济全球化、贸易投资自由化。预计未来五年，中国货物进口额累计超过10万亿美元，对外投资超过1万亿美元，出境旅游人数超过7亿人次，出国留学人员超过350万人，提交PCT国际专利申请量超过30万件。中国发展，世界受益；中国扩大开放，助力世界繁荣。</p></blockquote><p>真正的开放是中国的企业走出去，而不是外国的企业走进来，尤其是金融企业。</p><blockquote><p>美国驻华大使Branstad：特朗普希望大幅度增加对中国的农产品出口。（彭博）</p></blockquote><p>特朗普的希望马上就会成真，只是苦了中国的农民补贴了美国的农民。</p><blockquote><p>美国商务部长威尔伯罗斯美国东部时间5月14日表示，愿意尽快改变对中国手机制造商中兴通讯的销售禁令，此前一天美国总统特朗普表示，要求美国商务部帮助中兴通讯恢复运营。“中兴确实做了一些不合适的事情。 他们已经承认这一点”。罗斯在美国全国新闻俱乐部的活动中说。 “问题是：我们最初提出的措施是否有其他替代方案？ 这将是我们将非常、非常迅速地研究的地方。”（央视）</p></blockquote><p>说谎的最高境界就是明目张胆的说谎，但没有人敢站出来说不。</p><blockquote><p>隔夜纽约原油期货上涨0.4%，收于每桶70.96美元，而布伦特原油收涨1.4%，自2014年底以来首次升至每桶78美元上方。50多名巴勒斯坦人在抗议美国驻耶路撒冷大使馆开馆典礼时遇害，凸显该地区的紧张局势；一周前，特朗普政府重新恢复对OPEC第三大原油生产国伊朗的制裁。</p></blockquote><p>油价节节攀升。</p><h3><span id="2018-05-14">2018-05-14</span></h3><blockquote><p>近两个月楼市出现升温迹象，成交量环比上升，新房价格环比涨幅有所扩大。面对楼市新变化，近半月，住建部约谈12个城市并再次强调楼市调控目标不变，各地楼市再次迎来调控密集期。（中国新闻网）</p></blockquote><p>一轮又一轮，这样做真的有意思吗？</p><blockquote><p>特朗普发推称：我们正在为中兴通讯提供一种快速恢复业务的途径。（因中兴业务无法正常开展使得）中国有太多的工作岗位流失，我已告知商务部要尽快完成这项工作。</p></blockquote><p>中兴柳暗花明。哎，实际上制裁中心美国的芯片公司会损失惨重，那么中兴可能被制裁吗？</p><h3><span id="2018-05-11">2018-05-11</span></h3><blockquote><p>特朗普：将于6月12日在新加坡会见朝鲜领导人金正恩。</p></blockquote><p>时间敲定，但美国必然是没有诚意的。</p><h3><span id="2018-05-10">2018-05-10</span></h3><blockquote><p>去年“317新政”后，北京二手房成交量和成交价持续走低。近两个月以来，北京二手房交易量出现回升，价格趋稳。有分析称，这只是朝着正常交易水平恢复而已，过热并未出现，市场仍旧稳定。（中新网）</p></blockquote><p>压抑资本的投资需求是难以为继的。</p><blockquote><p>美国能源调查公司Rystad Energy：美国重新实施对伊朗的制裁，将导致伊朗原油出口量到今年11月减少70万桶/日。</p></blockquote><p>制裁伊朗的一个重要结果就是要提升石油价格，这符合沙特的预期。</p><blockquote><p>美国WTI 6月原油期货实盘价格周三收涨2.08美元，涨幅3%，报71.14美元/桶。</p></blockquote><p>石油这种大宗商品能跳涨3%算是少有的了。</p><blockquote><p>美国财政部拍卖250亿美元10年期国债，得标利率2.995%、创2014年1月份以来新高，投标倍数2.56、前次为2.46。</p></blockquote><p>10年国债利率在上涨。</p><blockquote><p>沙特能源大臣：美国决定退出伊朗核协议之后，确认沙特出于对产油国和石油消费者利益的考虑而维持原油市场稳定性的承诺。 与OPEC轮值主席国、俄罗斯、以及美国保持密切联系，未来数日，沙特还将接触其他产油国和重要消费者，以确保市场稳定。</p></blockquote><p>沙特的内心里充满了微笑。</p><blockquote><p>美国能源信息署（EIA）：美国5月4日当周EIA石油产出1070万桶/日，创单周历史新高。</p></blockquote><p>美国的页岩油也在欢庆量价提升。</p><h3><span id="2018-05-09">2018-05-09</span></h3><blockquote><p>德国外长：特朗普退出伊朗核协议的决定不算太令人意外。 我们将与盟友一起努力阻止中东局势升级。 我们的目标是继续维持伊朗核协议，协议是有效的。 我们呼吁伊朗坚持核协议下做出的承诺。 我们将留意美国退出伊核协议给企业带来的影响，并考虑欧洲的整体应对措施。</p></blockquote><p>按照鸿学院的分析，伊朗目前来看是走着最保守的路，也不是美国、以色列、沙特希望他走的路。在美国金融制裁的压力下，未来会发生什么变数呢？拭目以待，这可能是近10年最大的一场政治风波。不过，石油看来要涨。</p><h3><span id="2018-05-08">2018-05-08</span></h3><blockquote><p>美国东部时间5月7日下午，白宫称中共中央政治局委员、中国国务院副总理刘鹤将于下周访问美国首都华盛顿，与美国经贸官员继续举行经贸磋商。（财新）</p></blockquote><p>关注谈判局势。</p><blockquote><p>纽约原油跳水跌超3%，因为外媒报道美国总统特朗普可能将不会退出伊朗核协议。</p></blockquote><p>石油居然能在极短时间大幅跳水，有趣。</p><blockquote><p>美国总统特朗普：周二（5月8日）当地时间14:00（北京时间周三02:00）将宣布伊朗核协议决定。</p></blockquote><p>不出意外肯定退出。</p><blockquote><p>意大利五星运动党党首Di Maio：五星运动党不会支持中性政府，呼吁7月份大选。</p></blockquote><p>如果五星运动无法达到足够的选票比例，看起来意大利大选将毫无意义的一轮又一轮。</p><blockquote><p>京东第一季度调整后每ADS收益0.71元人民币，市场预期0.82元人民币。 第一季度营收1001亿元人民币，市场预期989.9亿元人民币。 第一季度商品交易总额（GMV）3,302亿元人民币。 京东预计第二季度营收1200亿~1240亿元人民币，市场预期1223.9亿元人民币。 京东预计全年营收增长29%~33%。</p></blockquote><p>不及预期，跌吧。经过这么多年，京东真的应该证明自己有足够强的护城河和盈利能力，否则这么多钱砸进去，出来个啥呢？只为改善人们生活？</p><h3><span id="2018-05-04">2018-05-04</span></h3><blockquote><p>鸿学院有关芯片问题的讨论。</p></blockquote><p>中国人普遍的系统性思维不足。</p><p>美国推行单边的强权政治导致规矩的破坏，不守规矩会导致维护成本上升，芯片的成本必然上升。</p><p>凡是地大物博的国家都比较粗放，难以形成所谓的“匠人”。</p><p>美国是谈判的高手，可以无中生有制造筹码。</p><blockquote><p>阿里巴巴大肆收购引发投资者疑虑，担忧其盈利能力或遭遇冲击。随着利润和收入增长放缓，阿里巴巴频频收购的行为或终于开始令其盈利受到影响。而该公司市值相比高点损失610亿美元，也反映了投资者的不满情绪。</p></blockquote><p>最近一段时间阿里的表现毫无亮点，护城河上毫无建树，反倒马云天天在国际上各种呼吁。</p><h3><span id="2018-04-23">2018-04-23</span></h3><blockquote><p>分析人士认为，此次海南发布的限购政策，条件异常苛刻，包含户籍、社保、贷款、年限等多重调控手段，这意味着外地新增炒房资金在数年内几乎无法进入海南楼市，前几年流入海南楼市的数千亿炒房资金面临着被“关门打狗”的尴尬局面。易居研究院智库中心研究总监严跃进指出，从限购的广度来说，较其他城市因城施策不一样，海南省全域限购是非常罕见的。（每经）</p></blockquote><p>中国人对房地产的狂热是过去十多年来培养出来的，政府一遍遍惩罚那些没有买房的人，不断去强化房子必须涨价的预期，才造成了像现在这种现象。要纠正这种情况，不可能通过限购，限购只是为了降低房价的杠杆，减少系统风险。</p><blockquote><p>这一建议初听让人热血沸腾，但冷静思考发现，它并不可行，甚至很危险。产业化的芯片业与“两弹一星”服从完全不同的经济规律。夸大“两弹一星”中的独立自主和人定胜天因素，并据此不计成本、闭门发展芯片业，更是有陷入过度社会动员的风险。脱离常识，一门心思想着弯道超车恐怕是欲速而不达。守正出奇才是正确的态度。产业环境和社会人文环境改善了，规模大了，基础厚实了，逆袭才有可能发生。真正的国家意志应该是创造环境，培植基础，而非亲自去做逆袭的计划，逆袭意志的主体只能是企业，并且是民营企业。</p></blockquote><p>两弹一星中领军人员与一线国家的差距要更小，而且只是一锤子买卖，而芯片如果没法赚钱，是不可能不计成本烧钱的。</p><blockquote><p>近期网约车在多城市开展“烧钱大战”引发社会强烈反响。针对这一现象，交通运输部微信号近期连发三篇评论性文章，指出“烧钱大战”不可持续，呼吁网约车发展要“脱虚向实”，运输市场要公平竞争。（中国交通报）</p></blockquote><p>再多的钱也烧不了多久了，赚司机的辛苦钱，是支撑不了成千上万码农的工资的。</p><h3><span id="2018-04-22">2018-04-22</span></h3><blockquote><p>刚成立的公司，如果有很像高管的高管，那这公司也长不了。 – 《知乎》</p></blockquote><p>对于刚成立的公司，每个人都必须实心用事。</p><blockquote><p>国资委报告，在此事件中，中兴通讯公司一系列应对都十分愚蠢和被动，美国的制裁对中兴通讯公司自身及其他中央企业都可能带来高危影响。一定程度上，不仅通讯行业，也不仅国有企业，国内很多企业都在为中兴通讯公司的短视和无诚信经营付出惨痛代价，我国外交布局和国家形象也不可避免地受到影响。</p></blockquote><p>这抹黑的不仅仅是企业，也是一大批充满神秘色彩的“老总们”，他们不再神乎其神，也会犯愚蠢的错误。</p><blockquote><p>鸿学院有关金融对外开放的讨论。</p></blockquote><p>弗洛伦撒之所以能兴起，成为欧洲的金融中心，主要靠三点：</p><ol><li>商人走出去，形成遍布欧洲的商业网络；</li><li>商业网络为教会服务，收取十一税，形成稳定的商业活动；</li><li>参与国家政府融资项目，获取税收等垄断权；</li></ol><p>作为反例，西班牙虽然有发现美洲的优势，但在本国没有形成相应的金融优势，使自己的胜利果实被热那亚商人攫取。而中国要开放，首要问题是这种开放是“对外”还是“对内”。对外意味着中国的商业大规模要走出国门，去服务世界各国；而对内意味着国际金融网络接入国内资本，中国的国有银行将面临全球的竞争，几乎毫无胜算！</p><p>中国的芯片虽然落后，但不过几十年而已。而金融的落后，政治的落后，与发达国家相比相差有数百年，真的需要密切关注这块的发展，因为它关系到每个人的财富变化。</p><h3><span id="2018-04-21">2018-04-21</span></h3><blockquote><p>朝中社报道，朝鲜最高领导人金正恩20日宣布，朝鲜将从21日开始不再进行任何核试验和洲际弹道导弹发射，废弃朝鲜北部核试验场。只要朝鲜不受核威胁挑衅，朝鲜绝对不使用核武器，不泄露核武器和核技术，集中全部力量发展经济，并将与周边国家和国际社会积极展开紧密联系和对话。（央视)</p></blockquote><p>朝鲜果断停止核试验并开始改革开放，这早就在鸿学院里提到，不出意料。下一步，如果有机会购买朝鲜的资产或许是一种很好的投资。</p><blockquote><p>Bitstamp平台数据显示，比特币最近24小时涨7.47%，刷新3月25日以来高位至8888美元。</p></blockquote><p>比特币已经彻底成为各种交易平台炒作赚钱的手段，这8888美元不正好是一种讽刺吗？</p><blockquote><p>美国10年期国债收益率涨至2.955%，为2014年1月以来最高。</p></blockquote><p>国债收益率提高意味着股市下跌。</p><blockquote><p>苹果跌幅达到4.2%。</p></blockquote><p>像苹果这样的大公司也能一天下跌4.2%，还有什么是不可能的呢？</p><blockquote><p>中国企业被诟病过太久，重资产轻人力，行业从业者待遇普遍不高。</p></blockquote><p>这句话很好的描述了中国的现象，正是<strong>“重资产而轻人力”</strong>。无论什么项目，似乎首先做的总是批地、盖楼，然后找一两个凑合的人才，带领一帮水平低下的人开始搞项目。似乎只要找对了方向，人才不是重点。可问题是现在的项目不是搬砖，不是靠蛮力就能搞定的。但我们的政府或企业往往没有长期规划，大批项目的重点不是把好东西做出来，而是要应对各级领导的参观和工作指导。可笑的是，如果一个企业只踏踏实实做事，往往是难以成功的，因为必须得到政府的“支持”，否则银行连贷款都不会给你。</p><h3><span id="2018-04-20">2018-04-20</span></h3><blockquote><p>深圳某投资机构负责人认为，“互联网泡沫2.0”有可能就在未来几年爆发，O2O、互联网金融、大数据、AI可能是“高危地带”，而在这些大领域的“独角兽”企业占比达半数以上。这意味着，可能有一批“独角兽”企业要倒下。“即使没倒下，‘挤泡沫’也是很难避免的。制度设计要避免二级市场泡沫提前向一级市场转移，对于“独角兽”企业IPO前一年内突击入股的投资人需延长锁定期，降低投机色彩。</p></blockquote><p>这种认识我个人非常认同，因为现在的互联网存在大量靠债务支撑的公司，不断融资，拆东墙补西墙却迟迟上不了岸，这种泡沫最终总会以某种形式破裂。</p><h3><span id="2018-03-13">2018-03-13</span></h3><blockquote><p>截至2017年9月30日，美国政府助学贷款总额达1.4万亿美元，有近500万人违约，违约率高达22%。</p></blockquote><p>直接反映美国就业形势并不好，至少工资离债务存在较大的距离。</p><blockquote><p>美国白宫：特朗普总统将在3月20日与沙特王储穆罕默德·本·萨勒曼举行会面。</p></blockquote><p>OPEC对石油的价格无法达成一致，美国页岩油产量还在增加，所以沙特面临较大的财政风险，所以这么着急会面。</p><blockquote><p><a href="https://www.reddit.com/r/investing/comments/83wctc/junk_bonds_diverging_from_sp_500/" target="_blank" rel="noopener">https://www.reddit.com/r/investing/comments/83wctc/junk_bonds_diverging_from_sp_500/</a></p></blockquote><p><img src="https://i.imgur.com/GvYflei.png" alt="pic"></p><p>该网友指出了自己的一个指标：观察junk bounds yield与S&amp;P 500 return之间的关系。他发现最近一段时间两者出现一定的背离，即S&amp;P一直在涨而PHDAX出现明显的下降。这种现象的出现不能直接解读成某种问题，直接反映的可能是资本变得更加倾向一些体量大的公司，就好比前一段时间在A股上证50的涨幅远超过沪深300，更是远超过中小板。这两者始终会一致，所以一方面可能是大盘股回调或小盘股追赶。</p><h3><span id="2018-03-14">2018-03-14</span></h3><blockquote><p>穆迪：将油价预估从45美元/桶上调至65美元/桶，因全球原油减产且需求增速强劲。</p></blockquote><p>最近的油价很焦灼，沙特和伊朗之间的分歧不知道最终会走向何方，沙特依靠美国对伊朗施压的效果究竟会不会提高油价？在3月底可能会有一定的消息透露出来。</p><blockquote><p>美国3月9日当周API原油库存 +115.6万桶，前值 +566万桶。库欣地区原油库存 -15.6万桶，前值 -79万桶。 汽油库存 -126.2万桶，前值 -454万桶。 精炼油库存 -425.8万桶，前值 +149万桶。</p></blockquote><p>原油库存下降有利于油价上升。</p><blockquote><p>“新债王”Gundlach：预计美国政府预算赤字将在2019年达到1.3万亿美元。</p></blockquote><p>美国财政赤字还在加大，系统风险继续加大。</p><blockquote><p>“新债王”Gundlach：考虑到规模为6000亿美元的量化紧缩（QT），美国债市可能会出现大约2万亿美元的债券供应。</p></blockquote><p>各国都在资金回笼过程，人民币也是这样，从而影响到一些垃圾创业公司的生存问题。</p><blockquote><p> 蚂蚁金服1.845亿美元入股巴基斯坦TMB 打造当地版“支付宝”：北京时间3月13日晚，挪威Telenor集团和蚂蚁金服联合宣布，双方已达成战略合作伙伴关系。蚂蚁金服将出资1．845亿美元，购入前者在巴基斯坦的子公司TMB（TelenorMicrofinanceBank）45%股权。</p></blockquote><p>蚂蚁金服可能出现系统风险。一方面国内频繁投资垃圾公司（最近还包括多家共享单车）；另一方面海外的高风险投资可能点燃导火索。</p><h3><span id="2018-03-15">2018-03-15</span></h3><blockquote><p> 全国50大热点城市的土地出让金高达6452.3亿：国家统计局数据显示，1-2月全国楼市（商品住宅）销售面积增速收窄至2.3%。但与楼市销售持续放缓相反的是，房企拿地的热情仍然不减。最新数据显示，在2018年的前2个月里，全国50大热点城市的土地出让金高达6452.3亿，与2017年前两个月的4019.2亿土地出让金相比同比上涨了60.5%。</p></blockquote><p>又是一轮地王？房企视政策于不顾，真的是有作死的感觉了。需要考察一些龙头企业在这次的表现。@新闻里提到龙头企业带头拿地…果然政府的政策都是搞笑的么？政策的执行上还是有些问题。</p><blockquote><p> 央行将进行200亿元人民币7天期逆回购、200亿元人民币28天期逆回购。央行公开市场今日净投放400亿元人民币。</p></blockquote><p>仔细阅读数量，资金实际上是净回笼的，对应了稍紧的货币政策。</p><blockquote><p> 蚂蚁金服消费贷款达 6000 亿人民币，是建行的 3.7 倍。彭博社援引知情人士称，尽管政府监管加强，但通过花呗、借呗业务，阿里巴巴旗下蚂蚁金服的消费贷款规模 2017 年至今增长了一倍。这一规模很可能进一步引发严格的监管措施，影响公司的增长速度。</p></blockquote><p>蚂蚁金服贷款的增加可能来自其互联网征信机制的高效率，但也不能排除其这么大的盘子里的系统风险问题。尚不清楚其违约情况。</p><h3><span id="2018-03-16">2018-03-16</span></h3><blockquote><p>美国1月长期资本净流入 621亿，前值 273亿。国际资本净流入 1197亿，前值 -1193亿。</p></blockquote><p>所谓的国际资本给美国人接盘，其实不能完全这样讲，毕竟美国仍然是世界上最为强大的国家，自然有人愿意来接美国的盘，而不是其它国家。因此，与其说美国有风险，其它国家同样有风险。</p><blockquote><p> 加拿大楼市出现崩跌 房屋销售创五年新低：加拿大地产协会（CREA）最新统计显示，2月加拿大的成屋销售环比跌6.5%，创近五年最低，也较去年12月的峰值连续两个月回落。未经季调的实际销售活动同比下跌16.9%，也为五年新低，并较10年均值低了7%。</p></blockquote><p>如上一条，加拿大这种“度假型”国家太弱，其房地产在金融风险出现时就会出现暴跌。估计不少国内炒房客也在其中吧。</p><h3><span id="2018-03-17">2018-03-17</span></h3><blockquote><p> 美国债务首次触及21万亿美元。美国财政部最新数据显示，联邦债务水平3月15日首次触及21万亿美元。自特朗普2017年1月就职以来，债务增长超过1万亿美元。</p></blockquote><p>系统风险仍然在增加。</p><blockquote><p> 从横向整合到垂直整合 全球芯片业并购愈演愈烈。随着芯片业成本压力与竞争压力加剧，行业龙头纷纷通过并购提升竞争力与市场份额。国际半导体产业协会预计，未来十年芯片产业或从横向整合进入到上下游垂直整合阶段。通过并购，芯片厂商的综合实力将越来越强，产业集中度将越来越高，寡头垄断格局将进一步强化。（中证）</p></blockquote><p>芯片业出现了与以往不同的发展，需要持续关注。Intel自然有它的技术优势，但是这种老牌公司内部的问题往往也根深蒂固，不好说将会如何。</p><blockquote><p>百度申请发行两批次美元债。百度申请发行两批次高级无担保债券，但没有言明每批次的发行额度。</p></blockquote><p>美元的加息对美债形成越来越大的压力。</p><blockquote><p>17日，上海证券交易所公司债券项目信息平台显示，中信证券-滴滴第【N】期CP资产支持专项计划于昨日受理。该计划显示，此次滴滴拟融资金额为100亿元，品种为持证券-ABS。滴滴出行营销副总裁李敏确认该消息属实，但对于滴滴外卖业务他三缄其口。（21世纪经济报道）</p></blockquote><p>最近垃圾公司呈现出许多有趣的特征，比如垃圾公司A与垃圾公司B合作就以为能变成非垃圾公司，比如垃圾公司A开展各种乱七八糟的业务就变成非垃圾公司。滴滴这家公司搞不好就是下一个乐视。当然，它也有一个强劲的竞争对手，美团。</p><div class="tip"><br><br>ABS（Asset-Backed Security）通常的用法是在公司在主营业务之外开辟新的产品时，将新的产品线作为资产抵押借贷。如果该业务失败，那么损失也不会波及原有的主营业务。这对投资人来讲是风险很大的。<br><br></div><h3><span id="2018-03-18">2018-03-18</span></h3><blockquote><p>《鸿学院——朝鲜与美国的会晤》</p></blockquote><blockquote><p>战略就必须有敌人和朋友</p></blockquote><blockquote><p>东北问题的根源是地缘环境恶劣，而改善的关键也在环境改变</p></blockquote><blockquote><p>如果你要投资一个无法放弃的棋子，就必须做到它感恩戴德，否则就是为他人做嫁衣裳</p></blockquote><blockquote><p>如果朝鲜真的走向改革开放，那么将会出现巨大的商机</p></blockquote><p>关注东北与一带一路；关注朝鲜改革开放的机遇。</p><blockquote><p> 英媒称，2017年全球不动产投资创下1.62万亿美元的历史新高，来自亚洲的投资占比超过半数。但伦敦仍是最受青睐的全球不动产投资目的地，因为对英国脱欧的担忧已被英镑贬值的影响抵消。</p></blockquote><p>中国炒房客的爱好：伦敦、澳洲、加拿大。</p><blockquote><p>日前，碧桂园400亿ABS获审批通过，一时间，非标转身ABS似乎成为非标转型最确定的出路。部分非标业务吃重的银行、券商正在山重水复之时，仿佛迎来柳暗花明的前景。但有业内人士表示，部分ABS底层资产涉及项目多，合规难度大，投资勿盲目入场。（中证）</p></blockquote><p>在这种时候提高债务的风险很大，美元加息的压力，非主营业务的风险等等，投资要避开这样的流氓公司。</p><blockquote><p>深圳市交委称3月17日凌晨收到相关举报，经调查，滴滴出行本次违规投放青桔单车约2万辆，该委联合市城管局、交警局于3月17日下午约谈滴滴出行，责令整改并立即收回违规投放车辆。（南方网）</p></blockquote><p>垃圾公司制造垃圾。</p><h3><span id="2018-03-19">2018-03-19</span></h3><blockquote><p>黑龙江省围绕“哈欧班列”已经建成“哈尔滨－汉堡”、“哈尔滨－明斯克”、“大庆－泽布鲁日”、“哈尔滨－莫斯科”四条核心线路，并形成了相应跨境产业链条。黑龙江省这个传统意义上的东北边陲省份，正借力“一带一路”加速成为我国向北开放的前沿地带。</p></blockquote><p>这才是正路！但朝鲜问题是否能顺利解决呢？有待进一步观察。</p><h3><span id="2018-03-20">2018-03-20</span></h3><blockquote><p>OPEC秘书长Mohammad Barkindo：OPEC和伙伴国家目前的焦点是全面、及时执行协议控制原油产出直至2018年底。</p></blockquote><p>油价在2018年底之前应该能保持不会出现大的波动。</p><blockquote><p>据媒体报道，全球最大的消费类无人机制造商大疆正在与投资者进行洽谈，希望能够以150亿美元的估值进行新一轮融资。此次募集的资金大约在5亿至10亿美元之间，交易细节尚未最终确定。“此次融资可能是以股权融资与债务融资结合的方式进行。”一位熟悉交易的内部人士表示，这也是大疆迄今为止规模最大的一轮融资。</p></blockquote><p>智能硬件仍然没有哪家企业真正走出消亡的命运。</p><blockquote><p>被称为固收衍生品交易界的传奇人物、全球最大债基PIMCO前基金经理Harley Bassman，撰文阐释了“美股熊市真正到来的信号”：美股与美债收益率的相关性由正转负时。据他列出的条件，这很可能出现在今年末。参考 <a href="https://www.zerohedge.com/news/2018-03-20/trading-legend-reveals-how-he-will-know-when-real-bear-market-starts" target="_blank" rel="noopener">1</a>和 <a href="https://www.blackrockblog.com/2018/02/21/rates-stocks-rise-together/?utm_source=BlackRock+Blog&amp;utm_campaign=4695393636-RSS_EMAIL_CAMPAIGN&amp;utm_medium=email&amp;utm_term=0_7beec13d69-4695393636-305445649" target="_blank" rel="noopener">2</a>。</p></blockquote><p>读了一遍，里面的逻辑感觉有互相矛盾的地方，感觉并不靠谱。</p><blockquote><p>摩根士丹利：预计美债收益率将在9月份发生倒挂。</p></blockquote><p>倒挂的形势最近一个月时间里变得越来越明显。</p><blockquote><p>白宫发言人桑德斯：美国总统特朗普和沙特王储的会面取得了进展。</p></blockquote><p>石油与军火的交易。</p><blockquote><p>近日，记者多次收到低佣金开户的广告，“无论资金量大小，均可享受万分之二点五的超低佣金率。”部分中小券商实际给出的佣金率更低，万分之二甚至是万分之一点八的佣金率已经不再是资金量大的客户的“专利”。此外，记者还了解到，为争夺优质客户，多家券商已经打破两融业务中的融资基准利率8%以上的行业惯例，融资基准利率在6%到7%之间。（证券日报）</p></blockquote><p>客户的争夺意味着金融市场的不稳定性还在上涨，越来越多的韭菜进入市场了。</p><h3><span id="2018-03-21">2018-03-21</span></h3><blockquote><p>中国商务部：拟对美对华出口的改性乙醇、无缝钢管等加征15%的关税。</p></blockquote><p>中美贸易战的回应。</p><blockquote><p>美国国家安全顾问McMaster将辞职，届时将由John Bolton接任。（纽约时报）</p></blockquote><p>温和派改成了鹰派。</p><blockquote><p>周四（3月22日）纽约尾盘，美国10年期基准国债收益率跌5.86个基点，报2.8244%，财政部拍卖TIPS后不久一度跌至2.7971%。两年期美债收益率跌2.69个基点，报2.2786%，财政部拍卖TIPS后不久一度跌至2.2538%、意味着美联储3月决议声明宣布加息以来的跌幅达到10.36个基点。</p></blockquote><p>股市和债市终于出现此消彼长的现象了，这是QE以来未出现过的状态。是否说明QE的退出已经接近尾声？这正是熊市来临的信号吗？</p><h3><span id="2018-03-22">2018-03-22</span></h3><blockquote><p>沙特能源部长al-Falih：OPEC与非OPEC将持续合作至2019年。原油市场三分之二的供应过剩已经得到解决。沙特有大量可用作燃料的铀储备。</p></blockquote><p>鼓励油价上涨的消息。</p><blockquote><p>新华社华盛顿3月22日电：美国总统特朗普22日签署总统备忘录，依据“301调查”结果，将对从中国进口的商品大规模征收关税，并限制中国企业对美投资并购。特朗普在白宫签字前对媒体说，涉及征税的中国商品规模可达600亿美元。中国商务部此前表示，中方绝不会坐视合法权益受到损害，必将采取所有必要措施，坚决捍卫自身合法权益。</p></blockquote><p>贸易战的硝烟，但只是硝烟。</p><blockquote><p>特朗普律师辞职。（纽约时报）</p></blockquote><p>特兰普身边的人换了一个又一个，如果真出现金融危机，那么特朗普就算是完蛋了。而他肯定不会让危机这么快到来，会尽量拖延，但总有个时间节点是无法抑制住的。</p><blockquote><p>道指跌幅再度超过400点，标普跌约1.6%，纳指跌约1.7%。据纽约时报报道，特朗普律师Johyn Dowd辞职，Dowd负责调查“通俄门”特别检察官Mueller。</p></blockquote><p>中美贸易战升级，股指暴跌。但评论基本上持有这只是一次谈判而已，因为中美经济纠葛太深，如果真的贸易战双方都不会有好结果。</p><h3><span id="2018-03-23">2018-03-23</span></h3><blockquote><p>林毅夫在 #中国发展高层论坛# 称，从计划经济向市场经济转型，中国不是唯一的国家，而很多转型中的国家出现了经济崩溃，危机不断，但中国却是稳定并快速发展，这其中的奥秘或许就是“新人新办法，老人老办法”。</p></blockquote><p>这不正是保守主义的做法吗？一刀切是政治上很不理智的行为，或者说是一种政治幼稚的表现。</p><blockquote><p>3月24日上午，中央政治局委员、国务院副总理、中财办主任、中美全面经济对话中方牵头人刘鹤应约与美国财政部长姆努钦通话。姆努钦向中方通报了美方公布301调查报告最新情况。刘鹤表示，美方近日公布301调查报告，违背国际贸易规则，不利于中方利益，不利于美方利益，不利于全球利益。中方已经做好准备，有实力捍卫国家利益，希望双方保持理性，共同努力，维护中美经贸关系总体稳定的大局。双方同意继续就此保持沟通。（新华社）</p></blockquote><p>贸易战照会后马上开始谈判。</p><blockquote><p>3月23日，在第二届中国直播与短视频峰会上发布的《2017年中国直播行业研究报告》显示，2017年，我国直播行业市场总收入超过300亿元，比上年增长39%。从数据来看，行业仍然在走上坡路。2017年，直播行业用户人数达到了4.2亿，无论是游戏直播用户，还是秀场直播用户，同比增速都超过了50%。直播行业用户规模呈现良好增长态势。（广州日报）</p></blockquote><p>我原本认为直播是一种不靠谱的行业，但自从理解每个人都有选择自己生活的原则后，开始认真审视这个行业。直播实际上满足了相当大一部分人的工作需求和消费需求，那么这就是一个合理的行业。而直播与许多互联网行业不同，它有着非常清晰的变现模式，在互联网这个十分不靠谱的环境下，直播俨然一种清流式的存在。严重看好YY。</p><h3><span id="2018-03-24">2018-03-24</span></h3><blockquote><p>宗庆后在中国发展高层论坛谈到“新零售”时表示，最终来讲互联网的成本更高，“它要把商品送到消费者那里去，最后又要回归到实体零售来”。“我不太认可互联网颠覆，全部颠覆我们不都死掉了？” <a href="http://t.cn/RnCURRJ" target="_blank" rel="noopener">http://t.cn/RnCURRJ</a></p></blockquote><p>这里的讨论非常有价值。随着网络零售对实体店的冲击，造成实体店盈利困难，间接肯定会造成实体店租金下降，从而慢慢压低实体店的成本。随着可能的无人零售的到来，这将与网络零售造成冲击，因为无人零售在人力成本上远远低于快递送达业务。下一步应该密切关注无人零售的发展。但注意这不是指自动贩卖机，自动贩卖机已经在很大程度上证明是入不敷出的，而且是个竞争极其激烈的行业。无人零售特指大型商超，而人力成本又极地的情况，这更像美国商超的状态。从这个角度，每个WMT和COSCO在亚马逊面前并非无力一战！</p><h3><span id="2018-03-25">2018-03-25</span></h3><blockquote><p>沙特王储：OPEC寻求与俄罗斯和其他产油国实现10-20年的供应合作。与俄罗斯就“整体情况”达成共识，正致力于磋商长期性石油合作的细节性内容。</p></blockquote><p>俄罗斯有非常强大的动机要跟沙特合作，而沙特刚刚访问美国，从这个角度来看似乎沙特王储访美并没有达到自己的目的，否则以美国的立场必然要求沙特拒绝与俄罗斯合作，这个政治格局有点意外，可能跟美国本土的石油行业有一定关系。如果是这样，那么沙特和俄罗斯的合作将对石油价格造成很强的影响，而美国因为本国一些利益，失去了沙特在中东的影响力。</p><h3><span id="2018-03-27">2018-03-27</span></h3><blockquote><p>今日，长沙市住建委印发《关于实施差别化购房措施的通知》。长沙市限购区域内“限房价、竞地价”的商品住房项目（不含定向限价房）和新建商品住房项目中144平方米（含）以下户型的普通商品住房，将优先满足首套刚需购房群体。首套购房刚需群体为长沙市户籍的无房家庭和个人（文件施行后离婚且不满1年的不包括在内）、自签订征收协议之日起1年内的被征收人以及符合长沙市限购政策的本市以外户籍无房家庭。</p></blockquote><p>确定这不是突破限购的借口吗？</p><blockquote><p>美国10年期国债收益率跌破2.8%。</p></blockquote><p>10年国债的变化是否符合经济危机的趋势？</p><blockquote><p>美国财政部拍卖350亿美元五年期国债，得标利率2.612%，投标倍数2.50、前次为2.44。</p></blockquote><p>美国发债仍在继续，而收益率还在下降，似乎说明人们把钱都投入债券。</p><blockquote><p>美国30年期国债收益率跌破3%，为2月6日以来首次。</p></blockquote><p>倒挂似乎在加剧，需要关注2年国债收益变化情况，如果其收益上升则说明问题。</p><h3><span id="2018-03-28">2018-03-28</span></h3><blockquote><p>巴克莱：预计WTI原油在下半年会跌至51美元/桶，布伦特原油年底会跌至57美元/桶。</p></blockquote><p>这个预测很别出心裁。。沙特要完？石油是个政治游戏啊！如果真是这样，沙特指定要跟美国翻脸了。从最近沙特与俄罗斯走得很近来看，这不是不可能。</p><blockquote><p>随着上市房企2017年年报的陆续披露，上市房企的融资情况相继浮出水面。从融资成本来看，银行贷款、中票、公司债等方式融资成本多在4%-5%之间，与信托融资相比优势明显。整理目前已披露2017年年报的30余家上市房企信托融资数据发现，上市房企信托融资成本大多集中在6%-10%之间，个别公司的信托融资成本达11%。（证券日报）</p></blockquote><p>这样高的债务利息，看来去杠杆的效果还没真正提现出来，值得警惕了。</p><h3><span id="2018-03-29">2018-03-29</span></h3><blockquote><p>周四（3月29日）纽约尾盘，美国10年期基准国债收益率跌4.18个基点，报2.7389%，美股盘中一度跌至2.7389%，为2月5日以来盘中新低；第一季度，10年期美债收益率累计上涨33.35个基点。两年期美债收益率跌1.81个基点，报2.2661%，美股收盘前一度跌至2.2620%，3月21日美联储发布FOMC利率决议声明前，一度涨至2.3574%、为2008年9月9日以来盘中最高位；第一季度，两年期美债收益率累计上涨38.31个基点。</p></blockquote><p>我一直觉得指望靠国债来避险是个非常幼稚的行为，而考虑10年甚至30年的预期是个绝顶幼稚的行为，购买竞争力足够强大的企业股票才是正道，跟巴菲特的思路才是王道。</p><blockquote><p>CNN恐惧与贪婪指数周四(3月29日)读数8，表明市场处在极度恐慌状态，较上日涨2个点；CNN恐惧与贪婪指数，和“VIX恐慌指数”差不多的功能；当CNN恐惧与贪婪指数处在贪婪状态，相当于VIX恐慌指数处在低位，利好风险资产，不利避险资产；相反，CNN恐惧与贪婪指数处在恐惧状态，相当于VIX恐慌指数处在高位，不利风险资产，利好避险资产。</p></blockquote><p>又一个指数，市场总是不理性的。</p><div class="tip"><br><br>这是一次补记，因为实在比较重要。金正恩临时访华，想必是决定跟中国就访美先交个底？金正恩访美的进程值得关注。<br><br></div><h3><span id="2018-03-30">2018-03-30</span></h3><blockquote><p>摩根大通：预计近期LIBOR/OIS利差扩大会给相应的业务领域带来110亿美元利率成本，并使得家庭利率成本增加50亿美元。 近期LIBOR/OIS利差扩大仅仅是金融条件“非常小幅度的收紧”，不足以促使改变对宏观经济前景的预期。</p></blockquote><p>同意。难道宏观经济有问题就不生活了吗？这不过是政治问题周期性的发酵而已。既不能消除，也没必要过于恐惧。</p><blockquote><p>美联储：美联储主席鲍威尔4月6日将在芝加哥针对经济发表讲话。</p></blockquote><p>已关注。（更新）符合市场预期，并没有什么值得说的。</p><h3><span id="2018-03-31">2018-03-31</span></h3><blockquote><p>湖南能源监管办发布的《湖南省电力企业2017年财务经营情况通报》显示，纳入监测范畴的58家电力企业2017年累计利润总额为8.46亿元，同比下降77.89%。其中，17家火电厂发电599.91亿千瓦时，同比增长17.68%，亏损15.23亿元，同比利润减少19.93亿元，共有14家亏损，占82.4%。</p></blockquote><p>火电在增长的情况下亏损还是如此严重，说明什么问题呢？电价在大幅下降？</p><h3><span id="2018-04-02">2018-04-02</span></h3><blockquote><p>财政部网站1日发布通告称，经国务院批准，国务院关税税则委员会决定对原产于美国的部分进口商品中止关税减让义务，自2018年4月2日起实施。中国对原产于美国的7类128项进口商品中止关税减让义务，在现行适用关税税率基础上加征关税，对水果及制品等120项进口商品加征关税税率为15%，对猪肉及制品等8项进口商品加征关税税率为25%。</p></blockquote><p>种种迹象，我感觉这次贸易战是真的要开打了。从朝鲜、沙特、俄罗斯等国的行为，看起来美国正处于特朗普一个人的个人show time，而这种并没有政治框架的莽夫，注定要经受一次考验了。</p><h3><span id="2018-04-05">2018-04-05</span></h3><blockquote><p>俄罗斯能源部长Novak：与沙特能源部长讨论了当前减产协议过后的长期合作；当前合作机制是有效的；长期合作可能包括监督石油市场，交换信息和采取一些联合行动；目前尚无联合文件公布，但在进行讨论。</p></blockquote><blockquote><p>OPEC主席称，俄罗斯在石油减产计划中是一个“好伙伴”。</p></blockquote><p>沙特与俄罗斯关系暧昧，充分说明美国在放弃自己在中东的立场，也可以理解为何麦克马斯特会辞职了。</p><blockquote><p>近日，在腾讯董事会主席兼CEO马化腾的牵线之下，美团点评正式谈妥投资入股摩拜单车事宜，且投资股权占比较大。另一边，ofo第一大股东滴滴亦最终同意蚂蚁金服投资ofo，此前蚂蚁金服对ofo的借债得以实现债转股，双方就投资细节尚在谈判中。（财新）</p></blockquote><p>祝贺摩拜已上岸。有些无法理解腾讯的立场，难道只是为了支付的流量入口？</p><h3><span id="2018-04-06">2018-04-06</span></h3><blockquote><p>据路透社报道，就在特朗普下令考虑对中国1000亿美元商品加征关税后，美国政府一位高级官员表示，美国愿意与中国就贸易问题进行谈判，但前提是谈判是认真的，因为以往的努力没有取得什么进展。双方尚未安排正式的谈判会议，“目前正与中方就贸易问题进行沟通”。</p></blockquote><p>贸易战再次升级，中方应该已经做好准备，等待特兰普的下一步show。</p><blockquote><p>消息称，欧盟和日本加入美国针对中国技术许可要求提起的世贸组织磋商请求。</p></blockquote><p>欧洲为何要追随美国？这次的态度值得深思。按理说这不符合欧盟的根本利益才对。</p><h3><span id="2018-04-07">2018-04-07</span></h3><blockquote><p>波音从美国航空获得123亿美元的47架梦想飞机协议。</p></blockquote><p>美国似乎也在准备着，给受伤的企业发一点甜枣，但这根本不解决问题。离开中国这个全球最大的市场来谈经济是一种愚蠢的决定。</p><blockquote><p>特朗普致函美国国会参议院金融委员会共和党籍主席Orrin Hatch和众议院共和党籍议长Ryan，解释商务部如何审查国家安全、并发现钢铁和铝进口适用于3月23日所实施的25%钢铁进口关税和10%的铝进口关税。特朗普称，对阿根廷、澳大利亚、巴西、加拿大、墨西哥、欧盟成员国、以及韩国等征收的金属关税被推迟至5月1日。</p></blockquote><p>一些有趣的观察，发现日本不在美国的第一批推迟执行关税国家里，这是不好理解的问题。美国与墨西哥仍然就边境墙的问题在做出一些相互攻击的言论。现在国际局势变得有些微妙，还需要进一步观察。如果EU不能在这件事上保持自己独立的立场，让人无法相信EU真的有复兴的一天，仍然是美国的跟屁虫而已。</p><blockquote><p>I think it’s fascinating to watch how Trump keeps testing his power and discovering that there are very real limits to it. Before entering politics, he has probably had to deal mostly with two categories of people - yes men, and people he could bully. Whether he’s bad at business or not, he has billions of dollars, and lawyers, and a private security force. He could certainly intimidate or bankrupt most people he didn’t like.</p></blockquote><blockquote><p>So then he becomes President and thinks he now has much more power because he still has all the money, but is now also in charge of the world’s largest economy and military. And then he discovers that the President’s power is limited by design. With his travel ban, Trump discovered that the judicial branch doesn’t work for him and can work against him. Then, as he discovered with Sessions and Mueller, even the executive branch can work against him, or at least not the way he’d like. Trump discovered that no, the Department of Justice isn’t like having his own team of attorneys, and the FBI isn’t the President’s personal police force.</p></blockquote><blockquote><p>Then Trump, who apparently doesn’t quite understand what a trade deficit is and how tariffs work, starts talking about tariffs left and right, feeling that it’s him/the US throwing his weight around. Only for him to discover that no, the Chinese government cannot be easily intimidated, and can retaliate by introducing tariffs in kind.</p></blockquote><p>另一个有趣的评论。</p><blockquote><p>The Trump organization is privately owned and run like a family business.</p></blockquote><blockquote><p>I’ve found that family businesses have no room for true meritocracy; they depend on kowtowing to the man at the top. Succession is not by rising through the ranks. It is by being related to the family.</p></blockquote><blockquote><p>If Trump was the CEO of a large publicly traded firm - like Rex Tillerson - he’d have a very different opinion on how decisions are made and how to build consensus.</p></blockquote><blockquote><p>But because he was the CEO of a family business, he still believes in those old-school ideas</p></blockquote><p>Reddit上的有趣的评论。</p><p>最近在看《大明王朝1566》，里面海瑞的格局实在是最高的，能看到封建王朝末期，大地主阶级土地兼并而导致的贫富分化，终于将走向无法调和，导致大明王朝的覆灭。古代200~300年才会出现一次轮回，而现代社会这个周期要短的多。如果不是核武器的发展使大家不再通过战争来解决争端，想必第三次、第四次世界大战也早就打完了。最近的中美贸易战，一方面可以认为是中国和美国之间的矛盾，其实更是全球化和逆全球化之间的矛盾。看起来全球化能加快经济发展，但这使得那些可以通过全球化获利的人的财富积累远远快过普通老百姓，从而加剧了贫富分化。在这场斗争中，没有谁对谁错，只是大家的立场不同而已。逆全球化实际上并不真正解决问题，解决问题的是让那些前几十年得到大量好处的阶层把利益分享出来，否则只是走形式主义，没有用。特朗普能帮助美国解决这个根本问题么？我觉得没戏，因为到目前为止仍然看不到他究竟做了什么有价值的事情。美国之所以强大，是因为他为强大提供了最好的土壤，自由平等包容，这些才是创造力的肥料，而今天他打算闭关来把这些好的留下，怎么可能呢？背道而驰。他真正该做的是在美国人民中提倡教育，发动那些整体无所事事的美国人做一些更有意义的事业，而不是只会吃喝玩乐，享乐生活。在过去的相当长的时间里，美国依靠的是来自其它国家的先进的生产力在维持它自身的高速发展，而最近这些优势在逐步散失。中国正相反，环境在变得越来越好，政府在有意识的吸引优秀人才，这是个非常好的趋势。中国也有贫富分化的问题，而19大已经明确把这件事当成中国社会的主要矛盾来说，不得不感慨中国政府真的做到了与时俱进，而反观美国政府，仍然在一些边缘问题上磨磨唧唧，不敢指出问题的要害。如果问题都提错了，怎么可能解决好呢？这次的“贸易战”于中国正是一次好的机会，一次表明自己立场的机会，正如宋鸿兵所说，如果你有战略却没有敌人，别人怎么敢跟你站队呢？没错，美国就是中国的敌人，而中国的朋友要向西发展，中东、东欧、西欧、非洲，都是中国非常重视的要发展的朋友，而孤悬海外的美国，如果还做着自己“天朝上国”的美梦，就跟清朝差不多了。</p><h3><span id="2018-04-08">2018-04-08</span></h3><blockquote><p>罗奇：特朗普应该好好照照镜子！美国是“扛不住的”</p></blockquote><p>作为一个中国人，实在是一种没有选择的选择，而我目前来说还是觉得中国在经济上会超越美国的，当然前提是中国人的基本观念不发生变化，这依赖政府时刻保持高度警戒，抓住社会的主要矛盾不断深化改革，这的确很难。我越来越佩服我们的政府了，要是我肯定做不到那么全面。</p><h3><span id="2018-04-09">2018-04-09</span></h3><blockquote><p>阿里巴巴董事局主席马云今天向员工发出了一封内部信宣布，彭蕾将卸任蚂蚁金服董事长，蚂蚁金服CEO井贤栋将兼任董事长一职。</p></blockquote><p>阿里内部的变化也挺有意思，蚂蚁金服在这个时候换人究竟传达了一种什么信号呢？</p><h3><span id="2018-04-13">2018-04-13</span></h3><blockquote><p>2018年以来，两市质押股数同比下降16.22%、质押市值下降23%。股票质押市场如今出现“量跌价升”状况，即便出质人降低价格要求，仍难以做成业务，在当前一段时间里的处于“有价无市”状态。2017年期间股票质押的融资利率一般在6%～6.5%之间，如今主流的股票质押利率一般在7%左右，6.5%的质押利率已经少见。 有一些券商，在综合考虑目前的风险与资金成本后，则直接将利率在8%以下的质押业务拒之门外。（证券时报）</p></blockquote><p>似乎反映了金融市场对不确定性（即风险）的感知在加深，7%~8%的利率已经较高了。</p><blockquote><p>美债收益率大涨，特朗普表态暂时缓和投资者对中东局势的担忧。周四（4月12日）纽约尾盘，美国10年期基准国债收益率涨5.50个基点，报2.8358%，盘中交投于2.7698%-2.8413%区间。两年期美债收益率涨4.10个基点，报2.3480%，盘中交投于2.2989%-2.3521%区间。</p></blockquote><p>资金又从债市去了股市？</p><blockquote><p>新媒体信息平台的发展，呼唤并推动着监管机制的创新，特别是更加重视人工智能算法的治理。而即便如此，仅靠监管部门也是不够的，互联网时代需要更加重视用户的力量，建立更具响应能力的举报渠道，发挥好用户作为内容生产者的正面作用。同时，也可以从用户的角度出发，更科学、更合理地对内容、平台进行分类管理。网络治理有了“用户思维”，才能从根本上改变内容生产的生态。</p></blockquote><p>互联网健康监控绝对是AI的好应用场景。</p><blockquote><p>中国证券报头版刊文称，对资本市场尤其是债市而言，除非未来资金面超预期宽松，否则资金面对债市的正面贡献可能逐渐衰弱。目前来看，随着收益率的快速回落，稳货币带来的流动性悲观预期的修复似乎已逐渐反映在市场预期中，且债券供给压力和4、5月存在连续大额财政收税的考验也逐渐临近，后续资金面宽松程度趋于收敛将是大概率事件。</p></blockquote><p>在美元加息的前提下，全球资金量还是以紧缩为基本趋势。</p><blockquote><p>外媒报道称小米正在考虑是否收购运动相机制造商GoPro，消息传出后，GoPro股价飙升近8.8%。根据惠普在2010年收购同样生产艰难的Palm时的出价，GoPro可能售价10亿美元。消息人士表示，尽管小米有收购意向，但不代表公司愿意出高价。 <a href="http://t.cn/Rm9yzwK" target="_blank" rel="noopener">http://t.cn/Rm9yzwK</a></p></blockquote><p>还是那句话，单纯的智能硬件产商很难生存下去，GoPro当年可不是一般的火。小米的根基在手机和家电，这是赚生活费的生意，而其它的各种“玩具”硬件都缺乏现金牛这重保险。</p><blockquote><p>OPEC秘书长默罕默德·巴金多：全球原油过剩自2017年开始有效的下降了十分之九。</p></blockquote><p>最近油价涨的厉害，但也要考虑整体经济下行的压力。</p><blockquote><p>特朗普：只有在TPP协议比奥巴马的版本更好的情况下，才会重新加入。我们已与TPP11个成员国中的6个达成双边协定，正致力于与最大成员国日本达成协议，后者多年来给我们在贸易上带来沉重打击！</p></blockquote><p>连日本都要敲打，这位总统在走钢丝呢。</p><blockquote><p>在此前的一次由中国汽车行业组织的高端论坛上，有相关负责人曾透露特斯拉将会在2018年正式在华独资建厂，这个消息似乎也从侧面佐证了上述汽车产业合资股比放开将在年内正式落地的消息。（经济观察报）</p></blockquote><p>特斯拉股票得涨~</p><blockquote><p>联社4月13日讯，中国央行据悉将放宽对商业银行存款利率上限的非正式指导。（新浪）</p></blockquote><p>如果这是真的，那么将意味着重大的金融改革。中国的银行体系终于能慢慢走出权威政府模式，这带给银行业许多机遇和挑战，例如需要银行加强信用评级体系，强化风控意识等等，而广大的中小企业也将慢慢获得相对优惠的银行贷款。银行的储蓄利率和放贷利率之间的差额在充分竞争后缩小到合理的区间。如果真的能做到这些，余额宝之类的“替代品”将受到严重的威胁。</p><blockquote><p>4 月 13 日，由小米投资的黑鲨科技发布了国内第一款游戏手机。</p></blockquote><p>当年PC游戏火爆的时代，游戏本并没有走出失败的命运；今天，一款面向手游的手机，能否改变这个宿命呢？个人并不看好。手机游戏本质上比PC游戏更加体现休闲，打发碎片化的时间，这似乎离hard core模式更加遥远。</p><h3><span id="2018-04-14">2018-04-14</span></h3><blockquote><p>从A股自身的供给侧改革来看，当前阶段亟需更多增量资金入场，而互联互通额度扩大，提升国际化水平，将对A股营造优胜劣汰生态环境、塑造价值导向具有重要意义。从全球资产配置来看，当前外资对A股整体严重低配，且以被动型基金覆盖为主，这与我国位列世界第二大经济体的地位存在巨大错位矛盾，亟需优化；同时，吸引“独角兽”企业前来A股上市，内地监管层也持欢迎态度，这就需要进一步营造充沛的资金环境，创建高效的估值体系。</p></blockquote><p>感觉证券市场改革是最近一段时间的主流，而国家终于开始认真重视这块了，对A股和中国的所有企业都是一种利好。中国企业依赖银行内部关系的时代是否要终结了？</p><blockquote><p>朱啸虎首次承认已清仓ofo：我们是财务投资人，战略投资人诉求跟我们不一样。</p></blockquote><p>垃圾公司，能有多远躲多远。</p><blockquote><p>新华社记者14日凌晨在叙利亚首都大马士革听到空中传来巨大爆炸声，叙利亚国家电视台说美英法三国对叙利亚“发动了侵略”。（新华社）</p></blockquote><p>弱国无外交。</p><blockquote><p>鸿学院有关叙利亚问题的讨论。</p></blockquote><p><img src="/blog/assets/syria.png" alt="syria"></p><p>当前世界的主要矛盾是民族主义和全球化之间的矛盾，叙利亚只是这种矛盾下的一个旁支，有一定的关联和体现，但不是纯主线。</p><p><strong>天然气</strong> 地理上占据了中东天然气输入欧洲的路线，在俄罗斯和伊朗的支持下加强了这两者对欧洲的天然气控制权。而美国本土的天然气输出与此矛盾。英法试图减弱对俄罗斯在天然气方面的依赖。</p><p><strong>库尔德问题</strong> 库尔德人独立是英法美的一张牌，但打出来同样会损害土耳其的利益，将导致土耳其倒向对手。</p><p><strong>石油价格</strong> 沙特依赖美国巩固其在中东的地位，美国依赖沙特联合打压俄罗斯油价。但最近的形势出现变化，OPEC与俄罗斯达成了协议来提高油价。石油价格上涨根本上也符合美国本土页岩油利益集团的期望，但也跟霸权主义不符。</p><p><strong>化武事件</strong> 3月份英俄之间的神经毒气事件“意外”发酵，也为4月美国对俄罗斯的经济制裁做了铺垫，更为英法美对叙利亚因化学武器的空袭做了铺垫。</p><p><strong>三派势力</strong> 新保守主义、新自由主义、新民粹主义三派势力强弱目前依次递减。前20年新自由主义一直是中国的支持者，但在中国提出一带一路和智能制造2025以后决定转支持为对抗；新民粹主义痛恨中国抢走了他们的制造业，在全球化问题上与中国对抗。</p><p><strong>通俄门</strong> 特朗普上台后即通俄门不断，反应了其它利益集团对民粹主义的不满。本质上特朗普和普京都是反全球化的，在这一点是他们的利益一致。</p><p>一个有趣的问题：中国当前是这三者哪个成分居多呢？</p><h3><span id="2018-04-15">2018-04-15</span></h3><blockquote><p>腾讯智能音箱“腾讯听听”4月20日上市。</p></blockquote><p>智能音箱已经成为红海，各大厂商都有自己的产品，但智能音箱的竞争是资本的竞争，只有足够的钱才能买足够优质的媒体版权，才能雇佣优秀的人工智能人才，才能不计成本推广自己的产品。在这场竞争中，百度是最没有希望的，一个对自己过去的产品三心二意的公司是无法做出好的产品的；腾讯有一定的希望，因为它足够财大气粗，但腾讯的强项是社交，除非沉溺社交的用户，否则来一个跟钉钉一样的使用体验真的很糟糕吧；阿里也财大气粗，但除非这货敢往里面加广告，否则与其已有的业务关联不大，不过这与其做平台的思路是一致的，搭建一个生态系统，让别家来完善；小米似乎有最正当的理由来做这件事，因为智能音箱正好是智能家居的入口，但真正geek到生活的人毕竟少数，而且由于其在媒体资源上相对弱，所以版权上不占优势；京东做这个真心不看好，基本没有什么技术积累和优势；喜马拉雅和yeelight都属于小厂，没法通过补贴推广自己的设备，比较难有前途。</p><p>现在我倒是期待网易的表现，毕竟它一直是以一种有格调的生活为定位的，且其版权资源也算不错。</p><h3><span id="2018-04-17">2018-04-17</span></h3><blockquote><p>美国财政部公布的2018年2月数据显示，中国所持美国国债规模较上月增加85亿美元至1.1767万亿美元，为美国第一大债权国。而在1月，中国则减持了167亿美元，当时持仓规模创下去年7月来的新低。</p></blockquote><p>中国仍然是美债的最大买家。</p><blockquote><p>美国商务部向中兴通讯发出出口权限禁止令。针对中兴通讯发出出口权限禁止令意味着，该公司将被禁止参与接受美国政府出口管理条例管辖的“任何形式的任何交易”，美国出口管理条例管制范围涵盖敏感技术的海外出口。(彭博)</p></blockquote><blockquote><p>招商电子4月17日研报关注中兴通讯禁运事件。招商电子认为，中兴通讯的三大应用领域里，芯片门槛最高的板块是RRU基站，这一领域要想实现国产替代，需要较长时间。光通信和手机产业链门槛相对较低，一些细分领域的国产芯片方案甚至于成为了国际龙头，但整体来看，还是偏低端应用。本次中兴通讯的禁运事件，对于通信产业冲击较大，也敲响了半导体产业的警钟，自主可控不仅仅是口号，而是涉及到国家安全，国计民生的要务。</p></blockquote><blockquote><p>美国商务部禁止美国公司向中兴出售零部件等产品 7 年。美国商务部称，2016 年 3 月中兴已被限制出口，由于中兴在缓期执行期间再次向美国政府做出虚假陈述，违反之前关于向伊朗和朝鲜非法出口电信设备的“和解协议”，商务部依据协议颁布出口禁令，禁止所有美国企业和个人以任何方式向中兴出售硬件、软件、技术服务，期限 7 年，立即执行。中兴手机等产品也将受制裁影响，无法获得零部件</p></blockquote><p>这次贸易战时刻提醒中国的国家安全仍然受到很强的挑战。如果没有微软、Intel、Google中国的IT产业起码倒退20年…因此，应该极度看好中国本土的芯片产业，例如紫光国芯（虽然这货已经很贵），只有拥有可选择的余地才能保障自身安全。</p><blockquote><p>李大霄：降准对稳定经济增长和股市有正面作用 今日央行决定4月25日起下调部分金融机构存款准备金率1个百分点。对此，英大证券首席经济学家李大霄表示，央行对部分金融机构降准及置换中期借贷便利（MLF）的操作，目的在于增加长期资金供应，降低企业融资成本，释放4000亿元增量资金，增加了小微企业贷款的低成本资金来源，解决小微企业融资难融资贵的问题，对于稳定经济增长有正面作用，对于股票市场的稳定也有非常好的正面作用，属重大利好消息。</p></blockquote><blockquote><p>国金李立峰：货币政策由中性偏紧转向适度扩大内需 中国人民银行决定，从2018年4月25日起，下调大型商业银行、股份制商业银行、城市商业银行、非县域农村商业银行、外资银行人民币存款准备金率1个百分点。对此，国金证券李立峰表示，随着外需今年的高度不确定性，今年货币政策理应有所转向，由中性偏紧转向适度扩大内需。今天披露的“央行针对部分银行实施定向降低存款准备金率”，正印证了我们的这一看法：货币政策在微调转向。</p></blockquote><p>货币政策在由严转宽，这似乎意味着某种资产（股票或房子）又开始要涨价了。所谓“照顾”中小企业不知道能怎么执行。接下来应该关注房产限购方面的变化。</p><blockquote><p>俄罗斯政府：普京和默克尔通电话探讨了叙利亚问题。</p></blockquote><p>似乎从某个时间点起英法就已经与美国穿一条裤子了，已经不再独立思考问题了。而德国则有一定的独立性，在此中扮演一种特定的角色。</p><blockquote><p>美国财长Mnuchin：特朗普有关中俄汇率的言论是对两国的“鸣枪警告”，特朗普希望确保中国不会像过去那样让本币贬值。</p></blockquote><p>中美金融战远远没有结束，也不会以这种不清不楚的形式结束。</p><h3><span id="2018-04-18">2018-04-18</span></h3><blockquote><p>美国总统特朗普确认已与朝鲜领导人金正恩直接通话。</p></blockquote><p>期待有进一步的内容曝露。</p><blockquote><p>记者17日从国家发改委获悉：新的外商负面清单将于今年上半年尽早公布实施，包括2018年及未来几年的开放措施。新的外商投资负面清单将把制造业开放作为重点。汽车行业将分类型实行过渡期开放，2018年取消专用车、新能源汽车外资股比限制；2020年取消商用车外资股比限制；2022年取消乘用车外资股比限制，同时取消合资企业不超过两家的限制。通过5年过渡期，汽车行业将全部取消限制。</p></blockquote><p>国产汽车扶植这么多年了，也没见什么起色，而现在放开估计也有外部的压力吧。对于汽车行业真不是好消息，回头想想中国的国产服装，随着国外品牌的进入，什么美特斯邦威、森马、班尼路之流都消失不见了。实际上，随着人们消费能力的上升，并非不能支撑起好的品牌，只是现在资金大都流入一些新兴行业，传统行业的从业人员收入不够，无法聚集足够好的人才，归根结底还是钱的问题。</p><blockquote><p>华尔街日报：以色列据称在美国对叙利亚行动上与美国进行了协商。</p></blockquote><p>美国无法亲自出面的情况下，是否会依赖这个中东盟友做点什么呢？</p><blockquote><p>福特表示对于中国有关外资股比限制的公告感到鼓舞。福特发言人在一封电子邮件声明中表示：“中国发改委的声明让我们感到鼓舞，这清楚地表明了中国政府进一步开放汽车行业的承诺。”</p></blockquote><p>对于福特和特斯拉，这的确是利好。</p><blockquote><p>美联储Williams：真正的收益率曲线倒挂会发出强有力的经济衰退信号。</p></blockquote><p>过去的一个月变化不明显。</p><blockquote><p>美国商务部向中兴通讯发出出口权限禁止，将禁止美国公司向中兴通讯销售零部件、商品、软件和技术7年。去年底工信部发布中国光电子器件产业技术发展路线图（2018-2022年）指出，核心、高端光电子器件落后已经成为制约我国信息产业发展瓶颈。目前高速率光芯片国产化率仅3%左右。政策要求在2022年中低端光电子芯片的国产化率超过60%，高端光电子芯片国产化率突破20%。A股公司可关注光迅科技、新易盛。</p></blockquote><blockquote><p>路透社援引知情人士消息称，美国限制中兴通讯使用美国制造的零部件之后，中兴通讯可能无法在其移动设备上使用谷歌的Android操作系统。消息人士补充称，中兴通讯和Alphabet公司一直在讨论美国政府禁令的影响，不过截至周二上午，两家公司尚未就中兴使用Android的问题做出决定。（中新社）</p></blockquote><p>Andorid都被限制，各种软硬件的限制很严重。</p><blockquote><p>根据美国4月17日提交WTO的文件《美国对来自中国的某些商品的关税措施》，美国表示愿意与中国进行磋商。</p></blockquote><p>终于要走到谈判桌前了吗？</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;每天读新闻，学习思考一些基本的经济逻辑。&lt;/p&gt;
    
    </summary>
    
    
      <category term="investment" scheme="liqul.github.io/blog/tags/investment/"/>
    
  </entry>
  
  <entry>
    <title>从Raft到MultiRaft</title>
    <link href="liqul.github.io/blog/multiraft/"/>
    <id>liqul.github.io/blog/multiraft/</id>
    <published>2018-11-01T08:52:03.000Z</published>
    <updated>2018-11-01T10:30:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>Raft是一种共识算法，在之前的文章里已经提到过。简而言之，每次集群处理一次请求，都需要经过集群中大部分节点协商。所以一个Raft集群的规模一般不会太大，否则协商的代价就会比较大。那么如果希望基于Raft实现一些规模比较大的服务该怎么扩展呢？</p><p>例如我们想做一个kv存储，那么一个简单的想法是把key分为多个range，然后不同的range由不同的Raft集群来控制。实际上，MultiRaft的思想就是这么简单…只是在实现上有一些细节需要考虑。如果希望更多理解MultiRaft的概念，可以读读这篇<a href="http://sergeiturukin.com/2017/06/09/multiraft.html" target="_blank" rel="noopener">文章</a>，还有<a href="https://www.cockroachlabs.com/blog/scaling-raft/" target="_blank" rel="noopener">这里</a>。从中可以发现，MultiRaft解决的两个核心问题分别是：</p><ul><li><strong>共享物理节点的问题</strong>：多个Raft集群实际上是共享物理节点的，所以需要小心组织每个节点上的数据；</li><li><strong>Heartbeat过多的问题</strong>：每个Raft集群逻辑节点需要处理Heartbeat消息，如果每个物理节点上都有多个Raft逻辑节点，那么开销会比较大，所以希望Heartbeat以物理节点为单位而不是逻辑节点。</li></ul><p>如果考虑跨Raft集群操作，实际上还有一个问题，就是如果一次操作跨不同的Raft集群怎么办？如果服务不需要提供事务那其实是没有问题的，但如果需要呢？现在使用MultiRaft的两个服务Cockroachdb和Tidb都有文档说明：</p><ul><li>Cockroachdb：看<a href="https://www.cockroachlabs.com/blog/how-cockroachdb-distributes-atomic-transactions/" target="_blank" rel="noopener">这里</a>和<a href="https://www.cockroachlabs.com/blog/serializable-lockless-distributed-isolation-cockroachdb/" target="_blank" rel="noopener">这里</a>；</li><li>Tidb：看<a href="https://pingcap.com/blog-cn/percolator-and-txn/" target="_blank" rel="noopener">这里</a>。</li></ul><p>Cockroachdb的思路比较容易理解，也跟我想的差不多，而Tidb的则没有看明白，尤其是关于锁的问题。</p><p>下面按照我自己的理解来说明。首先，数据需要以MVCC方式存储，即每个kv保存多个版本，例如：</p><table><thead><tr><th>key</th><th>value</th><th>commit</th><th>state</th></tr></thead><tbody><tr><td>a</td><td>1</td><td>1</td><td>stable</td></tr><tr><td>a</td><td>2</td><td>2</td><td>unstable</td></tr><tr><td>b</td><td>1</td><td>1</td><td>stable</td></tr></tbody></table><p>每个kv除了key和value额外保留两个字段，分别是commit和state。在这里stable代表一次事务已经完成，可以被外界读取的情况；反之，如果是unstable，表示事务没有完结，对外不可见。</p><p>在一次写入的时候，如果所涉及的数据都分布在一个Raft集群内，那么是不需要考虑事务的，因为这些变更可以记做一条Raft日志，从而达到事务的效果。只有跨多个Raft集群时才需要用Two-phase commit (2PC)来达到整体的事务效果。</p><p>在2PC的第一个阶段，每个Raft集群完成写入后，内部节点的状态（即一个kv map）对应的state都是unstable，表示这时候只是单个Raft完成写入，还需要等待2PC coordinator确定是否所有Raft集群都完成写入。数据里的commit是事务的编号，这可以由一个独立的服务来产生事务编号，保证commit单调递增。当所有Raft集群都写入成功，2PC进入第二个阶段，由coordinator向所有集群通告已经成功的commit号，接收到该信息后各个Raft集群将commit对应数据的state由unstable改变成stable，一次事务完成。</p><p>总的来说，MultiRaft是对Raft的一种扩展。但是，MultiRaft还不方便简单抽取出来作为一种可供其它应用直接使用的库，与业务逻辑的关联性比较强。不过，有了Cockroachdb和Tidb的实际应用，对其它类似的存储结构的扩展是很好的参考。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Raft是一种共识算法，在之前的文章里已经提到过。简而言之，每次集群处理一次请求，都需要经过集群中大部分节点协商。所以一个Raft集群的规模一般不会太大，否则协商的代价就会比较大。那么如果希望基于Raft实现一些规模比较大的服务该怎么扩展呢？&lt;/p&gt;
&lt;p&gt;例如我们想做一个
      
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="Raft" scheme="liqul.github.io/blog/tags/Raft/"/>
    
  </entry>
  
  <entry>
    <title>《人为制造的脆弱性》--读后感</title>
    <link href="liqul.github.io/blog/banks/"/>
    <id>liqul.github.io/blog/banks/</id>
    <published>2018-09-20T14:04:03.000Z</published>
    <updated>2018-09-20T14:35:14.167Z</updated>
    
    <content type="html"><![CDATA[<p>断断续续读了一遍《人为制造的脆弱性》。作者在第一部分里已经基本讲明了自己的观点，后面几部分只是列举一些国家佐证自己的论点，所以我也只重点看了前面前两个部分，后面的部分大致翻看了几眼。这本书现在可以在网上<a href="https://yuedu.baidu.com/ebook/9d86229dcd22bcd126fff705cc175" target="_blank" rel="noopener">直接看</a>。</p><p>刚开始读的时候就被前两段话吸引了，一个好的开头的确能起到吸引读者的作用，贴在下面：</p><blockquote><p>每个人都知道生活是不公平的，即所谓“政治在起作用”。当最钟爱的电影痛失奥斯卡奖时，我们会这样说；当办公室最底层的蠢人陪领导打高尔夫而获得了本应属于我们的升职机会时，我们会这么说；当发现一座毫无用途的大桥得以建成，仅仅是因为某个很有权势的参议员将联邦基础设施建设资金带回了家乡时，我们会这么说；当发现一个有关系的企业家获得数百亿政府补贴去组建一个根本不可能有竞争力的公司时，我们也会这么说。</p></blockquote><a id="more"></a><blockquote><p>我们意识到政治无处不在，有时却认为银行业危机是去政治化的，就如同地震和冰雹灾害一样，银行业危机是一种无法预知的非常规情形。我们之所以相信这种观点，是因为它作为一种正式言论屡屡被央行和财政部官员们提及，然后又被财经记者和电视台主播不断重复。在这一不断重复的故事里，那些有着良好意图且专业娴熟的人竭尽全力去建立高效的金融机构，有效分配信贷，并处理不断出现的问题。但他们不是全能的。他们不能预见每一个可能出现的意外事故，有时还会遭遇一连串噩运。“经济冲击”可能无法预见，它会动摇原本平稳运行的经济体系。在这个故事里，经济危机就如列夫托尔斯泰所说的“不幸的家庭各有各的不幸”。</p></blockquote><p>读完这两段话后，我意识到我以前也是这样认为的。我不知道我的这种思维根源来自哪里，或许是像我以前对历史的认知一样，认为“天下大势，合久必分分久必合”，所以王朝更替不过是个自然现象。但是当你仔细检查每个场景的时候，却发现这种宏观的高度概括的理解是毫无意义的，因为你无法总结任何可执行的经验。另一方面，作者提出需要极力避免从个人道德方面来得出结论，因为个人道德是一种随机事件，而隐藏在个人随机事件底下的趋势才是值得研究的。</p><p><img src="/blog/assets/banking.jpg" height="250"></p><center>图1:不同政治体制下的银行业</center><p>这本书的中心思想实际上也就在这两段话里：<strong>银行业是与政治是密不可分的</strong>。为什么呢？因为无论在民主国家还是威权国家，银行业总是不可避免的依赖政府提供的各项“照顾”，而政府也依赖银行来达到其政治目的。在不同的政治体制下，银行业和政治的关系表现形式是不同的。例如在威权政治下，不是谁想办银行就能做到的，往往政府控制着严格的准入制度。反过来，如果一家银行被批准了，那么意味着银行需要协助政府来完成一些政治目标，例如优先贷款给政府扶持的行业。如果在腐败的政治环境下，银行甚至可能只贷款给政府和银行内部人士开办的公司。作为经济补偿，政府也往往需要给银行兜底以减少其风险，同时利用暴力机器维护银行的利益。作者以墨西哥为例，详细讨论了墨西哥银行业的发展历史。正是由于威权政府治下的银行通常只照顾政府直接或间接指定的企业，范围之外的企业难以获得信贷，所以没有特殊关系的民营企业很难利用银行提供的信贷来发展和壮大。</p><p>看到这里想起在去年底之前，我一直以为银行的主要业务时吸纳储户的存款，并把存款放贷出去收取利息。这种想法真是“很傻很天真”，实际上现代商业银行体系承担着“发行”货币的职能。可以看看知乎上<a href="https://www.zhihu.com/question/21234062" target="_blank" rel="noopener">这个问题的回答</a>。简而言之你存一张100元的人民币到银行，在现在的制度下，银行大致能放贷700元。你存3年定期的利息可能只有3.2%左右，而贷款的利率大概在6%左右。在各行各业中，想必能如此做生意的也就只有银行了吧。那么是谁允许它们这样做的呢？</p><p>民主政治看起来要好的多，但仍然避免不了政治和银行业的勾结而导致恶果。作者以美国为例，从银行业的角度介绍了08年次贷危机的前因后果。虽然次贷危机在08年爆发，但早在90年代就已经埋下伏笔。随着全球化的发展，美国的贫富分化加剧，出现了一个批聚集在城市的低收入者，导致社会矛盾不断尖锐。</p><p><img src="/blog/assets/08finance.png" height="200"></p><center>图2:次贷危机中的四方同盟</center><p>随着人数增多，这些低收入者逐渐形成了一股政治势力。在民主选举的国家里人数众多就能产生足够的政治影响力。进而国会选举时，选举人也不得不考虑得到他们的支持。但如何才能得到支持呢？政治家无法直接为他们提供高福利，因为那需要动用财政收入（即税收），直接侵害其他纳税人的利益。于是“聪明”的政治家们想到了一个绝妙的主意——为他们提供廉价的贷款来让他们过上好日子。然而，代表着政治家的国会无法直接迫使银行来做这种看起来低回报高风险的生意，所以还需要一个机会。这个机会就是上世纪八九十年代的美国银行业扩张。</p><p>美国本土的银行业在早期的状况是全国各地遍布小银行，却没有形成全国性的大银行，而这源于美国人根深蒂固的一些观念。《美联储的诞生》这本书里就反复的在强调美国人对全国性的银行极度反感，认为这会侵害所有人的利益。而这一问题在八九十年代发生了改变，政府开始允许银行间的兼并，但前提是要得到银行当地社区的同意。银行希望一些低收入社区批准兼并计划，而低收入者则希望获得廉价贷款。这似乎与国会没有关系，当然不是，因为银行是不可能自己来承受这种高风险的生意。于是政府拉入了第四个博弈方，即两房（房利美和房地美），由两房来购买银行的贷款从而降低银行自身的风险。当然，在国会的支持下，两房享受着很多政治特权，例如可以提供更低的保证金和加更高的杠杆。就这样，一个四方同盟形成了。</p><p>在次贷危机爆发的前几年里，这个同盟在不断的强化自己。住房贷款从最初的要求20%首付和收入证明变成仅需3%的首付且不需要收入证明。房地产的泡沫不断加剧，监管部门对此则视而不见。并非他们道德败坏，或愚蠢到看不到泡沫的存在，而是在那个时间点，任何反对政策都很难被执行，因为那样做似乎会损害所有同盟成员的利益。看到这里，就好像所有人都在狂欢，冷静的人只能悄悄离场而无法提醒别人。如果所有人都不愿意停止这场狂欢，最后会由谁来买单呢？答案是隐藏在背后的纳税人。如果一个企业已经能做到“大而不倒”，那么就意味着所有纳税人都需要为它买单，不管你愿意还是不愿意。</p><p>同样的事情不会发生两次，但类似的事情却在不断重复，次贷危机中这种资产是房地产，而下一次则可能是股票。因此，要做的并不是去空谈所谓水满则溢、月盈则亏，因为那没有任何可操作性。当然，对于无法承受任何风险的人来讲，永远不要触碰投资或许是最为稳妥的策略，但那仍然无法摆脱你被动为一些“大而不倒”的东西买单，同时你也失去了利用这种坏的机遇的机会。就好比中国的房价，即使你认定中国的房价不合理，也完全没有必要带有情绪去声讨，如果你能看清楚房价上涨的本质，并且你有能力早一点买房，至少你应该明白这可以抵御通胀造成的货币贬值。按照达里奥（Ray Dalio）的意思，在整体环境加杠杆的过程中，如果你不加则会有机会成本，而且物价上涨也会导致你实际收入下降。但是，如果在降杠杆的过程中，你还要逆势加杠杆，恐怕就是自找麻烦了。如果理性看待，泡沫的破裂其实是自由市场自我修复的一个重要手段，因为人性是贪婪的，所以做到理性的及时调整就变得非常困难，所以不得不借助这种阵痛来实现动态平衡。</p><p>如果能顺应这种趋势，即使不能赚到很多钱但也至少能抵抗不必要的损失。当然，如何能洞察这些经济潜流呢？我也不知道，但我知道每一个趋势都不是一两天，甚至不是一两年能形成的。好比次贷危机经历了90年代末的积累，在08年才真正爆发出来。而在这漫长的过程中，如果理性观察应该是能发现这些问题的。但是，如果你沉迷于自己的思维习惯而停止学习，那么即使一些显而易见的现象摆在你眼前，你也会熟视无睹的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;断断续续读了一遍《人为制造的脆弱性》。作者在第一部分里已经基本讲明了自己的观点，后面几部分只是列举一些国家佐证自己的论点，所以我也只重点看了前面前两个部分，后面的部分大致翻看了几眼。这本书现在可以在网上&lt;a href=&quot;https://yuedu.baidu.com/ebook/9d86229dcd22bcd126fff705cc175&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;直接看&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;刚开始读的时候就被前两段话吸引了，一个好的开头的确能起到吸引读者的作用，贴在下面：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;每个人都知道生活是不公平的，即所谓“政治在起作用”。当最钟爱的电影痛失奥斯卡奖时，我们会这样说；当办公室最底层的蠢人陪领导打高尔夫而获得了本应属于我们的升职机会时，我们会这么说；当发现一座毫无用途的大桥得以建成，仅仅是因为某个很有权势的参议员将联邦基础设施建设资金带回了家乡时，我们会这么说；当发现一个有关系的企业家获得数百亿政府补贴去组建一个根本不可能有竞争力的公司时，我们也会这么说。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Reading" scheme="liqul.github.io/blog/categories/Reading/"/>
    
    
  </entry>
  
  <entry>
    <title>Raft协议实现学习之—概览</title>
    <link href="liqul.github.io/blog/etcd_raft_1/"/>
    <id>liqul.github.io/blog/etcd_raft_1/</id>
    <published>2018-09-13T07:50:03.000Z</published>
    <updated>2018-09-26T02:31:59.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="raft协议概览">Raft协议概览</span></h1><h2><span id="raft是什么">Raft是什么？</span></h2><p>Raft是一种共识协议。与Raft完成相同任务的系统有Chubby和Zookeeper，以及一些系统内置的完成类似功能的组件，例如Elasticsearch里的Zen-Discovery。简而言之，共识协议的目的是让一组节点在响应外界输入时能表现的像一个节点一样。共识系统往往应用于有主备结构的存储系统中，如果缺少这种协议，就无法避免数据<a href="http://www.bailis.org/blog/when-does-consistency-require-coordination/" target="_blank" rel="noopener">错误</a>。</p><a id="more"></a><p>共识协议非常重要，而且实现起来往往很容易犯错，因此大部分系统都依赖已经久经考验的系统，比如Zookeeper。选择自己实现共识组件需要莫大的勇气，看看<a href="https://www.elastic.co/guide/en/elasticsearch/resiliency/current/index.html" target="_blank" rel="noopener">这里</a>就知道Elasticsearch曾经出现过许多一致性问题bug，而且还有一些没有被fix。Raft的提出是针对Paxos的，目的是为了提出一种容易被理解的共识协议。容易被理解也就意味着便于维护，不会有许多看起来”黑魔法“一样的技巧。</p><p>之前在<a href="/blog/the-raft-consensus-algorithm/">这篇</a>文章里已经有一些关于Raft的讨论。这次重新看Raft是希望基于etcd/raft的实现来详细梳理一遍其中的细节。Raft对一些需要实现强一致性的操作是如此重要，值得反复学习。</p><p>这个系列里一些重要参考的来源：</p><ol><li><a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="noopener">Raft thesis</a>：Raft作者的论文</li><li><a href="https://github.com/etcd-io/etcd/tree/master/contrib/raftexample" target="_blank" rel="noopener">etcd/contrib/raftexample</a>和<a href="https://github.com/etcd-io/etcd/tree/master/raft" target="_blank" rel="noopener">etcd/raft</a>：etcd里Raft的实现代码</li><li><a href="http://otm.github.io/2015/05/raft-a-first-implementation/" target="_blank" rel="noopener">Raft:a first implementation</a>：一篇有关如何简单使用etcd/raft库的blog</li></ol><h2><span id="节点的三种状态">节点的三种状态</span></h2><p>在一个正常运行状态（即集群能正常处理外部操作请求的情况）下的Raft集群中，节点分为leader和follower两种角色。其lLeader有且仅有一个，负责处理外部的操作请求；follower有多个，它们从属于leader，负责处理来自leader的指令。</p><p><img src="/blog/assets/raft_state_machine.png"><br>图1. Raft节点的状态转移图（原图Figure 3.3）</p><p>一个Raft节点有三种状态：follower、candidate和leader。图1中描述了三种状态之间的转移条件。正常运行状态下的节点要么处于follower状态，要么处于leader状态，而candidate属于follower和leader之间的中间状态，也是节点在非正常运行状态下所处的状态。</p><p>节点的初始状态是follower。当一个节点启动后，其状态即为follower。此后受到不同事件触发的影响会变更自己状态。Raft集群中的节点都会采用定期”广播“自己的状态。节点处于follower状态下，如果定期能接收到来自leader广播的消息，那么它会一直处于follower状态，而不会转移到candidate状态。</p><p>多个节点竞选leader的过程称为leader election，这是Raft协议中最重要的过程之一，将在后续分析代码时再详细梳理。需要稍微注意图1并不是完全的状态转移图，例如图1中并未包含节点在follower状态下接收到广播消息或选举消息的状态变化情况。此外，还有一个细节问题，若某个异常节点主动发起选举，那么其它节点监听到的选举消息里的term比自己当前的更大，那么其它节点是否应该参与选举呢？答案在Raft thesis的4.2.3章。所以图1只是一个基本的状态转移概览。</p><h2><span id="log">Log</span></h2><p>Term是Raft中用来计量时间的概念，可以理解为<strong>阶段</strong>。当一个节点被选举为leader后，Raft系统进入稳定运行状态，随后如果leader节点停机则会进入下一轮选举。这里从上一次选举成功到下一次选举之间的时间即一个term。节点初始化的时候term=0,随后term越大也就意味着状态越新，term是单调增加的。处在正常运行状态下的所有Raft节点都有相同的term，所以如果一个节点监听到的来自其它节点的消息里包含的term比自己的更大，那么说明它自己处于异常状态；反之如果监听到消息里的term比自己的更小，那么这样的消息可以直接忽略掉。</p><p><img src="/blog/assets/logs.png"><br>图2. Raft协议中的日志备份（原图Figure 3.5）</p><p>每条log对应一次请求，也唯一对应一个term。除了term以为，每条log在每个节点上还有一个唯一的index。如图2中所示，index是单调连续增加的自然数，这意味着任意节点上都不会出现index空缺。在稳定情况下，follower的log可以比leader落后，但不会出现不一致。例如，如果leader的index=4对应的log内容是x&lt;-2且term=2，那么在所有follower上index=4的log都应该与leader相同。如果发生leader切换，在短期内有可能出现不一致的情况，但随后leader会要求所有follower完全复制自己的log（不一致的部分将被删除），那么等到稳定状态下，大家的log又会回到一致的状态。</p><h2><span id="请求处理工作流">请求处理工作流</span></h2><p>Raft最核心的工作是使一组节点对来自外界的请求作出一致的反应。在一个正常运行的Raft集群里，只有leader能回应外部请求。这一点需要牢记，如果当前的leader因为停机而失效，那么必须等选举出下一个leader之后集群才能对外服务。在选举的过程中，集群是无法服务的，这会影响服务的HA，但又是得到强一致性操作必须的代价。图2是Raft集群的工作过程示意图。</p><p><img src="/blog/assets/replicated_state_machine.png"><br>图3. Raft集群的工作过程（原图Figure 2.1）</p><p>在图3中，client发出外部写入请求(1)，Raft集群的leader接收该请求后将请求内容写入本地log，同时将请求内容转发给所有follower(2)。每个follower在接收到请求后将内容写入自己本地log，并通知leader自己已经完成操作（这个步骤图2中没有标出）。leader一旦接收到大多数follower已经完成备份则把请求内容commit到本地的状态机（state machine），完成该操作后回复client写入完成(4)。随后在leader的广播里会包含最新的被commit的log序号，各follower监听到以后将写入操作commit到本地状态机。</p><p>图4精确描述了Raft基本协议中各角色的事件处理状态机。一些国外课程以Raft来作为课程作业，比如<a href="https://thesquareplanet.com/blog/students-guide-to-raft/" target="_blank" rel="noopener">这里</a>，提到：</p><blockquote><p>In fact, Figure 2 is extremely precise, and every single statement it makes should be treated, in specification terms, as MUST, not as SHOULD.</p></blockquote><p>文中的Figure 2就是图4。这张图算是对Raft基本协议作了一个非常精确又详尽的总结。</p><p><img src="/blog/assets/raft_protocol_basic.png"><br>图4. Raft基本协议（原图Figure 3.1)</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Raft协议概览&quot;&gt;&lt;a href=&quot;#Raft协议概览&quot; class=&quot;headerlink&quot; title=&quot;Raft协议概览&quot;&gt;&lt;/a&gt;Raft协议概览&lt;/h1&gt;&lt;h2 id=&quot;Raft是什么？&quot;&gt;&lt;a href=&quot;#Raft是什么？&quot; class=&quot;headerlink&quot; title=&quot;Raft是什么？&quot;&gt;&lt;/a&gt;Raft是什么？&lt;/h2&gt;&lt;p&gt;Raft是一种共识协议。与Raft完成相同任务的系统有Chubby和Zookeeper，以及一些系统内置的完成类似功能的组件，例如Elasticsearch里的Zen-Discovery。简而言之，共识协议的目的是让一组节点在响应外界输入时能表现的像一个节点一样。共识系统往往应用于有主备结构的存储系统中，如果缺少这种协议，就无法避免数据&lt;a href=&quot;http://www.bailis.org/blog/when-does-consistency-require-coordination/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;错误&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="Raft" scheme="liqul.github.io/blog/tags/Raft/"/>
    
  </entry>
  
  <entry>
    <title>Raft协议实现学习之—etcd/raft库的使用</title>
    <link href="liqul.github.io/blog/etcd_raft_2/"/>
    <id>liqul.github.io/blog/etcd_raft_2/</id>
    <published>2018-09-13T07:50:03.000Z</published>
    <updated>2018-10-08T08:32:21.000Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="etcd中的raft协议实现">Etcd中的Raft协议实现</span></h1><p>Etcd里Raft协议的实现的在<a href="https://github.com/etcd-io/etcd/tree/master/raft" target="_blank" rel="noopener">这里</a>。etcd并不是Raft的唯一实现，事实上Raft协议有<a href="https://raft.github.io/#implementations" target="_blank" rel="noopener">许多实现</a>，还有我简单尝试过的<a href="https://github.com/atomix/" target="_blank" rel="noopener">atomix</a>。选择etcd/raft是因为个人对etcd和go语言比较感兴趣，而且Raft论文里提到的实现方法恰好比较适合用go语言的goroutine来实现。</p><p>另外的一个原因正如etcd/raft在github上的readme所说：</p><blockquote><p>To keep the codebase small as well as provide flexibility, the library only implements the Raft algorithm; both network and disk IO are left to the user. Library users must implement their own transportation layer for message passing between Raft peers over the wire. Similarly, users must implement their own storage layer to persist the Raft log and state.</p></blockquote><a id="more"></a><p>etcd/raft采取了一种极简的实现方式，只有最核心的状态转移逻辑，不包含网络通信和磁盘读写，所以比较方便对照论文来梳理代码的实现。</p><h2><span id="etcdraft与用户系统的关系">Etcd/raft与用户系统的关系</span></h2><p>图1描述了基于etcd/raft完成一个分布式存储系统的一般结构。每个节点分为两部分，左边是用户需要自己实现的部分，右边代表etcd/raft库。在用户实现的逻辑中，首先是系统状态（State machine）。系统状态是与应用相关的，例如对于key-value store来说，它的系统状态可以描述为一个key-&gt;value的映射关系。正是由于系统状态是应用相关的，所以它必须由用户来实现，同时用户还必须实现系统状态的序列化和反序列化用于快照。</p><p><img src="/blog/assets/raft_modules.png" height="250"><br>图1. Raft实现模块关系示例实现的是一个key-value store，而其主要的结构体如下</p><p>需要特别注意系统状态并不是Raft协议的一部分。在基于Raft实现分布式系统的时候，可以采用这样的思路：先实现一个单机的功能齐备的系统，然后再利用Raft协议将它扩展到多节点模式。显然在这个单机系统中，系统状态及其维护都需要用户自己来实现，所以它并不是Raft协议的一部分。当然，并不是所有的单机系统都可以直接依赖Raft协议扩展到多个节点的，因为Raft协议本质上是多节点日志备份系统，这要求系统状态必须能描述为一组日志序列。</p><p>网络模块（Net）和持久化存储（Persistent store）分别提供节点间通信能力和持久化能力。Raft协议需要节点间通信来协同操作，而etcd/raft库本身不实现通信功能，而是每当节点间需要通信时把消息交给用户实现的网络模块发送到其它节点。同样，etcd/raft也不提供持久化能力，而节点需要将一些有用信息保存在持久化存储中，以便能在程序意外退出恢复时读取这些信息。</p><p>Etcd/raft库里与用户实现交互的逻辑由node完成（代码在node.go）。Node接收来自用户实现逻辑的大部分输入（除来自其它节点的网络消息外），此外还负责将raft状态机（代码在raft.go）输出的行动通过Ready结构发送到用户实现逻辑。用户逻辑与Raft之间共享一个存储结构Storage（代码在storage.go），对于两边都要读写的结构，需要锁来避免读写冲突。</p><h2><span id="一个可运行的示例">一个可运行的示例</span></h2><p>代码库里已经有一些关于如何使用的示例，但并没有一个完整的例子。而官方给出的<a href="https://github.com/etcd-io/etcd/tree/master/contrib/raftexample" target="_blank" rel="noopener">raftexample</a>例子由于依赖了etcd里的rafthttp和wal，引入了一些不利于梳理的内容。所幸这篇<a href="http://otm.github.io/2015/05/raft-a-first-implementation/" target="_blank" rel="noopener">blog</a>里作者提供了一个可以运行的最简单的示例，方便用作学习，对应的代码库在<a href="http://github.com/otm/raft-part-1" target="_blank" rel="noopener">这里</a>。由于作者实现的时间较早，代码引用的是旧的库地址</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"github.com/coreos/etcd/raft"</span></span><br><span class="line"><span class="string">"github.com/coreos/etcd/raft/raftpb"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//改成下面</span></span><br><span class="line"></span><br><span class="line"><span class="string">"go.etcd.io/etcd/raft"</span></span><br><span class="line"><span class="string">"go.etcd.io/etcd/raft/raftpb"</span></span><br></pre></td></tr></table></figure><p>主体的数据结构如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> node <span class="keyword">struct</span> &#123;</span><br><span class="line">id     <span class="keyword">uint64</span>   <span class="comment">//raft节点的id</span></span><br><span class="line">ctx    context.Context <span class="comment">//context</span></span><br><span class="line">pstore <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span> <span class="comment">//用来保存key-&gt;value的map</span></span><br><span class="line">store  *raft.MemoryStorage <span class="comment">//raft需要的内存结构</span></span><br><span class="line">cfg    *raft.Config <span class="comment">//raft需要的配置</span></span><br><span class="line">raft   raft.Node    <span class="comment">//前面提到的node</span></span><br><span class="line">ticker &lt;-<span class="keyword">chan</span> time.Time <span class="comment">//定时器，提供周期时钟源和超时触发能力</span></span><br><span class="line">done   &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码示例里pstore实际上就是key-value store的存储结构。为了使用etcd/raft库，按照github里的<a href="https://github.com/etcd-io/etcd/tree/master/raft" target="_blank" rel="noopener">readme</a>所说，用户需要完成下面一些功能：</p><blockquote><p>First, read from the Node.Ready() channel and process the updates it contains. These steps may be performed in parallel, except as noted in step 2.</p><p>1.. 2.. 3.. 4..</p></blockquote><p>用户需要监听和处理Ready消息，上面引用里的4点内容较多在此省略。其中的要点是在执行任何操作之前都需要先持久化一些状态，这与<a href="/blog/etcd_raft_1">上一篇</a>文章中图2的工作原理是对应的。</p><blockquote><p>Second, all persisted log entries must be made available via an implementation of the Storage interface. The provided MemoryStorage type can be used for this (<strong>if repopulating its state upon a restart</strong>), or a custom disk-backed implementation can be supplied.</p></blockquote><p>用户需要实现Storage接口来存储必要的信息。MemoryStorage是库提供的一个基于内存的实现，本身并不能进行持久化。用户能自己增加逻辑来实现MemoryStorage的持久化。</p><blockquote><p>Third, after receiving a message from another node, pass it to Node.Step().</p></blockquote><p>如果接收到来自其它节点的消息，通过Step方法传递到raft的状态机。</p><blockquote><p>Finally, call Node.Tick() at regular intervals (probably via a time.Ticker). Raft has two important timeouts: heartbeat and the election timeout. However, internally to the raft package time is represented by an abstract “tick”.</p></blockquote><p>提供一个周期性的时钟定时触发Tick方法。</p><p>在示例实现里完成上述逻辑的代码如下（以First、Second、Third、Finally与上面的描述对应）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Ready的处理逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">run</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-n.ticker:    <span class="comment">// Finally</span></span><br><span class="line">n.raft.Tick()</span><br><span class="line"><span class="keyword">case</span> rd := &lt;-n.raft.Ready():    <span class="comment">//First</span></span><br><span class="line">n.saveToStorage(rd.HardState, rd.Entries, rd.Snapshot) <span class="comment">//First.1</span></span><br><span class="line">n.send(rd.Messages) <span class="comment">//First.2</span></span><br><span class="line"><span class="keyword">if</span> !raft.IsEmptySnap(rd.Snapshot) &#123;</span><br><span class="line">n.processSnapshot(rd.Snapshot) <span class="comment">//First.3</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> _, entry := <span class="keyword">range</span> rd.CommittedEntries &#123;</span><br><span class="line">                <span class="comment">// 对于key-value store这个应用，用户真正需要关心的只有下面这行</span></span><br><span class="line">n.process(entry) <span class="comment">//First.3</span></span><br><span class="line"><span class="keyword">if</span> entry.Type == raftpb.EntryConfChange &#123;</span><br><span class="line"><span class="keyword">var</span> cc raftpb.ConfChange</span><br><span class="line">cc.Unmarshal(entry.Data)</span><br><span class="line">n.raft.ApplyConfChange(cc)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">n.raft.Advance() <span class="comment">//First.4</span></span><br><span class="line"><span class="keyword">case</span> &lt;-n.done:</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Second. 作者并未实现Storage的持久化，所以这里只有MemoryStore的操作</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">saveToStorage</span><span class="params">(hardState raftpb.HardState, entries []raftpb.Entry, snapshot raftpb.Snapshot)</span></span> &#123;</span><br><span class="line">n.store.Append(entries)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> !raft.IsEmptyHardState(hardState) &#123;</span><br><span class="line">n.store.SetHardState(hardState)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> !raft.IsEmptySnap(snapshot) &#123;</span><br><span class="line">n.store.ApplySnapshot(snapshot)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 作者并未实现真正的网络模块，只是模拟了节点间的收发消息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">receive</span><span class="params">(ctx context.Context, message raftpb.Message)</span></span> &#123;</span><br><span class="line">n.raft.Step(ctx, message) <span class="comment">//Third</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Etcd/raft库的使用大致如代码示例里描述。当然，这里做了不少简化，例如：</p><ol><li>没有实现节点间的网络通信；</li><li>没有实现可持久化的存储；</li><li>没有实现快照的生成和处理逻辑；</li><li>用户Application是单线程的；</li></ol><p>这些将在后续的文章中逐步梳理和学习。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Etcd中的Raft协议实现&quot;&gt;&lt;a href=&quot;#Etcd中的Raft协议实现&quot; class=&quot;headerlink&quot; title=&quot;Etcd中的Raft协议实现&quot;&gt;&lt;/a&gt;Etcd中的Raft协议实现&lt;/h1&gt;&lt;p&gt;Etcd里Raft协议的实现的在&lt;a href=&quot;https://github.com/etcd-io/etcd/tree/master/raft&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;。etcd并不是Raft的唯一实现，事实上Raft协议有&lt;a href=&quot;https://raft.github.io/#implementations&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;许多实现&lt;/a&gt;，还有我简单尝试过的&lt;a href=&quot;https://github.com/atomix/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;atomix&lt;/a&gt;。选择etcd/raft是因为个人对etcd和go语言比较感兴趣，而且Raft论文里提到的实现方法恰好比较适合用go语言的goroutine来实现。&lt;/p&gt;
&lt;p&gt;另外的一个原因正如etcd/raft在github上的readme所说：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To keep the codebase small as well as provide flexibility, the library only implements the Raft algorithm; both network and disk IO are left to the user. Library users must implement their own transportation layer for message passing between Raft peers over the wire. Similarly, users must implement their own storage layer to persist the Raft log and state.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="Raft" scheme="liqul.github.io/blog/tags/Raft/"/>
    
  </entry>
  
  <entry>
    <title>Raft协议实现学习之—初始化和Leader Election过程</title>
    <link href="liqul.github.io/blog/etcd_raft_3/"/>
    <id>liqul.github.io/blog/etcd_raft_3/</id>
    <published>2018-09-13T07:50:03.000Z</published>
    <updated>2018-11-23T06:35:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="实验代码和输出">实验代码和输出</span></h2><p>实验代码是基于作者<a href="http://github.com/otm/raft-part-1" target="_blank" rel="noopener">原来的代码</a>稍微修改而来，main函数如下所示:<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">nodes = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int</span>]*node)</span><br><span class="line">)</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// start a small cluster</span></span><br><span class="line">nodes[<span class="number">1</span>] = newNode(<span class="number">1</span>, []raft.Peer&#123;&#123;ID: <span class="number">1</span>&#125;, &#123;ID: <span class="number">2</span>&#125;, &#123;ID: <span class="number">3</span>&#125;&#125;)</span><br><span class="line"><span class="keyword">go</span> nodes[<span class="number">1</span>].run()</span><br><span class="line"></span><br><span class="line">nodes[<span class="number">2</span>] = newNode(<span class="number">2</span>, []raft.Peer&#123;&#123;ID: <span class="number">1</span>&#125;, &#123;ID: <span class="number">2</span>&#125;, &#123;ID: <span class="number">3</span>&#125;&#125;)</span><br><span class="line"><span class="keyword">go</span> nodes[<span class="number">2</span>].run()</span><br><span class="line"></span><br><span class="line">nodes[<span class="number">3</span>] = newNode(<span class="number">3</span>, []raft.Peer&#123;&#123;ID: <span class="number">1</span>&#125;, &#123;ID: <span class="number">2</span>&#125;, &#123;ID: <span class="number">3</span>&#125;&#125;)</span><br><span class="line"><span class="keyword">go</span> nodes[<span class="number">3</span>].run()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Wait for leader election</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">time.Sleep(<span class="number">100</span> * time.Millisecond)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在上面的这段代码里首先创建了3个节点，然后程序进入休眠等待节点竞争leader。程序的输出如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 阶段1：节点初始化数据结构</span></span><br><span class="line">17:40:03 INFO: 1 became follower at term 0</span><br><span class="line">17:40:03 INFO: newRaft 1 [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]</span><br><span class="line">17:40:03 INFO: 1 became follower at term 1</span><br><span class="line">17:40:03 INFO: 2 became follower at term 0</span><br><span class="line">17:40:03 INFO: newRaft 2 [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]</span><br><span class="line">17:40:03 INFO: 2 became follower at term 1</span><br><span class="line">17:40:03 INFO: 3 became follower at term 0</span><br><span class="line">17:40:03 INFO: newRaft 3 [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]</span><br><span class="line">17:40:03 INFO: 3 became follower at term 1</span><br><span class="line"><span class="comment"># 阶段2：节点处理配置的peer列表</span></span><br><span class="line">17:40:03 node 1: processing entry: &#123;1 1 EntryConfChange [8 0 16 0 24 1] []&#125;</span><br><span class="line">17:40:03 node 1: processing entry: &#123;1 2 EntryConfChange [8 0 16 0 24 2] []&#125;</span><br><span class="line">17:40:03 node 1: processing entry: &#123;1 3 EntryConfChange [8 0 16 0 24 3] []&#125;</span><br><span class="line">17:40:03 node 2: processing entry: &#123;1 1 EntryConfChange [8 0 16 0 24 1] []&#125;</span><br><span class="line">17:40:03 node 3: processing entry: &#123;1 1 EntryConfChange [8 0 16 0 24 1] []&#125;</span><br><span class="line">17:40:03 node 3: processing entry: &#123;1 2 EntryConfChange [8 0 16 0 24 2] []&#125;</span><br><span class="line">17:40:03 node 3: processing entry: &#123;1 3 EntryConfChange [8 0 16 0 24 3] []&#125;</span><br><span class="line">17:40:03 node 2: processing entry: &#123;1 2 EntryConfChange [8 0 16 0 24 2] []&#125;</span><br><span class="line">17:40:03 node 2: processing entry: &#123;1 3 EntryConfChange [8 0 16 0 24 3] []&#125;</span><br><span class="line"><span class="comment"># 阶段3：节点1开启新一轮leader election</span></span><br><span class="line">17:40:19 INFO: 1 is starting a new election at term 1</span><br><span class="line">17:40:19 INFO: 1 became candidate at term 2</span><br><span class="line"><span class="comment"># 阶段4：节点1向节点2和3发送MsgVote</span></span><br><span class="line">17:40:19 INFO: 1 received MsgVoteResp from 1 at term 2</span><br><span class="line">17:40:19 INFO: 1 [logterm: 1, index: 3] sent MsgVote request to 2 at term 2</span><br><span class="line">17:40:19 INFO: 1 [logterm: 1, index: 3] sent MsgVote request to 3 at term 2</span><br><span class="line"><span class="comment"># 阶段5：节点2和3处理来自节点1的MsgVote请求</span></span><br><span class="line">17:40:19 1-&gt;2 MsgVote Term:2 Log:1/3</span><br><span class="line">17:40:19 1-&gt;3 MsgVote Term:2 Log:1/3</span><br><span class="line">17:40:19 INFO: 2 [term: 1] received a MsgVote message with higher term from 1 [term: 2]</span><br><span class="line">17:40:19 INFO: 2 became follower at term 2</span><br><span class="line">17:40:19 INFO: 2 [logterm: 1, index: 3, vote: 0] cast MsgVote <span class="keyword">for</span> 1 [logterm: 1, index: 3] at term 2</span><br><span class="line">17:40:19 2-&gt;1 MsgVoteResp Term:2 Log:0/0</span><br><span class="line">17:40:19 INFO: 1 received MsgVoteResp from 2 at term 2</span><br><span class="line"><span class="comment"># 阶段6：节点1成功成为leader</span></span><br><span class="line">17:40:19 INFO: 1 [quorum:2] has received 2 MsgVoteResp votes and 0 vote rejections</span><br><span class="line">17:40:19 INFO: 3 [term: 1] received a MsgVote message with higher term from 1 [term: 2]</span><br><span class="line">17:40:19 INFO: 1 became leader at term 2</span><br><span class="line">17:40:19 INFO: 3 became follower at term 2</span><br><span class="line">17:40:19 INFO: raft.node: 1 elected leader 1 at term 2</span><br><span class="line">17:40:19 INFO: 3 [logterm: 1, index: 3, vote: 0] cast MsgVote <span class="keyword">for</span> 1 [logterm: 1, index: 3] at term 2</span><br><span class="line"><span class="comment"># 阶段7：节点1成为leader后向其它节点广播MsgApp</span></span><br><span class="line">17:40:19 1-&gt;2 MsgApp Term:2 Log:1/3 Commit:3 Entries:[2/4 EntryNormal <span class="string">""</span>]</span><br><span class="line">17:40:19 3-&gt;1 MsgVoteResp Term:2 Log:0/0</span><br><span class="line">17:40:19 INFO: raft.node: 2 elected leader 1 at term 2</span><br><span class="line">17:40:19 1-&gt;3 MsgApp Term:2 Log:1/3 Commit:3 Entries:[2/4 EntryNormal <span class="string">""</span>]</span><br><span class="line">17:40:19 2-&gt;1 MsgAppResp Term:2 Log:0/4 <span class="comment"># 这里2汇报已经保存了新的entry</span></span><br><span class="line">17:40:19 INFO: raft.node: 3 elected leader 1 at term 2</span><br><span class="line">17:40:19 1-&gt;2 MsgApp Term:2 Log:2/4 Commit:4 <span class="comment"># 在这里commit从3变成4</span></span><br><span class="line">17:40:19 3-&gt;1 MsgAppResp Term:2 Log:0/4 </span><br><span class="line">17:40:19 node 1: processing entry: &#123;2 4 EntryNormal [] []&#125; <span class="comment"># 由于已经确认大部分节点都保存成功，可以apply到state machine</span></span><br><span class="line">17:40:19 1-&gt;3 MsgApp Term:2 Log:2/4 Commit:4</span><br><span class="line">17:40:19 2-&gt;1 MsgAppResp Term:2 Log:0/4</span><br><span class="line">17:40:19 node 2: processing entry: &#123;2 4 EntryNormal [] []&#125; <span class="comment"># 2在接收到来自1的MsgApp后得知commit=4，可以apply到本地的state machie</span></span><br><span class="line">17:40:19 3-&gt;1 MsgAppResp Term:2 Log:0/4</span><br><span class="line">17:40:19 node 3: processing entry: &#123;2 4 EntryNormal [] []&#125;</span><br><span class="line"><span class="comment"># 阶段8：进入心跳阶段</span></span><br><span class="line">17:40:20 1-&gt;2 MsgHeartbeat Term:2 Log:0/0 Commit:4</span><br><span class="line">17:40:20 1-&gt;3 MsgHeartbeat Term:2 Log:0/0 Commit:4</span><br><span class="line">17:40:20 2-&gt;1 MsgHeartbeatResp Term:2 Log:0/0</span><br><span class="line">17:40:20 3-&gt;1 MsgHeartbeatResp Term:2 Log:0/0</span><br><span class="line">17:40:21 1-&gt;2 MsgHeartbeat Term:2 Log:0/0 Commit:4</span><br><span class="line">17:40:21 1-&gt;3 MsgHeartbeat Term:2 Log:0/0 Commit:4</span><br><span class="line">17:40:21 2-&gt;1 MsgHeartbeatResp Term:2 Log:0/0</span><br><span class="line">17:40:21 3-&gt;1 MsgHeartbeatResp Term:2 Log:0/0</span><br></pre></td></tr></table></figure><h2><span id="节点的基本数据结构">节点的基本数据结构</span></h2><p>正常情况下，初始化节点的代码在/raft/node.go里的StartNode方法。每个Node结构都关联到一个raft结构（定义在/raft/raft.go里）。其中Node负责与应用线程交互，而raft负责实现Raft协议的状态机，根据Node的输入raft产生相应的输出。</p><h3><span id="softstate和hardstate">SoftState和HardState</span></h3><p>在实现里有两种状态，稍微说明一下。在Raft作者的<a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="noopener">论文</a>里，图3.1里列举了不同节点需要保存的状态，分为Persistent state和Volatile state。其中Persistent state包括currentTerm、votedFor和log[]，这三个数据的前两个定义在HardState结构里（/raft/raftpb/raft.pb.go），而log[]则在Storage里维护，例如MemoryStorage里的ents数组。与论文不同的地方，在HardState里还包含了Commit，即论文图3.1里Volatile state里的commitIndex（todo:理解这里区别的含义）。SoftState与图中的Volatile state没有直接关系，其中包含了节点当前leader的id，以及节点当前的状态（leader还是follower等）。</p><p>此外，观察etcd/raft的实现发现，在MemoryStorage的初始化过程中，会向ents里写入一个<em>dummy entry</em>；而在ApplySnapshot方法里会在压缩完历史的entry之后初始化ents时写入一个特殊的entry，仅包含snapshot中最后一个entry的term和index。因此，在任何时刻在ents数组中的第一个元素都不是真正的entry，在一些处理过程中需要注意这一点（例如MemoryStorage的FirstIndex接口实现）。</p><h3><span id="log的状态">Log的状态</span></h3><p>完整的管理entry（或称为log）的结构是raftLog（参考/raft/log.go）。其中主要的属性，</p><table><thead><tr><th>属性</th><th>说明</th></tr></thead><tbody><tr><td>unstable</td><td>记录所有收到但未成功复制到多数节点的日志，或尚未持久化的snapshot</td></tr><tr><td>committed</td><td>记录最大的已经被复制到多数节点的日志</td></tr><tr><td>applied</td><td>记录最大的已经被应用到状态机的日志</td></tr><tr><td>storage</td><td>记录已经持久化的日志，和最新的已经持久化的snapshot</td></tr></tbody></table><p>每个entry都应该按照顺序先是unstable，然后是committed，最后才是applied，这个顺序不能乱。unstable和storage分别记录了未持久化和已持久化的entry和snapshot。</p><h3><span id="peer列表">Peer列表</span></h3><p>Raft论文图3.1里，作为leader，还需要维护两个状态，即nextIndex[]和matchIndex[]。这两者的实现在/raft/progress.go里，其中的主要结构体Progress用于记录每个follower节点的进度。其中match和next的定义分别是：</p><ul><li>match：follower与leader间一致的最大的entry</li><li>next：leader下一个要复制到follower的entry</li></ul><p>代码库里专门有一个markdown文件来说明这些概念及其使用方式，在/raft/design.md。正常情况下，follower与leader的entry列表应该完全一样，但由于leader处理新接收到的entry；节点故障而导致新一轮选举；有新节点加入，follower与leader之间出现不一致。这时候leader首先要了解follower的进度与自己进度的区别，此时的follower处于probe状态。如果follower接收并成功复制来自leader的entry，那么follower进入replicate状态，leader一次可以发出大于一条entry以提高传输效率。</p><p>在未了解follower的进度时，leader的行为是设置match=0和next=lastIndex+1。这样做是假定follower已经复制了所有leader上的日志。下一次leader向其follower发起复制的时候，如果follower实际上落后一些，会reject新的日志，并会告知leader自己的当前状态，leader根据情况再协调后续的发送。这里的逻辑参考/raft/raft.go里的handleAppendEntries实现。</p><p>snapshot相关的过程留在后续分析。</p><h2><span id="增加peer节点">增加peer节点</span></h2><p>通常情况下在集群初始化时都会有多个节点，例如在</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nodes[<span class="number">1</span>] = newNode(<span class="number">1</span>, []raft.Peer&#123;&#123;ID: <span class="number">1</span>&#125;, &#123;ID: <span class="number">2</span>&#125;, &#123;ID: <span class="number">3</span>&#125;&#125;)</span><br></pre></td></tr></table></figure><p>里在初始化节点1时就向它的构造方法里传入了三个节点ID。考察StartNode方法（/raft/node.go）可以清楚的看到，对每一个ID，当前都会往日志里主动增加一条ConfChangeAddNode消息。这其实是在模仿节点从网络接收到了增加节点的配置消息，这两者后续的处理逻辑是相同的。</p><p>Raft节点的线程逻辑在node.run方法里。Run的逻辑大致是：</p><ol><li>等待新的触发事件，例如接收到来自用户线程的写入请求；接收到来自网络的消息等等。</li><li>被触发后经过raft.Step来驱动Raft协议状态机，输出一些变化（由containsUpdates来检验）。这些变化可能包括节点状态变化，或者有新的消息要发送，或者有新的log要持久化等等。</li><li>如果有新的变化，那么组织一个Ready结构发送给用户线程，具体的网络和持久化操作都在用户线程完成。</li></ol><p>回到增加peer节点的情况，以advancec和readyc（run方法开头定义的临时变量）为线索来整理执行的流程。下图梳理了用户线程（app.run）和Raft线程（node.run）的交互逻辑：</p><p><img src="/blog/assets/add_peer.png"></p><center>图1. 节点初始化peer列表过程中用户线程和Raft线程之间的交互过程</center><p>由于在初始化时已经指定了3个节点，所以在检查containsUpdates时会发现更新。后续的过程就如图1所示，在交互过程中用到的一系列channel也标记在图中的箭头上。在初始化的过程中，节点均处于follower角色，所以增加节点仅仅是向peer列表里增加了一些记录。</p><h2><span id="成为leader的过程">成为Leader的过程</span></h2><p>在完成初始化之后，选举的过程是由超时来触发的。注意在初始化过程中，会执行becomeFollower（raft.go)将节点角色设置为follower。其中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">r.step = stepFollower <span class="comment">// 设置step逻辑</span></span><br><span class="line">r.reset(term)</span><br><span class="line">r.tick = r.tickElection <span class="comment">// 设置tick逻辑</span></span><br><span class="line">r.lead = lead</span><br><span class="line">r.state = StateFollower</span><br><span class="line">r.logger.Infof(<span class="string">"%x became follower at term %d"</span>, r.id, r.Term)</span><br></pre></td></tr></table></figure><p>包含设置step和tick逻辑的代码。在follower角色下，节点的超时行为是触发下一次选举；对应的，如果处于leader角色中，超时则是触发发送心跳消息。如果follower节点超时了，会给自己“发送”一个MsgHup消息，进而开始竞选leader。在竞选前的一些逻辑包括：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// campaign</span></span><br><span class="line">r.becomeCandidate()</span><br><span class="line">voteMsg = pb.MsgVote</span><br><span class="line">term = r.Term</span><br><span class="line"></span><br><span class="line"><span class="comment">// becomCandidate</span></span><br><span class="line">r.step = stepCandidate  <span class="comment">// 更改step逻辑</span></span><br><span class="line">r.reset(r.Term + <span class="number">1</span>)<span class="comment">// 增加term</span></span><br><span class="line">r.tick = r.tickElection <span class="comment">// 处于candidate角色下节点超时触发下一轮选举</span></span><br><span class="line">r.Vote = r.id</span><br><span class="line">r.state = StateCandidate</span><br></pre></td></tr></table></figure><p>随后，竞选节点需要邀请其它节点提名自己。当然，如果集群是只包含一个节点这种特殊情况，则不需要经过其它节点提名的过程而直接当选。发送邀请的过程如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> id := <span class="keyword">range</span> r.prs &#123;</span><br><span class="line"><span class="keyword">if</span> id == r.id &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里可以与论文原图Figure 3.1里的RequestVote RPC对照理解</span></span><br><span class="line"><span class="comment">// Term: candidate的term</span></span><br><span class="line"><span class="comment">// To: candidate的id</span></span><br><span class="line"><span class="comment">// Type: MsgVote</span></span><br><span class="line"><span class="comment">// Index: candidate最新一条log的index，这里的log包含unstable</span></span><br><span class="line"><span class="comment">// LogTerm: candidate最新一条log的term，这里的log包含unstable</span></span><br><span class="line">r.send(pb.Message&#123;Term: term, To: id, Type: voteMsg, Index: r.raftLog.lastIndex(), LogTerm: r.raftLog.lastTerm(), Context: ctx&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="noopener">论文</a>3.6章讨论的是在选举过程中的安全问题，即如何避免一个log落后的节点竞选成为leader。作者提出了一个需要保证的性质——Leader Completeness Property，说明如下：</p><div class="tip"><br>If a log entry is committed in a given term, then that entry will be present in the logs of the leaders for all higher-numbered terms.<br></div><p>也就是一旦一条log确认被committed了，那么它一定要出现在下一个竞选成功的leader的日志里。这句话有两个问题：</p><h3><span id="如何判断一条log已经committed">如何判断一条log已经committed？</span></h3><p>按照定义，committed的标准是在多数节点上复制成功。具体考虑一次写入操作，首先log通过网络复制到多数节点的日志；然后leader获得复制情况，确定完成复制后在本地commit日志；最后通过心跳消息通知其它节点commitment信息，接收到消息的其它节点在本地commit日志。从这个过程来看，leader和follower角色下的节点对同一条log是否已经被commit的认识时机是不同的，leader先于follower知晓该信息。如果leader已经知晓commitment但没来得及通知其它节点就掉线了，那么这条本来已经被commit的消息会怎么样呢？按照论文的讨论，由于其它节点并不知晓这条log已经被commit，所以如果一个没有包含这条log的节点当选为leader，那么这条本已经复制到多数节点的消息将被抹掉。所以，个人认为更为精确的说法是</p><div class="tip"><br>一条log被commit，意味着它已经被复制到多数节点，并且多数节点已经知晓来自leader的commit的信息。<br></div><h3><span id="如何保证committed的log出现在后续竞选成功的leader">如何保证committed的log出现在后续竞选成功的leader？</span></h3><p>按照上一个问题的逻辑，在MsgVote RPC里每个节点都应该包含自己已知的committed的日志的term和index，这样大家比较以后就能自然得出谁更加“up-to-date”一些。但是对比代码的实现细节，与论文的描述有所区别。在上面的代码片段里，raftLog.lastIndex和raftLog.lastTerm对应了index和term的值。而观察它们的实现，这里的“最后一条log”实际上包含了unstable结构里的数据，也就是包含没有被commit的日志。这样修改有什么影响呢？个人觉得这不会打破Leader Completeness Property，但会影响协议的行为。考虑一条日志被复制到多数节点但没有完成commitment，这时如果leader掉线，下一个被选举的leader一定包含这条尚未被commit的日志，因为那些尚未复制这条日志的节点无法得到足够多节点的支持。</p><p>节点接收到MsgVote后判断candidate的日志是否足够新的逻辑在raftLog.isUpToDate。</p><h3><span id="如何防止节点扰乱选举">如何防止节点扰乱选举</span></h3><p>解决了这两个问题，还有可能出现一种异常情况：如果一个失联节点不断增大自己的term，然后邀请其它正常工作状态下的节点参与选举，会扰乱集群的执行秩序。这个问题在论文的4.2.3章节讨论。</p><p>基本思想是如果一个节点能够接收到来自其leader的心跳，那么它不会参与选举。这个逻辑的实现可以查看raft.go下的inLease变量定义。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;实验代码和输出&quot;&gt;实验代码和输出&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;实验代码是基于作者&lt;a href=&quot;http://github.com/otm/raft-part-1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原来的代码&lt;/a&gt;稍微
      
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="Raft" scheme="liqul.github.io/blog/tags/Raft/"/>
    
  </entry>
  
  <entry>
    <title>Raft协议实现学习之—写入过程</title>
    <link href="liqul.github.io/blog/etcd_raft_4/"/>
    <id>liqul.github.io/blog/etcd_raft_4/</id>
    <published>2018-09-13T07:50:03.000Z</published>
    <updated>2018-11-23T06:35:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>在上一篇文章重点梳理了选举的过程，而这一篇想着重梳理一下写入的过程。仍然沿着节点初始化的日志开始：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ...</span></span><br><span class="line"><span class="comment"># 阶段7：节点1成为leader后向其它节点广播MsgApp</span></span><br><span class="line">17:40:19 1-&gt;2 MsgApp Term:2 Log:1/3 Commit:3 Entries:[2/4 EntryNormal <span class="string">""</span>]</span><br><span class="line">17:40:19 3-&gt;1 MsgVoteResp Term:2 Log:0/0</span><br><span class="line">17:40:19 INFO: raft.node: 2 elected leader 1 at term 2</span><br><span class="line">17:40:19 1-&gt;3 MsgApp Term:2 Log:1/3 Commit:3 Entries:[2/4 EntryNormal <span class="string">""</span>]</span><br><span class="line">17:40:19 2-&gt;1 MsgAppResp Term:2 Log:0/4 <span class="comment"># 这里2汇报已经保存了新的entry</span></span><br><span class="line">17:40:19 INFO: raft.node: 3 elected leader 1 at term 2</span><br><span class="line">17:40:19 1-&gt;2 MsgApp Term:2 Log:2/4 Commit:4 <span class="comment"># 在这里commit从3变成4</span></span><br><span class="line">17:40:19 3-&gt;1 MsgAppResp Term:2 Log:0/4 </span><br><span class="line">17:40:19 node 1: processing entry: &#123;2 4 EntryNormal [] []&#125; <span class="comment"># 由于已经确认大部分节点都保存成功，可以apply到state machine</span></span><br><span class="line">17:40:19 1-&gt;3 MsgApp Term:2 Log:2/4 Commit:4</span><br><span class="line">17:40:19 2-&gt;1 MsgAppResp Term:2 Log:0/4</span><br><span class="line">17:40:19 node 2: processing entry: &#123;2 4 EntryNormal [] []&#125; <span class="comment"># 2在接收到来自1的MsgApp后得知commit=4，可以apply到本地的state machie</span></span><br><span class="line">17:40:19 3-&gt;1 MsgAppResp Term:2 Log:0/4</span><br><span class="line">17:40:19 node 3: processing entry: &#123;2 4 EntryNormal [] []&#125;</span><br></pre></td></tr></table></figure><p>在raft.becomeLeader方法的实现里，节点一旦选举成为leader会主动向自己的日志里写入一条空日志：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r.appendEntry(pb.Entry&#123;Data: <span class="literal">nil</span>&#125;)</span><br></pre></td></tr></table></figure><p>注意这条空日志并非前面提到过的<em>dummy entry</em>，而仅仅是内容为空的一条真实的日志，所以在上面程序输出的日志里，可以看到节点1将该日志复制到节点2和3的过程。当然，正常的写入流程的入口在node.Propose，其中会将用户给的数据组织成一个MsgProp然后发送到node的propc等待处理。</p><p>在Raft协议下，只有leader能处理来自client的写入请求，如果其它follower节点接收到请求也会转发给leader。leader和follower处理MsgProp的逻辑自然是不同的，分别在raft.stepLeader和raft.stepFollower里定义。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// leader的处理逻辑</span></span><br><span class="line">r.appendEntry(m.Entries...)</span><br><span class="line">r.bcastAppend()</span><br><span class="line"></span><br><span class="line"><span class="comment">// follower的处理逻辑</span></span><br><span class="line">r.handleAppendEntries(m)</span><br></pre></td></tr></table></figure><p>Leader的处理逻辑非常简单，将日志写入unstable，然后广播到所有followers。这里需要展开说明follower的处理情况：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// handleAppendEntries的处理逻辑</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 正常运行情况下m.Index应该等于r.raftLog.committed</span></span><br><span class="line"><span class="keyword">if</span> m.Index &lt; r.raftLog.committed &#123;</span><br><span class="line">    r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: r.raftLog.committed&#125;)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注意这里几个参数的含义</span></span><br><span class="line"><span class="comment">// index是新entries的前一个entry的index</span></span><br><span class="line"><span class="comment">// logterm是新entries前一个entry的term</span></span><br><span class="line"><span class="comment">// commit是leader最大的committed entry的index</span></span><br><span class="line"><span class="comment">// entries是leader复制到follower的日志，但需要注意这些日志可能&lt;commit</span></span><br><span class="line"><span class="keyword">if</span> mlastIndex, ok := r.raftLog.maybeAppend(m.Index, m.LogTerm, m.Commit, m.Entries...); ok &#123;</span><br><span class="line">    r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: mlastIndex&#125;)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    r.logger.Debugf(<span class="string">"%x [logterm: %d, index: %d] rejected msgApp [logterm: %d, index: %d] from %x"</span>,</span><br><span class="line">        r.id, r.raftLog.zeroTermOnErrCompacted(r.raftLog.term(m.Index)), m.Index, m.LogTerm, m.Index, m.From)</span><br><span class="line">    r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: m.Index, Reject: <span class="literal">true</span>, RejectHint: r.raftLog.lastIndex()&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>理解这里逻辑的关键在于了解maybeAppend方法的含义。Follower在接收到一组来自leader的日志后需要判断这些日志是否能追加到自己本地的日志。MsgApp中的index和logterm分别是leader节点新复制的entries的前一条日志的index和term。可以再仔细阅读<a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="noopener">论文</a>里Figure 3.1里AppendEntries RPC的结构说明。在正常运行状态下，这条日志应该是已经被commit的最后一条日志，从本文最开始的程序输出日志里就能看到：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">17:40:19 1-&gt;2 MsgApp Term:2 Log:1/3 Commit:3 Entries:[2/4 EntryNormal <span class="string">""</span>]</span><br></pre></td></tr></table></figure><p>这条程序输出日志里打出了leader当前处于term2，而新entries的前一条日志是配置peer的日志，其term和index分别为1和3，leader最后commit的index也是3，最后新entry里的term和index分别为2和4。接收到这条记录的follower根据前一条日志的index来判断leader与自己的日志是否能匹配，即不存在中间漏掉日志的情况。判断的依据是matchTerm(index, logTerm)，即前一条日志是否已经在本地保存，如果没有说明中间存在漏洞。如果新来的日志可追加到本地，用户线程会根据接收到的Ready结构将日志持久化，然后给leader返回一条消息，如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">17:40:19 2-&gt;1 MsgAppResp Term:2 Log:0/4</span><br></pre></td></tr></table></figure><p>这条消息里包含了写入日志的index，这里是4，通知leader index=4的日志已经在节点上成功复制。Leader节点在接收到MsgAppResp消息后，在raft.stepLeader下处理消息，处理逻辑如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在正常情况下，会进入如下判断</span></span><br><span class="line"><span class="keyword">if</span> pr.maybeUpdate(m.Index) &#123; <span class="comment">// 在这里面可能会更新peer的progress</span></span><br><span class="line">    <span class="comment">// peer的状态转移，参考raft/design.md文件说明</span></span><br><span class="line">    <span class="keyword">switch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> pr.State == ProgressStateProbe:</span><br><span class="line">        fmt.Printf(<span class="string">"%x become replicate\n"</span>, m.From)</span><br><span class="line">        pr.becomeReplicate()</span><br><span class="line">    <span class="keyword">case</span> pr.State == ProgressStateSnapshot &amp;&amp; pr.needSnapshotAbort():</span><br><span class="line">        r.logger.Debugf(<span class="string">"%x snapshot aborted, resumed sending replication messages to %x [%s]"</span>, r.id, m.From, pr)</span><br><span class="line">        pr.becomeProbe()</span><br><span class="line">    <span class="keyword">case</span> pr.State == ProgressStateReplicate:</span><br><span class="line">        pr.ins.freeTo(m.Index)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> r.maybeCommit() &#123; <span class="comment">// 这里判断是否有新的待commit的日志</span></span><br><span class="line">        r.bcastAppend()</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> oldPaused &#123;</span><br><span class="line">        <span class="comment">// If we were paused before, this node may be missing the</span></span><br><span class="line">        <span class="comment">// latest commit index, so send it.</span></span><br><span class="line">        r.sendAppend(m.From)</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 可能继续向落后的节点发日志</span></span><br><span class="line">    <span class="keyword">for</span> r.maybeSendAppend(m.From, <span class="literal">false</span>) &#123; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码里的raft.maybeCommit的判断依据是大部分节点是否都已经复制了新的日志。如果判断成立，leader节点会调用raft.bcastAppend，从实现代码里可以看到即使没有新的日志，leader也会发送空信息来传达新的commit消息。所以，观察文章最前面的程序输出可以看到</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">17:40:19 1-&gt;2 MsgApp Term:2 Log:2/4 Commit:4</span><br></pre></td></tr></table></figure><p>这里节点1向2发出的MsgApp消息里附带的commit已经由3变成4了。Leader节点一旦更新commit消息，在用户线程获得这个信息后（通过Ready结构）就可以把这条日志应用到状态机了，于是有</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">17:40:19 node 1: processing entry: &#123;2 4 EntryNormal [] []&#125;</span><br></pre></td></tr></table></figure><p>至此，一条日志的写入过程结束。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在上一篇文章重点梳理了选举的过程，而这一篇想着重梳理一下写入的过程。仍然沿着节点初始化的日志开始：&lt;/p&gt;
&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;
      
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="Raft" scheme="liqul.github.io/blog/tags/Raft/"/>
    
  </entry>
  
  <entry>
    <title>Reading &quot;State Management in Apache Flink&quot;</title>
    <link href="liqul.github.io/blog/flink/"/>
    <id>liqul.github.io/blog/flink/</id>
    <published>2018-09-09T14:47:09.000Z</published>
    <updated>2018-09-15T14:40:48.922Z</updated>
    
    <content type="html"><![CDATA[<div class="tip"><br>Updated on 2018-09-09<br></div><p>I’m playing with Flink (1.6) and Structured Streaming (2.3.1) recently. I’m no expert for either framework, so my opinion is based on my very short experience with each of them. </p><a id="more"></a><p>In Flink, stream processing is the first class application. There are a lot of nice features to make it easy and flexible to support various streaming scenarios. You can do complex event processing (CEP) and co-processing with multiple input sources. One great feature is that you can attach user defined state to amost any operator. From version 1.6, they provide the so called “<a href="https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html" target="_blank" rel="noopener">broadcast state</a>“ which is very useful for streaming applications with dynamic configurations. With support of transactional write by Kafka, now Flink is able to achieve the end-to-end exactly-once semantic. Here is the <a href="https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html" target="_blank" rel="noopener">blog</a> explaining how they use two-phase commit to implement this.</p><p>Spark is originally designed for batch processing. Even they now support streaming by introducing Spark Streaming and Structured Streaming, their advantages remains still for batch oriented applications. The data model is tightly coupled with DataSet which makes it more friendly for ETL like data manipulations, but not so nice for operations like event processing. I’m not saying that Spark has no advantage compared with Flink. For example, Spark can scale dynamically to the traffic load. Flink is currently missing this feature due to its more complicated state management (the <a href="https://stackoverflow.com/questions/51139656/flink-autoscaling-and-max-parallelism?noredirect=1&amp;lq=1" target="_blank" rel="noopener">answer</a> here says that it is a coming feature). Also, I note that in the newly introduced “contineous model”, dynamic scaling is not supported due to similar reason as in Flink. If I want to pick one for ETL only where latency is not the major concern, Spark is actually a good candidate. However, if my main application is event processing, Flink is definitely the better choice. Actually, Flink provides a very nice UI to monitor the application status. In contrast, the Spark UI is way too complicated for stream processing applications. </p><p>In conclusion, Flink is generally more suitable in stream processing applications. But now, if your application is with highly dynamic traffic load, and latency is not your major concern, pick Spark. </p><div class="tip"><br>Updated on 2018-02-05<br></div><p>I recently read an excellent <a href="https://streaml.io/blog/exactly-once/" target="_blank" rel="noopener">blog</a> about exactly-once streaming processing. It details typical solutions for exactly-once processing used by various open source projects. No matter if the solution is based on streaming or mini-batch, exactly-once processing incurs a inevitably latency. For example in Flink, the state at each operation can only be read at each checkpoint, in order not to read something that might be rollbacked during a crash. </p><p>===</p><p>I recently read the VLDB’17 paper “State Management in Apache Flink”. In one sentence,</p><blockquote><p>The Apache Flink system is an open-source project that provides a full software stack for programming, compiling and running distributed continuous data processing pipelines.</p></blockquote><p>For me, Flink sounds yet another computation framework alternative to Spark and Mapreduce with a workflow management tool. However,</p><blockquote><p>In contrast to batch-centric job management which prioritizes reconfiguration and coordination, Flink employs a schedule-once, long-running allocation of tasks. </p></blockquote><p>How exactly does a streaming-centric framework differ from a batch-centric framework? Conceptually, there is no fundamental difference between the two. Any batch processing framework can work “like” a streaming processing framework by reducing the size of each batch to 1. However, in practice, they are indeed different. A batch-centric framework usually involve a working procedure such as </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">batch 1 start</span><br><span class="line">do some job</span><br><span class="line">batch 1 end</span><br><span class="line">update some state</span><br><span class="line"></span><br><span class="line">batch 2 start</span><br><span class="line">do some job</span><br><span class="line">batch 2 end</span><br><span class="line">update some state</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>Note that the job is started and ended within each batch. In contrast, for a streaming-centric framework, </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">start a job</span><br><span class="line"></span><br><span class="line">receiving a new data</span><br><span class="line">process the data</span><br><span class="line">update some state</span><br><span class="line">pass the data to the next job</span><br><span class="line"></span><br><span class="line">receiving a new data</span><br><span class="line">process the data</span><br><span class="line">update some state</span><br><span class="line">pass the data to the next job</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">end the job</span><br></pre></td></tr></table></figure><p>This comparison is clear. A job in the streaming-centric framework usually work continuously without being started/stopped multiple times as in a batch-centric framework. Starting and stopping a job usually incur some cost. Therefore, a batch-centric framework usually performs less efficiently compared to a streaming-centric one. Additionally, if the application is mission critical (e.g., malicious event detection), processing data in batch usually means high latency. However, if the task is batch-by-batch in nature, a batch-centric framework usually performs as efficiently as a streaming-centric one. </p><p>Another problem is about snapshotting. Snapshotting is a key capability for a processing pipeline. A snapshot is consist of both the state and data. The global state of the pipeline is composed of the sub-state of each operator. Each state is either a <em>Keyed state</em> or a <em>Operator state</em>. The former represents all type of states indexed by the key from data (e.g., count by key); the latter is more an operator-aware state (e.g., the offset of data). Snapshotting the data is tricky where Flink assumes that </p><blockquote><p>Input data streams are durably logged and indexed externally allowing dataflow sources to re-consume their input, upon recovery, from a specific logical time (offset) by restoring their state. This functionality is typically provided by file systems and message queues such as Apache Kafka</p></blockquote><p>Each operator snapshots the current state once processing a mark in the dataflow. With the marks and the snapshotted states of each operator, we can always restore the system state from the last snapshot. One should note that the keyed state is associated with an operator, and therefore, the data with the same key should be physically processed at the same node. Otherwise, there should be a scalability issue. Consequently, there should be a shuffle before such operators, or the data is already prepared to ensure data with the same key is processed at a single node.</p><p>In conclusion, Flink is great as streaming-centric frameworks have some fundamental advantages over batch-centric frameworks. However, since batch-centric frameworks such as Mapreduce and Spark are already widely applied, there should be really strong motivations to migrate existing systems to this new framework. Moreover, the implementation quality and contributor community are two very important facts for the adoption of a new born framework, while Spark has been a really popular project. Maybe, a higher level project such as the <a href="https://beam.apache.org/" target="_blank" rel="noopener">Apache Beam</a> is a good direction. Beam hides the low-level execution engine by unifying the interface. Any application written in Beam is then compiled to run on an execution engine such as Spark or Flink.</p>]]></content>
    
    <summary type="html">
    
      Understanding the concepts in Apache Flink.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="flink" scheme="liqul.github.io/blog/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Things about replication in Elasticsearch</title>
    <link href="liqul.github.io/blog/things-about-replication-in-elasticsearch/"/>
    <id>liqul.github.io/blog/things-about-replication-in-elasticsearch/</id>
    <published>2018-04-18T13:33:09.000Z</published>
    <updated>2018-04-18T13:33:55.000Z</updated>
    
    <content type="html"><![CDATA[<div class="tip"><br>Updated on 2018-04-18<br></div><p>Elasticsearch is evolving fast in the past few years. There have been quite some discussions on data loss during node crashes, which can be found <a href="https://github.com/elastic/elasticsearch/issues/10933" target="_blank" rel="noopener">here</a> and <a href="https://github.com/elastic/elasticsearch/issues/14252" target="_blank" rel="noopener">here</a>. Most of the issues have been fixed as described <a href="https://www.elastic.co/guide/en/elasticsearch/resiliency/current/index.html" target="_blank" rel="noopener">here</a>. However, since Elasticsearch carried out a major upgrade to version 5+, some serious issues still remain for low versions, e.g., the stale replica problem described <a href="https://github.com/elastic/elasticsearch/issues/14671" target="_blank" rel="noopener">here</a>. </p><a id="more"></a><p>I already discussed in the original article about the two node issue. I recently carried out an experiment with 3 nodes which is actually the recommended minimum size for an Elasticsearch cluster. With 3 nodes, the quorum size is 2 and the minimum master nodes is 2 (discovery.zen.minimum_master_nodes). Therefore, there is always an overlap where some nodes have the latest state. Let me explain this with an example. The nodes are A, B, and C. We go through the following test steps:</p><ol><li>Create a new index with 2 replicas, i.e., 3 copies in total;</li><li>Shut down A;</li><li>Index 1 document on index B and C successfully;</li><li>Shut down B and C;</li><li>Turn on A;</li></ol><p>What about the state for the index? The replica on A will not be allocated as the primary shard since there is only one alive node less than the minimum master nodes 2. Now, we turn on B. As B has the latest state, B propagate the latest state to A. </p><p>Most of open sourced distributed system rely on a mature consensus approach such as Raft or Zookeeper. However, Elasticsearch decided to invent its own. This actually leads to most of those serious issues. This really drive me crazy :( </p><p>So far as I know, the most close setting to make elasticsearch strong consistent in a 3 node cluster consists of:</p><ul><li>A minimun master nodes = 2</li><li>write consistency = quorum</li><li>write/read/search preference = primary</li><li>check if index succeeds on &gt;= 2 nodes</li><li>always refresh before search (assume search is an infrequent operation)    </li></ul><p>========</p><p>Replication is a key feature for Elasticsearch from two aspects: (1) When some machines fail, the alive ones can still serve requests; (2) Replication boosts the read speed since read can retrieve data from multiple nodes simultaneously. </p><p>Elasticsearch follows a primary-secondary fashion for replication. When a write request (e.g., create, index, update, delete) arrives, it is first forward to the primary replica. The primary replica finishes the request, and then, concurrently forward the requests to all alive secondary replicas. There are a few details about this process. </p><p>First, there is a concept of write consistency level in Elasticsearch, with available options one, quorum, and all. This concept is a bit different from what we normally find for other systems such as Kafka. It barely forces the primary replica to check if there are enough alive replicas available receiving a write request. For instance, suppose we have a cluster of 3 nodes with replica number 2, i.e., each shard is with one primary replica and 2 secondary replicas. If we set the write consistency level to quorum, when the primary replica receives a index request, it checks if there are at least 2 replicas available (i.e., &gt;=replicas/2+1). If the check passes, the primary replica will start the action of index, after which it forward the request to all replicas. One should note that the consistency level is only for the check. This means there is a chance when a replica fails after the check, and right before the action.</p><p>Second, we need to answer the question: when shall the primary replica respond to the client? It turns out that there are two modes, sync and async as discussed <a href="https://discuss.elastic.co/t/es-default-async-or-sync/19654" target="_blank" rel="noopener">here</a>. The sync mode means the primary replica only responds the client if “all” secondary replicas have finished the request. Note that the “all” here, which has nothing to do with the selected write consistency level. Under the async mode, the primary replica responds to the client right after itself finishing the request. The request is then forward to other replicas in an async way. This accelerate the response timing for the client, which however may lead to overload for the Elasticsearch cluster. Mean while, since the request propagates eventually to the replicas, there will be no read-write consistency guarantee even inside the same session if the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.3/search-request-preference.html" target="_blank" rel="noopener">read preference</a> is not set to primary. </p><p>In normal case, there is only one primary replica for each shard. Once the primary replica fails, a secondary replica is elected to serve as primary. In some special situations, the primary replica may lose connection to other replicas, leading to multiple primary replicas in the system, which is called the split brain problem as discussed <a href="https://qbox.io/blog/split-brain-problem-elasticsearch" target="_blank" rel="noopener">here</a>. The cue to this problem is by setting the discovery.zen.minimum_master_nodes to &gt;= half of nodes + 1. For example, if you have 3 nodes, the minimum_master_nodes should be set to 2. By setting the minimum_master_nodes we ensure that the service is only available if there are more than minimum_master_nodes living nodes within one master domain. In other words, there can not be two masters in the system. </p><p>Finally, I want to discuss the problem of stale shard which I read recently from <a href="https://www.elastic.co/blog/tracking-in-sync-shard-copies" target="_blank" rel="noopener">here</a>. Let’s start by use a concrete example. Say if we have two nodes and each shard has two replicas (one primary and the other secondary). We first index 10 documents with the secondary shard node turned off. Then, we turn off the primary shard node, and bring up the secondary shard node. The question here is whether the secondary shard will be promoted to primary? If it is, how about the 10 documents we indexed before? According to this <a href="https://www.elastic.co/blog/tracking-in-sync-shard-copies" target="_blank" rel="noopener">blog</a>, with Elasticsearch v5+, the primary shard will not only do the index, but also inform the master about in-sync shards. In this case, the answer to our questions are no. Because the secondary shard is not in in-sync state after being brought up. I didn’t experiment it myself about this since I don’t have a Elasticsearch v5+ environment. I only tested this with Elasticsearch 2.4.5 where I found different answer. After secondary shard node was brought up, the secondary shard was indeed promoted to primary, and the 10 documents were lost if I then brought up the previous primary shard node. This is indeed a problem if such special situation happens, which however should be quite rare in practice especially if you have more than 2 nodes, and with quorum write consistency level.</p>]]></content>
    
    <summary type="html">
    
      Notes on what I learn about replication in Elasticsearch.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="consistency" scheme="liqul.github.io/blog/tags/consistency/"/>
    
      <category term="elasticsearch" scheme="liqul.github.io/blog/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Notes on HBase</title>
    <link href="liqul.github.io/blog/hbase/"/>
    <id>liqul.github.io/blog/hbase/</id>
    <published>2018-04-17T14:47:09.000Z</published>
    <updated>2018-04-17T15:05:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>So far as I know, HBase is the first open source “table” style storage in the big data scope. It is an implementation of the <a href="https://research.google.com/archive/bigtable-osdi06.pdf" target="_blank" rel="noopener">BigTable paper</a> presented by Google. If you read the paper or the <a href="https://hbase.apache.org/book.html" target="_blank" rel="noopener">reference guide</a>, HBase does not look like a table. The paper tells you that it is a </p><blockquote><p>sparse, distributed, persistent, multidimensional sorted map.</p></blockquote><a id="more"></a><p>There are so many details in this definition. If you want to find out what each of these terms means, you can go through this <a href="https://dzone.com/articles/understanding-hbase-and-bigtab" target="_blank" rel="noopener">article</a>. After reading it, you’d rather call HBase a map, instead of a table, because the data structure is</p><blockquote><p>(row key, column family:qualifier, timestamp) -&gt; value</p></blockquote><p>From the perspective of RDBM, each table in HBase could still be thought of as, for example, a table in MySQL. Data is organized into rows and each row is composed of columns (grouped into column families). A cell is specified by its row key and column name. So far, everything is the same with RDBM. You can insert rows, manipulate fields within a row, retrieve a row by its row key, and so on. The <strong>timestamp</strong> is actually an internal concept, <a href="https://www.ngdata.com/bending-time-in-hbase" target="_blank" rel="noopener">which should not be used by the user</a> or even put in the data model. In fact, timestamp is used as a version number. Therefore, to the user, there are still two dimensions (row and column) like in an ordinary RDBM table. </p><p>HBase has been out there for quite a few years, so it is not hard to find a good introduction about what is going on inside. This <a href="https://mapr.com/blog/in-depth-look-hbase-architecture/" target="_blank" rel="noopener">blog</a> has really nice diagrams. It covers comprehensively some of the most important building blocks of HBase, which I’d like to elaborate a few below. </p><h3><span id="data-organization">Data Organization</span></h3><p>Each row in a HBase table is break into cells for persistence. And each cell is in fact a key-value pair, where the key is (row key, column family:qualifier, timestamp). Data is first written to a memory cache called MemStore. Once the MemStore accumulates enough data, the data is flushed into a persistent file called HFile. Both data in the MemStore and in the HFile are sorted by their keys. Each flush may generate more than one HFiles. Each row of data is break down by defined column families. For instance, if the table is with two column families, each flush will get two separate HFiles. </p><p>A row is not stored as a whole, especially if the row has been manipulated later after insertion. Therefore, each time the client read a row, HBase goes through the MemStore and maybe, a few HFiles to bring together all fields to assemble the row. This is called the <strong>read amplification</strong> problem. </p><p>HBase keeps its metadata inside a special HBase table called METADATA. The metadata maintains a set of pointers where the key is a three-value tuple [table, region start key, region id] and the value is the RegionServer. If the client wants to find a specific row key, it will go through the metadata to find the right RegionServer. Then, the RegionServer go through its managed regions to find the required data. A HFile is with multiple layers of index, bloom filters, and time range information to skip as much unnecessary data as possible. </p><h3><span id="data-write">Data Write</span></h3><p>Writing data into HBase has three steps. Firstly, the data is written to a WAL on HDFS. Secondly, the data is written to the MemStore. Finally, when the MemStore size reaches a threshold, the data is flushed into HDFS. In fact, once the data is recorded into the WAL, the write is already successful, though the data is invisible at that moment. If the RegionServer crashes before writing to the MemStore, the data can still be loaded into MemStore once the server recovers. </p><p>HBase does not support cross row transactions. However, it does support atomic intra-row operations, and we know that a row is actually a set of key-value pairs. Therefore, <strong>I think</strong> the set of key-value pairs are grouped into a transaction. </p><p>HBase provides strong consistency for read and write, which means every read gets exactly the same result. The result depends solely on the timestamp the request is received by HBase. In the HBase architecture, strong consistency is achieved based on HDFS. In other words, the HBase provides a consistent global view to the WAL for all RegionServers. </p><h3><span id="compaction-and-split">Compaction and Split</span></h3><p>HDFS is designed for batch process, and therefore, huge number of small files can cause a unacceptable memory footprint to the NameNode. There are two kinds of compaction, the minor compaction and the major compaction. A minor compaction collects a set of HFiles (belonging to the same column family) and merge them into one. A major compaction merge all HFiles belonging to the same column family into one. Since a major compaction consumes quite a lot of resources, it is recommended to be carried out carefully. From this point of view, HBase is not really suitable for use cases where data is manipulated frequently.</p><p>A region is a consecutive range of row keys. Once a region reaches a certain size (e.g., 1G), the region is split into two. This is to keep the size of a region from being too big. Big region is bad since <strong>region</strong> is the unit of parallal access in HBase. For instance, a mapreduce program treat each region a split. The region is split in an automatic way in default. But the user could also predefine the split boundaries when creating the table. </p><p>If the regions are split automatically, one need to be careful about the row key design. For instance, if the row key is mono-increasing numbers, the new arriving data will always be inserted to the newly split region, creating write hotspot. In generally, the row keys should be random enough to prevent both read hotspot and write hotspot. </p><p><br><br><br></p><p>Finally, I’d like to give my two cents on HBase:</p><ul><li>Better documentation: The current document is not well written. The text contains a lot of references to Jira issues and external articles which is really disrupting. As discussed above, HBase is really about <strong>tables</strong>, not some complicated maps. I understand the differences, but as a beginner, I prefer concepts closer to my existing mindset. </li><li>SQL interface: Providing a SQL-like interface is much more friendly than raw Java apis. Such an interface helps users to play with HBase much more easily. </li><li>Predefined partition: Predined partition feels more controllable than the automatic split. Though there is a way of defining the split boundaries which is still quite indirect. In practice, people usually know how to partition their data to achieve the best performance. This is the well adopted use case for RDBMs. </li><li>Local filesystem: HDFS is designed for batch access which HBase can be used for random access, even with frequent manipulations. Local filesystems might be a better choice. </li></ul><p>I also read about Kudu and MapR-DB. From the architecture point of view, they actually share a lot of design patterns. Only, Kudu and MapR-DB are built on the shoulder of HBase, so they can avoid pitfalls. Anyway, HBase is still a very good designed software which provide a very good study case. Thanks to the community and the contributors.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;So far as I know, HBase is the first open source “table” style storage in the big data scope. It is an implementation of the &lt;a href=&quot;https://research.google.com/archive/bigtable-osdi06.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;BigTable paper&lt;/a&gt; presented by Google. If you read the paper or the &lt;a href=&quot;https://hbase.apache.org/book.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;reference guide&lt;/a&gt;, HBase does not look like a table. The paper tells you that it is a &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;sparse, distributed, persistent, multidimensional sorted map.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="HBase" scheme="liqul.github.io/blog/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>投资的心法</title>
    <link href="liqul.github.io/blog/invest/"/>
    <id>liqul.github.io/blog/invest/</id>
    <published>2018-04-12T13:45:21.000Z</published>
    <updated>2018-04-12T14:14:22.000Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="为什么要投资">为什么要投资？</span></h2><p>自从货币与黄金脱钩以后，整体的发展趋势总是超发的。政治家还经常会以各种借口来增发货币，比如“量化宽松”这个听起来不知所云的名词，本质就是货币超发。你辛苦工作后换来的货币随着时间流逝，其内在价值在逐渐变少。怎么能尽量减少由于一些不确定性造成的经济损失呢？一般人除了投资似乎没有别的办法。</p><a id="more"></a><h2><span id="巴菲特的估值核心护城河-安全边际">巴菲特的估值核心：护城河 + 安全边际</span></h2><p>基本概念有两个，</p><ul><li>护城河：企业有足够强的竞争优势甚至是垄断，并且企业在不断加大这种优势，同时企业本身的业务是具有长久的生命力的</li><li>安全边际：只有企业的股价与其内在价值相比足够便宜（如5折）的情况下的购买才是相对安全的</li></ul><p>护城河用一句话来概括：</p><p><div class="tip"><br>“如果你不能拥有一支股票10年，那么就不要拥有它10分钟”。<br></div><br>护城河实际上比起安全边际更加重要（除非现在的价格已经严重背离其内在价值），因为一家伟大的公司即使现在落魄，将来还是很有希望回归的。</p><h2><span id="etf的优势和劣势">ETF的优势和劣势</span></h2><p>ETF的优势在于其天然具备良好的“护城河”，因为你永远不用担心一个ETF会破产，或者ETF对应的企业不是行业里优秀的（因为通常ETF都会有一定的优胜劣汰机制）。其劣势是由于ETF足够“宽”，所以也意味着你获得的收益不如某些个股表现突出。但对于一般投资者来说，要准确找出这些个股的难度太大了，而历史上真正长期（10年以上）做到这一点的专业投资人凤毛麟角，所以投资ETF的实际收益要远远好于投资个股。另一方面，ETF的价格相对个股比较稳定，从而也更难买到足够便宜的，除非市场出现重大的波动。</p><h2><span id="永远不要动用生活费">永远不要动用生活费</span></h2><p>只有在不动用生活费的前提下才能使自己的损失更少。股指的短期波动是难以预料的，如果短期的下跌并不影响你的生活，那么为什么要着急把股票卖掉呢？而如果并不影响你的生活，你又为什么那么在意股指在短期内的波动呢？如果你坚信你所购买股票的公司是经过你认真分析的（前面提到的护城河），不会在短期内倒闭（如果是ETF那根本不会发生），那么请把你的钱留在股市里，因为“健全”的股市迟早有一天会回到这样的高度。你担心股市永远不会回到这样的高度？如果是那样的话，必然已经有一些更加令人担心的事情出现了（比如战争），那这些钱是在股市还是银行真的有区别吗？</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;为什么要投资？&quot;&gt;&lt;a href=&quot;#为什么要投资？&quot; class=&quot;headerlink&quot; title=&quot;为什么要投资？&quot;&gt;&lt;/a&gt;为什么要投资？&lt;/h2&gt;&lt;p&gt;自从货币与黄金脱钩以后，整体的发展趋势总是超发的。政治家还经常会以各种借口来增发货币，比如“量化宽松”这个听起来不知所云的名词，本质就是货币超发。你辛苦工作后换来的货币随着时间流逝，其内在价值在逐渐变少。怎么能尽量减少由于一些不确定性造成的经济损失呢？一般人除了投资似乎没有别的办法。&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="investment" scheme="liqul.github.io/blog/tags/investment/"/>
    
  </entry>
  
  <entry>
    <title>Eventual Consistency vs. Strong Consistency</title>
    <link href="liqul.github.io/blog/consistency_model/"/>
    <id>liqul.github.io/blog/consistency_model/</id>
    <published>2018-03-16T07:05:39.000Z</published>
    <updated>2018-04-12T13:33:38.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://cloud.google.com/datastore/docs/articles/balancing-strong-and-eventual-consistency-with-google-cloud-datastore/" target="_blank" rel="noopener">Here</a> is a very good explanation about eventual consistency and strong consistency. I’d like to borrow the two figures on that page below:</p><p><img src="/blog/assets/eventual-consistency.png"><br>Fig. 1 figure for eventual consistency</p><a id="more"></a><p>In this example above, Node A is the master, which replicate X to its followers Node B and C. Suppose the time when X is successfully writen to Node A is t_1, and the time when X  is replicated to Node B is t_2. Any time between t_1 and t_2, if a client reads from Node A, it gets the latest value of X. But if the client reads from Node B, it gets an old version of X. In other words, the result of a read depends on which Node the client reads from, and therefore, the storage service presents an inconsistent global view for the client. </p><p>In contrast, if the storage service provides a strong consistency semantic, the client should always read the same result. This figure below illustrates an example of strong consistency. </p><p><img src="/blog/assets/strong-consistency.png"><br>Fig. 2 figure for strong consistency</p><p>The single difference between Fig. 1 and Fig. 2 is that before X has been successfully replicated to Node B and C, a read request of X to Node B and C should be blocked. How about reading from Node A before all replications done? It should be blocked as well, and therefore, there is a missing  ‘lock’ symbol in Fig. 2. The full picture should has the following steps:</p><ol><li>A client issues a write request of X to Node A;</li><li>Node A locks X globally to prevent any read or write to X;</li><li>Node A store X locally, and then replicate X to Node B and C;</li><li>Node B and C store X locally and send Node A a response;</li><li>After receiving from Node B and C, Node A release the lock of X and respond to the client;</li></ol><p>These steps are only used to understand the basic idea of strong consistency, which is not necessary a best practice. If you want to know more details, research some real systems such as Spanner or Kudu.</p><p>While sounds more understandable for developers, strong consistency trades Availability for Consistency. In the instance shown in Fig. 2, a client may need to wait for a while before it reads the value of X. If the networking fails apart (for example, Node C is partitioned from Node A and B), any write requests to Node A will fail if each value is forced to have 3 replications. In addition, if the global lock service fails, the storage service will also be unavailable. In general, a storage service with strong consistency has much higher requirements to the infrastructure in order to function well, and therefore, is more difficult to scale compared to one with eventual consistency.</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel" target="_blank" rel="noopener">AWS S3’s consistency model</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://cloud.google.com/datastore/docs/articles/balancing-strong-and-eventual-consistency-with-google-cloud-datastore/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Here&lt;/a&gt; is a very good explanation about eventual consistency and strong consistency. I’d like to borrow the two figures on that page below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/eventual-consistency.png&quot;&gt;&lt;br&gt;Fig. 1 figure for eventual consistency&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="distributed" scheme="liqul.github.io/blog/tags/distributed/"/>
    
      <category term="consistency" scheme="liqul.github.io/blog/tags/consistency/"/>
    
  </entry>
  
  <entry>
    <title>Notes on MR memory issues</title>
    <link href="liqul.github.io/blog/experience_with_mr_memory_parameters/"/>
    <id>liqul.github.io/blog/experience_with_mr_memory_parameters/</id>
    <published>2018-02-05T03:29:09.000Z</published>
    <updated>2018-04-12T13:37:19.000Z</updated>
    
    <content type="html"><![CDATA[<div class="tip"><br>Updated on 2018-02-05<br></div><p>I recently encountered several OOMs from mapper tasks reading parquet files. The yarn container is killed due to running out of physical memory. Since I already set the JVM memory to 0.8 of the container size, I’m pretty sure that this is due to off-heap memory allocation issues. I found the two jira issues <a href="https://issues.apache.org/jira/browse/SPARK-4073" target="_blank" rel="noopener">here</a> and <a href="https://issues.apache.org/jira/browse/PARQUET-118" target="_blank" rel="noopener">here</a>, pointing me to the snappy codec used by parquet for decompression. There aren’t so much I can do except allocating more memory beside the JVM.  </p><a id="more"></a><p>===</p><p>I recently experienced two OOM problems running a mapreduce application. The MR application reads from a group of parquet files, shuffles the input rows, and writes into parquet files, too. </p><p>The first OOM is thrown by the mapper with error logs look like following</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2017-06-22 09:59:10.978 STDIO [ERROR] [WORKER] [129] Container [pid=14638,containerID=container_e26_1495868456939_0784_01_000066] is running beyond physical memory limits. Current usage: 1.0 GB of 1 GB physical memory used; 1.5 GB of 2.1 GB virtual memory used. Killing container.</span><br><span class="line">Dump of the process-tree for container_e26_1495868456939_0784_01_000066 :</span><br><span class="line">    |- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE</span><br><span class="line">    |- 14638 14632 14638 14638 (bash) 0 0 17096704 774 /bin/bash -c /usr/lib/jvm/java-7-oracle-cloudera/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx1024m -Djava.io.tmpdir=/disk1/yarn/nm/usercache/hdfs/appcache/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/disk2/yarn/container-logs/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.130.123 46432 attempt_1495868456939_0784_m_000020_1 28587302322242 1&gt;/disk2/yarn/container-logs/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066/stdout 2&gt;/disk2/yarn/container-logs/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066/stderr  </span><br><span class="line">    |- 14655 14638 14638 14638 (java) 4654 290 1616650240 272880 /usr/lib/jvm/java-7-oracle-cloudera/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx1024m -Djava.io.tmpdir=/disk1/yarn/nm/usercache/hdfs/appcache/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/disk2/yarn/container-logs/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.130.123 46432 attempt_1495868456939_0784_m_000020_1 28587302322242</span><br></pre></td></tr></table></figure><p>After some investigation, I realized this is due to a misconfiguration of the mapper container memory limit (mapreduce.map.memory.mb) and the mapper JVM memory limit (mapreduce.map.java.opts). Basically, the latter should be smaller than the former, because the mapper container consumes some memory itself. After setting mapreduce.map.java.opts = mapreduce.map.memory.mb * 0.8, the OOM problem is gone. I note that this also applies for the reducer, which has two corresponding parameters (mapreduce.reduce.java.opts and mapreduce.reduce.memory.mb). This <a href="https://discuss.pivotal.io/hc/en-us/articles/201462036-MapReduce-YARN-Memory-Parameters" target="_blank" rel="noopener">article</a> explains nicely.</p><p>The second OOM issue is much harder to address, which comes with the shuffle phase. I saw error logs like following</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">2017-06-21 20:22:42.294 STDIO [ERROR] [WORKER] [100] Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)</span><br><span class="line">    at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)</span><br><span class="line">    at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)</span><br><span class="line">    at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">    at javax.security.auth.Subject.doAs(Subject.java:415)</span><br><span class="line">    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)</span><br><span class="line">    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)</span><br><span class="line">Caused by: java.lang.OutOfMemoryError: Java heap space</span><br><span class="line">    at org.apache.hadoop.io.BoundedByteArrayOutputStream.&lt;init&gt;(BoundedByteArrayOutputStream.java:56)</span><br><span class="line">    at org.apache.hadoop.io.BoundedByteArrayOutputStream.&lt;init&gt;(BoundedByteArrayOutputStream.java:46)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.&lt;init&gt;(InMemoryMapOutput.java:63)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.unconditionalReserve(MergeManagerImpl.java:309)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.reserve(MergeManagerImpl.java:299)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:514)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:336)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)</span><br></pre></td></tr></table></figure><p>This is not an old problem which could be found in <a href="https://issues.apache.org/jira/browse/MAPREDUCE-6447" target="_blank" rel="noopener">here</a> and <a href="https://issues.apache.org/jira/browse/MAPREDUCE-6108" target="_blank" rel="noopener">here</a>. Most of the solutions suggest tuning the three parameters:</p><ul><li>mapreduce.reduce.shuffle.input.buffer.percent (default 0.7): how much memory shuffle can use to store data pulled from mappers for in-memory sort.</li><li>mapreduce.reduce.shuffle.memory.limit.percent (default 0.25): how much memory each shuffle thread uses for pulling data from mappers into memory. </li><li>mapreduce.reduce.shuffle.parallelcopies (default 10): the number of shuffle thread can run in parallel</li></ul><p>Some solutions claims that we should have </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mapreduce.reduce.shuffle.input.buffer.percent * mapreduce.reduce.shuffle.memory.limit.percent * mapreduce.reduce.shuffle.parallelcopies &lt; 1</span><br></pre></td></tr></table></figure><p>which is actually not correct. MergeManager allocates memory to shuffle threads which is used for copying mapper output into memory. Each time a shuffle thread applies for a copy action, the MergeManager determines if the application is granted by checking (1) if the appliedMemory size is more than the max memory each shuffle thread can have. This is controlled by mapreduce.reduce.shuffle.input.buffer.percent * mapreduce.reduce.shuffle.memory.limit.percent. Suppose the reducer JVM has 3.5G heap size, each shuffle can apply no more than 3500*0.7*0.25=612M with default settings. (2) if the usedMemory is more than memoryLimit. The used memory accounts for memory used by shuffles and in-memory merge. The memory limit is calculated by 3.5*0.7 = 2.45G with 3.5G JVM heap size. Now, if the usedMemory is 2.44G and appliedMemory is 612M, the real memory used by shuffle could be more than 3G !!! </p><p>This is not a bug, since there is a detailed comments in MergeManagerImpl.reserve. The comments explain why the actually used memory could be one shuffle larger than the limit. From the other side, this could cause OOM. Due to this issue, there’s no 100% safe way to fix the OOM by tuning the parameters. We can only mitigate this problem by reducing mapreduce.reduce.shuffle.input.buffer.percent and/or mapreduce.reduce.shuffle.memory.limit.percent. One should carefully calculate these parameters according to the real workload. Especially, the memory each shuffle can use limit the max size of output from each mapper. For example, if the mapper produces a 300M intermediate file, the shuffle should be able to allocate memory more than 300M. Otherwise, all sort will be done on disk. </p><p>One more thing is about the parquet format. It is a highly compressed format, and therefore the decompressed mapper output is much larger than the input split size. I think this is why OOM happens more frequently for parquet files than other file formats.</p>]]></content>
    
    <summary type="html">
    
      I recently experienced two OOM problems running a mapreduce application. The MR application reads from a group of parquet files, shuffles the input rows, and writes into parquet files, too. 
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="Mapreduce" scheme="liqul.github.io/blog/tags/Mapreduce/"/>
    
      <category term="OOM" scheme="liqul.github.io/blog/tags/OOM/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the SSD</title>
    <link href="liqul.github.io/blog/ssd/"/>
    <id>liqul.github.io/blog/ssd/</id>
    <published>2017-12-07T12:47:09.000Z</published>
    <updated>2018-04-12T13:37:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>Reading the chapter 13.5 “Arranging data on disk” in the book “DATABASE SYSTEM: IMPLEMENTATION” makes me think of a question: How data should be arranged on a SSD (Solid-State Drive)? This is indeed an old question, so after doing some research with Google, I find some very good explanations. </p><p><a href="http://site.aleratec.com/blog/2011/09/22/overview-pages-blocks-ftls-solidstate-drive-ssd/" target="_blank" rel="noopener">An Overview of Pages, Blocks and FTLs in a Solid-State Drive (SSD)</a></p><p><a href="https://www.extremetech.com/extreme/210492-extremetech-explains-how-do-ssds-work" target="_blank" rel="noopener">How Do SSDs Work?</a></p><a id="more"></a><p>The two articles above describes how SSD works differently from a HDD. Some key points to take away are:</p><ul><li>The minimum read/write unit for a SSD is a <em>page</em>. A <em>block</em> is made up of a set of pages.</li><li>A dirty page (with data) can <em>not</em> be overwritten before being erased.</li><li>The minimum erase unit for a SSD is a <em>block</em>.</li><li>Each block has a finite program/erase cycles (P/E cycles).</li></ul><p>Within a SSD, data can only be erased by block. <em>Garbage collection</em> need to run to reclaim logically deleted pages (e.g., due to update). Therefore, data in blocks with deleted pages are packed and rewrite to another empty block. A piece of data might be rewritten over and over again, which is called the <em>write amplification</em> problem. This also leads to the fact that data is moving constantly which is quite different from data stored within a HDD.</p><p><a href="https://blog.2ndquadrant.com/tables-and-indexes-vs-hdd-and-ssd/" target="_blank" rel="noopener">Tables and indexes vs. HDD and SSD</a></p><p>This article above discussed about the strategy of storing table data and indexes on HDD vs. SSD. The results are clearly shown by those charts. Also, the discussion in the comments is worthwhile for reading. </p><p><a href="http://codecapsule.com/2014/02/12/coding-for-ssds-part-1-introduction-and-table-of-contents/" target="_blank" rel="noopener">Coding for SSDs</a></p><p>Finally, I found a very interesting serial of blogs “Coding for SSDs”. The author built a key-value store optimized for SSDs. There are quite a lot of insights in these blogs. </p><p>In conclusion, SSDs outperform HDDs from almost every aspects today, except the price per bit. However, I envision that in the near future, the price could be made low enough to replace most HDDs. SSDs are almost drop-in replacement for HDDs. However, to get the best performance from SSDs, developers do need to take care about the data access characteristics of SSDs.</p>]]></content>
    
    <summary type="html">
    
      Understanding the characteristics of SSD.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="ssd" scheme="liqul.github.io/blog/tags/ssd/"/>
    
  </entry>
  
  <entry>
    <title>读《洪业：清朝开国史》有感</title>
    <link href="liqul.github.io/blog/ming_lessons/"/>
    <id>liqul.github.io/blog/ming_lessons/</id>
    <published>2017-10-28T12:47:09.000Z</published>
    <updated>2018-11-01T10:32:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>读<a href="https://www.amazon.cn/%E6%B4%AA%E4%B8%9A-%E6%B8%85%E6%9C%9D%E5%BC%80%E5%9B%BD%E5%8F%B2-%E9%AD%8F%E6%96%90%E5%BE%B7/dp/B06XFTC5TJ/ref=sr_1_1?ie=UTF8&amp;qid=1509194106&amp;sr=8-1&amp;keywords=%E6%B4%AA%E4%B8%9A" target="_blank" rel="noopener">《洪业：清朝开国史》</a>关于崇祯的一些感受。</p><a id="more"></a><h2><span id="魏忠贤问题">魏忠贤问题</span></h2><ul><li>上策：保持互相制衡，两方敲打，改革弊政</li><li>中策：无所作为</li><li>下策：杀魏忠贤导致文臣势力过大</li></ul><h2><span id="皇太极的问题">皇太极的问题</span></h2><ul><li>上策：联络岱善，内部瓦解后金统治阶级</li><li>中策：同意与皇太极议和，攘外必先安内，剿灭李自成</li><li>下策：同时面对两股敌人</li></ul><h2><span id="用人的问题">用人的问题</span></h2><ul><li>上策：黑猫白猫，不在意细节，以能力取人</li><li>中策：坚持用人时间长一点，不随意更替</li><li>下策：动辄得咎，反复无情，换人如流水</li></ul><h2><span id="自杀的问题">自杀的问题</span></h2><ul><li>上策：尽早自杀，传位于太子</li><li>中策：南下或北上。南下学宋高宗，虽末世无法与南宋比肩，但仍有一战的实力；北上主动联系后金，一同剿灭李自成，有崇祯在后金不那么容易南侵，何况还有吴三桂</li><li>下策：自杀身死，连太子也没有放过</li></ul><p>总结：第一次感受到了一个人对历史产生了如此大的作用。</p>]]></content>
    
    <summary type="html">
    
      读《洪业：清朝开国史》有感。
    
    </summary>
    
      <category term="Book Reading" scheme="liqul.github.io/blog/categories/Book-Reading/"/>
    
    
      <category term="洪业" scheme="liqul.github.io/blog/tags/%E6%B4%AA%E4%B8%9A/"/>
    
  </entry>
  
  <entry>
    <title>Quorum in Amazon Aurora</title>
    <link href="liqul.github.io/blog/quorum_in_amazon_aurora/"/>
    <id>liqul.github.io/blog/quorum_in_amazon_aurora/</id>
    <published>2017-10-27T08:12:09.000Z</published>
    <updated>2018-04-12T13:39:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>I recently read a serial of posts about the quorum mechanism in Amazon Aurora, which is a distributed relational database. These posts are: </p><ul><li><a href="/blog/assets/Amazon Aurora under the hood_ quorums and correlated failure _ AWS Database Blog.pdf">post1</a>: quorums and correlated failure.</li><li><a href="/blog/assets/Amazon Aurora Under the Hood_ Quorum Reads and Mutating State _ AWS Database Blog.pdf">post2</a>: quorum reads and mutating state.</li><li><a href="/blog/assets/Amazon Aurora Under the Hood_ Reducing Costs Using Quorum Sets _ AWS Database Blog.pdf">post3</a>: reducing costs using quorum sets.</li><li><a href="/blog/assets/Amazon Aurora Under the Hood_ Quorum Membership _ AWS Database Blog.pdf">post4</a>: quorum membership.<a id="more"></a></li></ul><p>Besides, there is actually a Sigmod’17 paper about Amazon Aurora which could be found <a href="http://www.allthingsdistributed.com/files/p1041-verbitski.pdf" target="_blank" rel="noopener">here</a>. I only briefly went through that paper which spends most of words talking about the basic architecture. </p><p>I like this serial of posts which is a very good tutorial if you want to learn practical usage of quorum. By definition, a quorum model is </p><blockquote><p>Formally, a quorum system that employs V copies must obey two rules. First, the read set, Vr, and the write set, Vw, must overlap on at least one copy.</p></blockquote><blockquote><p>Second, you need to ensure that the quorum used for a write overlaps with prior write quorums, which is easily done by ensuring that Vw &gt; V/2. </p></blockquote><p>At the heart of this model is that each read/write to the cluster of nodes overlaps at least one node with each other. </p><p>While it is cool to enjoy the replication benefit with the quorum model, there comes cost for both read and write. For read, a client may need to consult multiple nodes (i.e., the read set) in order to ensure reading the latest state. For write, the multiple copies need to be materialized in order to maintain the quorum model. The author introduced the basic ideas of solving these two problems in post2 and post3. Especially, for the read penalty, the master maintains a cache of the status of all successful replicas, including their latency estimations. Therefore, a client need only to find information from the master in order to read the latest information. </p><p>Membership management is discussed in post4 where they use the approach of overlapping quorums to solve the node failure problem. One nice feature is that this approach is robust given new failures happening right during the handling process. </p><p>Finally, I’d like to end up with the following sentence from the posts:</p><blockquote><p>State is often considered a dirty word in distributed systems—it is hard to manage and coordinate consistent state as you scale nodes and encounters faults. Of course, the entire purpose of database systems is to manage state, providing atomicity, consistency, isolation, and durability (ACID).</p></blockquote>]]></content>
    
    <summary type="html">
    
      Notes on the quorum mechanism in Amazon Aurora.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="quorum" scheme="liqul.github.io/blog/tags/quorum/"/>
    
      <category term="amazon aurora" scheme="liqul.github.io/blog/tags/amazon-aurora/"/>
    
  </entry>
  
  <entry>
    <title>Reading the New Apache HBase MOB Compaction Policy</title>
    <link href="liqul.github.io/blog/new_apache_hbase_mob_compaction_policy/"/>
    <id>liqul.github.io/blog/new_apache_hbase_mob_compaction_policy/</id>
    <published>2017-08-29T02:19:09.000Z</published>
    <updated>2018-04-12T13:40:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>In case you want to understand more on MOB (Moderate Object Storage), you may refer to this <a href="https://issues.apache.org/jira/browse/HBASE-11339" target="_blank" rel="noopener">issue</a>. Basically, hbase was first introduced with capability of storing mainly small objects (&lt;100k). Moderate objects stand for files from 100k to 10m. </p><p>Recently, there is a <a href="https://blog.cloudera.com/blog/2017/06/introducing-apache-hbase-medium-object-storage-mob-compaction-partition-policies/?elqTrackId=2a7ed08f6935464e84b51ad5a8f15cb2&amp;elq=896612af50b741d7b8bf576ac30276e4&amp;elqaid=4662&amp;elqat=1&amp;elqCampaignId=2850" target="_blank" rel="noopener">blog</a> introducing the new compaction policy for MOB files. The problem with the initial approach is multiple compaction. For instance, the goal is to compact the objects created in one calendar day into one big file. The compaction process starts after the first hour. The objects created in the first hour are compacted into a temporal file. Then, the objects created in the second hour, and the temporal file created for the first hour are compacted into a new temporal file…</p><a id="more"></a><p>In this way, finally, all objects created in one day is compacted into one file. However, the objects in the first hour is compacted quite a few of times, wasting IO. The new method is based on partition. For instance, we may compact the objects in each hour of day, which is the first stage. Then, the temporal files in each hour are compacted into the final file, which is the second stage. This saves a lot of IO in comparison with the initial approach. Actually, this improvement is quite straightforward. </p><p>What I found really insightful is about the compaction partitioned by the created time. Note that the creation time of each object is never changed during its life time. Therefore, suppose a set of objects is compacted into a big file which say contains objects between 2017-08-23 ~ 2017-08-24. After a while, some objects in that set may be deleted (with tombstone in hbase), or replaced with newer versioned metadata. However can we remove these objects physically? The answer is easy. We search for all objects created between 2017-08-23 ~ 2017-08-24, which should result in a subset of the original set of objects. We then extract the remain objects into a new big file, and delete the old big file. There are two other essential points to achieve the clear process described above: (1) the metadata should be 1:1 mapping with the objects. In other words, there should be no more than 1 metadata pointing to the same object. (2) the creation time and the pointer to file should be always updated atomically.</p>]]></content>
    
    <summary type="html">
    
      Notes on the new apache hbase mob compaction policy.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="hbase" scheme="liqul.github.io/blog/tags/hbase/"/>
    
      <category term="compaction" scheme="liqul.github.io/blog/tags/compaction/"/>
    
  </entry>
  
  <entry>
    <title>Understanding Chain Replication</title>
    <link href="liqul.github.io/blog/notes-chain-replication/"/>
    <id>liqul.github.io/blog/notes-chain-replication/</id>
    <published>2017-07-28T10:05:39.000Z</published>
    <updated>2018-04-12T13:40:43.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/blog/assets/chain_replication.svg" alt="Chain Replication"></p><p>I learned the idea of chain replication from <a href="https://github.com/hibari/hibari" target="_blank" rel="noopener">hibari</a>,</p><blockquote><p>Hibari is a production-ready, distributed, ordered key-value, big data store. Hibari uses chain replication for strong consistency, high-availability, and durability. Hibari has excellent performance especially for read and large value operations.</p></blockquote><a id="more"></a><p>The term “strong consistency” indeed caught my attention as I already know a few key-value storage services with only eventually consistency, e.g., openstack swift. I read its doc to find out the key tech sitting in the core is called “chain replication”. I did some investigation about this concept which actually back to very early days in 2004 in a OSDI <a href="http://www.cs.cornell.edu/home/rvr/papers/OSDI04.pdf" target="_blank" rel="noopener">paper</a>. </p><p>The idea is actually very easy to understand. The service maintains a set of chains. Each chain is a sequence of servers, where one server is called the <em>head</em>, and one is called the <em>tail</em>; all servers in between are <em>middle</em> servers. The figure in the very beginning shows such an example with two middle servers. Each write request is directed to the head server, and the update is pipelined from the head server to the tail server though the chain. Read requests are directed to only tail servers. What a client can read from the chain is definitely replicated across all servers belonging to the chain, and therefore, strong consistency is guaranteed. </p><p>Though the idea sounds straightforward, there are few practical issues. First of all, the traffic load at tail servers is higher than other servers, since they handle both write and read traffics. A load balancing aware chain organization algorithm is needed to balance the load across all servers. For instance, one server may be middle server of one chain and meanwhile tail server of another chain (see Fig. 3 in the <a href="http://www.snookles.com/scott/publications/erlang2010-slf.pdf" target="_blank" rel="noopener">Hibari paper</a>). Another problem is failure handling. There should be a way of detecting failed servers, which turns out to be non-trivial in such distributed world. There are also plenty of issues about recovering from failures, replication, and migration. In conclusion, this “simple” idea comes with a bunch of tough issues. </p><p>There are only few open source projects based on chain replication, such as <a href="https://github.com/hibari/hibari" target="_blank" rel="noopener">Hibari</a> and <a href="https://github.com/CorfuDB/CorfuDB" target="_blank" rel="noopener">CorfuDB</a>. One fundamental reason may be the cost paid for strong consistency is too high. One killer application for object storage is handling highly massive objects such as user data in social network companies. However, the chain can never cross data centers in order for low latency. The idea of using chained servers is not really new. HDFS also use a pipeline to optimize data transfer latency while achieving strong consistency. Therefore, if the number of files is not a issue, storing them directly on HDFS might be a reasonable choice, given the advantage of naive integration with other Hadoop components.</p>]]></content>
    
    <summary type="html">
    
      A brief understanding about chain replication.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="distributed" scheme="liqul.github.io/blog/tags/distributed/"/>
    
      <category term="replication" scheme="liqul.github.io/blog/tags/replication/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习笔记</title>
    <link href="liqul.github.io/blog/notes-learning-spark/"/>
    <id>liqul.github.io/blog/notes-learning-spark/</id>
    <published>2017-07-07T11:19:09.000Z</published>
    <updated>2018-04-12T13:41:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="spark与scala">Spark与Scala</span></h2><p>在学习Spark之前务必对Scala有所理解，否则面对完全陌生的语法是很痛苦的。</p><p>Scala的一种入门方式是：</p><ol><li>学习<a href="https://www.coursera.org/learn/progfun1/home/welcome" target="_blank" rel="noopener">Scala 函数式程序设计原理</a>。这是Scala作者自己开的课程。没什么比语言作者更加能理解这门语言的了，是切入Scala编程的最好入门方式。课程习题参考了《计算机程序的构造和解释》一书，非常经典。</li><li>阅读《Scala in depth》一书，对一些Scala的重点概念有更加详细的讨论。</li><li>根据特定的topic，Google各种网络资料。</li></ol><a id="more"></a><h2><span id="rdd-resilient-distributed-datasets">RDD (Resilient Distributed Datasets)</span></h2><h3><span id="rdd的含义">RDD的含义</span></h3><p>RDD是spark中用于记录数据的数据结构。根据具体的RDD类型，数据有不同的组织形式。一个RDD包含多个partition，partition是并行的基本单位。RDD可能存在内存中，也可能存在硬盘里，或者两者皆有。一个RDD可以由数据源创建，也可能由其它RDD计算得到，所有参与计算RDD的RDD称为父RDD。若对mapreduce有所了解，可以把partition看作mapper的一个split。</p><h3><span id="rdd中的窄依赖narrow-dependency和宽依赖wide-dependency">RDD中的窄依赖（Narrow Dependency）和宽依赖（Wide Dependency）</span></h3><p>若一个RDD中每一条记录仅仅依赖父RDD中唯一一条记录，则其为窄依赖，否则为宽依赖。比如在map中，每一条子RDD中的记录就对应着唯一父RDD中的对应记录。而groupByKey这样的操作中，子RDD中的一条记录，我们并不知道它究竟来自哪个父RDD中的哪个partition。</p><p>利用mapreduce的概念来理解，一组连续的窄依赖操作可以用一个mapper来实现，而宽依赖操作则只能依赖reducer。正因如此，一组连续窄依赖中产生的“中间结果”（实际并不需要产生这些中间结果）是没有存在的意义的，只要知道输入、操作就能直接计算输出了。举个具体的例子：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resRDD = srcRDD.map(_ + <span class="number">1</span>).map(_ + <span class="number">2</span>).filter( _ % <span class="number">2</span> == <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>中的transformation链可以看作mapreduce下的一个mapper，一条记录从左到右执行不依赖其它记录。若把上面例子改为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resRDD = srcRDD.map(_ + <span class="number">1</span>).distinct().filter( _ % <span class="number">2</span> == <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>其中加入了distinct意味着一条记录从左到右无法利用一个mapper就完成，必须截断加入一个reducer。这里需要理解mapreduce中的一个mapper并不是等价于spark中的一个map操作，而是对应所有窄操作的组合，例如filter、flatMap、union等等。</p><blockquote><p>补充材料：<a href="https://martin.atlassian.net/wiki/pages/viewpage.action?pageId=67043332" target="_blank" rel="noopener">why spark’s mapPartitions transformation is faster than map</a>。其中的一句话讲的非常清楚——you probably know that “narrow” transformations/tasks happen independently on each of the partitions. 即窄操作在单机即可完成，不需要依赖保存在其它主机上的partition。</p></blockquote><h3><span id="rdd中persist和checkpoint的逻辑">RDD中persist和checkpoint的逻辑</span></h3><p>persist的目的是为了加快后续对该RDD的操作；checkpoint的目的是为了减少长执行链失败带来的开销。由于目的不同，如果persist的RDD丢失了，可以重新计算一遍（这就是普通cache的基本逻辑）。反过来，如果checkpoint丢失了，则无法重新计算，因为该checkpoint之前的内容都遗忘了。cache只是persist的一个子操作，其storage level为memory_only。</p><p>persist和checkpoint都是异步操作，执行persist或checkpoint命令仅仅给对应的RDD加上一个mark，后续交给block manager完成具体的物化操作（？？？）。persist有多种storage level，包括memory, off heap memory, disk等等。在spark中，block manager负责所有的数据存储管理，包括persist、checkpoint、或shuffle产生的中间数据等。</p><p>值得一提的是关于off heap memory的<a href="http://stackoverflow.com/questions/6091615/difference-between-on-heap-and-off-heap" target="_blank" rel="noopener">概念说明</a>。简而言之，off heap memory就是不受JVM管控的一块内存空间，由于不受管控所以不存在GC的开销；另一方面由于并非JVM native环境，所以并不能识别其中存储的Java对象这样的结构，需要序列化和反序列化来支持。off heap memory的典型应用场景则是缓存一些较大的静态数据。</p><h3><span id="重要的方法">重要的方法</span></h3><h4><span id="compute">compute</span></h4><p><strong>def compute(split: Partition, context: TaskContext): Iterator[T]</strong><br>根据给定的partition计算一个interator，可以遍历该partition下的所有记录。有意思的是partition的名字为split，与mapreduce下mapper的处理单位名字一样。</p><h3><span id="rdd中的基础transformation">RDD中的基础transformation</span></h3><h4><span id="map">map</span></h4><p><strong>def map[U: ClassTag](f: T =&gt; U): RDD[U]</strong><br>返回的RDD为MapPartitionsRDD类型，其compute方法会对其父RDD中的记录执行f映射。</p><h4><span id="mappartitions">mapPartitions</span></h4><p><strong>def mapPartitions[U: ClassTag](f: Iterator[T] =&gt; Iterator[U], preservesPartitioning: Boolean = false): RDD[U]</strong><br>与map的区别在于映射f的作用对象是整个partition，而不是一条partition中的记录。在一些初始化代价较高的场景下，mapPartition比map更加合理和高效。</p><blockquote><p>补充材料：<a href="https://martin.atlassian.net/wiki/pages/viewpage.action?pageId=67043332" target="_blank" rel="noopener">why spark’s mapPartitions transformation is faster than map</a>。</p></blockquote><h4><span id="flatmap">flatMap</span></h4><p><strong>def flatMap[U: ClassTag](f: T =&gt; TraversableOnce[U]): RDD[U]</strong><br>与map类似，仅仅将对iterator的map操作换成flatMap操作。这里f映射的输出类型为TraversableOnce，表示只要能完成单次遍历即可，可以是Traversable或Iterable。</p><h4><span id="filter">filter</span></h4><p><strong>def filter(f: T =&gt; Boolean): RDD[T]</strong><br>与map类似，仅仅将对iterator的map操作换作filter操作。</p><h4><span id="distinct">distinct</span></h4><p><strong>def distinct(numPartitions: Int)(implicit ord: Ordering[T] = null): RDD[T]</strong><br>首先这个方法存在一个implicit的参数ord，类型为scala.math.Ordering。Ordering中实现了各种基础类型（Int, Long, Double, String等）的比较方法，这意味着如果T是一种基础类型则无须实现自己的比较方法，只需要import scala.math.Ordering即可。</p><p>与前几种transformation最大的不同在于distinct依赖reduce，即它是一种宽依赖操作。其具体实现代码如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map(x =&gt; (x, <span class="literal">null</span>)).reduceByKey((x, y) =&gt; x, numPartitions).map(_._1)</span><br></pre></td></tr></table></figure><p>可见其首先将一条记录映射为一个pair，然后执行reduceByKey的操作。这里reduceByKey方法并非RDD所有，之所以可以调用是因为object RDD里定义了从RDD转换为PairRDDFunctions的implicit方法。这种针对特定情况下的RDD增加操作的抽象方式可以学习。reduceByKey中给出了合并两个value的方式，即把相同的key的alue合并为一个（在此为null），然后根据给定的numPartitions数量进行hash partition。最终结果通过map仅保留key即可。</p><p>与mapreduce一致，这里的合并会发生在本地和reducer处，类似mapreduce中的combiner。在调用reduceByKey后的调用逻辑为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reduceByKey((x, y) =&gt; x, numPartitions)</span><br><span class="line">combineByKeyWithClassTag(x=&gt;x, (x,y)=&gt;x, (x,y)=&gt;x, <span class="keyword">new</span> <span class="type">HashPartitioner</span>(numPartitions))</span><br></pre></td></tr></table></figure><p>在combineByKeyWithClassTag中会根据传入的三个映射分别创建createCombiner、mergeValue和mergeCombiner。其中，createCombiner用于产生合并的初始值；mergeValue用于合并两条记录；mergeCombiner用于将mergeValue得到的结果再次合并。上述三者组成一个Aggregator对象。</p><h4><span id="coalesce">coalesce</span></h4><p><strong>def coalesce(numPartitions: Int, shuffle: Boolean = false)(implicit ord: Ordering[T] = null) : RDD[T]</strong><br>连接的作用是重新整理原有的RDD。有两种情况：（1）若shuffle\=\=false，表示一种虚拟的RDD分区变化，此时numPartitions应该比原来的少，否则无意义。注意此时是不会发生真实的IO的；（2）若shuffle\=\=true，表示要做一次真实的shuffle，即会带有真实的数据IO。对于第二种情况，在coalesce方法内部会做一次随机的mapping操作，把每个元素与结果RDD中的partition做一次mapping。在第二种情况下，numPartitions可以比父RDD的分区数量更多。</p><p>虽然前一种情况只是虚拟的分区变化，但究竟把哪些父partition分入同一个子partition是可以考虑locality因素的，CoalescedRDD的balanceSlack参数用来控制locality在分配父partition时起的权重。</p><p>看代码中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// include a shuffle step so that our upstream tasks are still distributed</span><br><span class="line">      new CoalescedRDD(</span><br><span class="line">        new ShuffledRDD[Int, T, T](mapPartitionsWithIndex(distributePartition),</span><br><span class="line">        new HashPartitioner(numPartitions)),</span><br><span class="line">        numPartitions).values</span><br></pre></td></tr></table></figure></p><p>这段话比较难懂，而实际上是做了几件事：首先，在ShuffledRDD中根据随机生成的key将父RDD各partiton中的数据分散到子RDD的各partiton中；然后，隐式转换为PairRDDFunctions的values方法转换成普通的RDD。</p><h4><span id="sample">sample</span></h4><p><strong>def sample(withReplacement: Boolean, fraction: Double, seed: Long = Utils.random.nextLong): RDD[T] = withScope</strong><br>对当前RDD的每个partition进行一次sample。withReplacement用于控制是否可出现重复sample，fraction控制sample的比例，seed即随机种子。</p><h4><span id="randomsplit">randomSplit</span></h4><p><strong>def randomSplit(weights: Array[Double], seed: Long = Utils.random.nextLong): Array[RDD[T]]</strong><br>给定一组weights，例如Array(2.0,3.0,5.0)，将父RDD按这样的比例划分，得到一个子RDD数组。<br>示例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val rdd = sc.makeRDD(1 to 10,10)</span><br><span class="line">rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at makeRDD at &lt;console&gt;:27</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.collect</span><br><span class="line">res1: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) </span><br><span class="line"></span><br><span class="line">scala&gt; val randomSplittedRDD = rdd.randomSplit(Array(2.0, 3.0, 5.0))</span><br><span class="line">randomSplittedRDD: Array[org.apache.spark.rdd.RDD[Int]] = Array(MapPartitionsRDD[12] at randomSplit at &lt;console&gt;:29, MapPartitionsRDD[13] at randomSplit at &lt;console&gt;:29, MapPartitionsRDD[14] at randomSplit at &lt;console&gt;:29)</span><br><span class="line"></span><br><span class="line">scala&gt; randomSplittedRDD.foreach(x =&gt; println(x.collect.mkString(&quot; &quot;)))</span><br><span class="line">9 10</span><br><span class="line">2 4 8</span><br><span class="line">1 3 5 6 7</span><br></pre></td></tr></table></figure></p><p>其内部实现实际上是利用了BernoulliCellSampler完成的，每次把父RDD的某个partition做一次sample得到一个子partition，通过一个MapPartitionsRDD实现从父RDD到子RDD的映射。但由于产生的是一组子RDD，因此每多一个子RDD就需要把父RDD做一次sample。由于每次调用时random seed是在内部保持不变的，所以即使多次sample，也不会导致某个元素被分到不同的子RDD里去。这一点是开始一直想不通的，因为我一直以为只需要sample一遍就能完成整个过程。</p><h4><span id="takesample">takeSample</span></h4><p><strong>def takeSample(withReplacement: Boolean, num: Int, seed: Long = Utils.random.nextLong): Array[T]</strong><br>返回指定数量的sample。</p><h4><span id="union同">union（同++）</span></h4><p><strong>def union(other: RDD[T]): RDD[T]</strong><br>获取两个RDD的并集，若一个元素出现多次，并不会通过union操作去重，因此union本身属于窄依赖。根据partitioner的情况，分两种情况处理：（1）如果两个RDD的partitioner都定义了且相同，那两RDD的partition数量一样，得到的并集RDD也有相同数量的partition。在考虑locality时，会按照多数原则处理，即如果大多数属于某个并集partition的父partition都倾向某个locality选择，那么就以此多数为准；（2）如果不满足（1）的情况，则并集RDD的partition数量为两父RDD的数量之和，即简单的合并关系。</p><h4><span id="keyby">keyBy</span></h4><p><strong>def keyBy[K](f: T =&gt; K): RDD[(K, T)]</strong><br>根据映射f抽取原RDD中每条记录的key，使结果RDD中每条记录为一个kv二元组。</p><h4><span id="sortby">sortBy</span></h4><p><strong>def sortBy[K](f: (T) =&gt; K, ascending: Boolean = true, numPartitions: Int = this.partitions.length)(implicit ord: Ordering[K], ctag: ClassTag[K]): RDD[T]</strong><br>对RDD排序，key由映射f抽取。这个方法的实现比较有趣，如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">this.keyBy[K](f)  //生成一个基于kv二元组的RDD</span><br><span class="line">        .sortByKey(ascending, numPartitions)  //sortByKey是OrderedRDDFunctions中的方法，由隐式转换rddToOrderedRDDFunctions支持</span><br><span class="line">        .values //排好序的RDD再退化由原来的元素组成，也是隐式转换支持</span><br></pre></td></tr></table></figure></p><p>实现过程经过两次隐式转换，非常有scala的特色，这种隐式转换往往发生在特殊的RDD之上。排序的具体过程参考Shuffle一节。</p><h4><span id="intersection">intersection</span></h4><p><strong>def intersection(other: RDD[T]): RDD[T]</strong><br>计算两个父RDD的交集，得到子RDD，交集元素无重复。实现如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">this.map(v =&gt; (v, null)).cogroup(other.map(v =&gt; (v, null))) //map成kv二元组后，隐式转换PairRDDFunctions调用其cogroup方法得到(k, (v1, v2))的结构</span><br><span class="line">        .filter &#123; case (_, (leftGroup, rightGroup)) =&gt; leftGroup.nonEmpty &amp;&amp; rightGroup.nonEmpty &#125;  //把两边都不是空的情况筛选出来</span><br><span class="line">        .keys //退化为普通的RDD</span><br></pre></td></tr></table></figure></p><p>其中cogroup依赖shuffle，所以是宽依赖操作。intersection操作还有一些重载，但基本实现是相同的。</p><h4><span id="glom">glom</span></h4><p><strong>def glom(): RDD[Array[T]]</strong><br>将原来的RDD变成新的RDD，其原有的每个partition变成一个数组。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val a = sc.parallelize(1 to 9, 3)</span><br><span class="line"></span><br><span class="line">scala&gt; a.glom.collect</span><br><span class="line">res66: Array[Array[Int]] = Array(Array(1, 2, 3), Array(4, 5, 6), Array(7, 8, 9))</span><br></pre></td></tr></table></figure></p><p>这篇<a href="http://blog.madhukaraphatak.com/glom-in-spark/" target="_blank" rel="noopener">文章</a>把glom的作用讲的非常清楚。其中的例1和例2都是在处理一个数组要比挨个处理每个元素好很多的时候。当然，这消耗的内存要更大（<strong>TODO</strong>: 具体使用情况如何？是否会导致OOM？），是一个折衷。</p><h4><span id="cartesian">cartesian</span></h4><p><strong>def cartesian[U: ClassTag](other: RDD[U]): RDD[(T, U)]</strong><br>生成当前RDD与另一个RDD的笛卡尔积，即列举所有a in this和b in other而组成的(a,b)的集合。生成的新RDD的partition数量等于原两个RDD各自的partition数量的乘积。</p><h4><span id="groupby">groupBy</span></h4><p><strong>def groupBy[K](f: T =&gt; K, p: Partitioner)(implicit kt: ClassTag[K], ord: Ordering[K] = null) : RDD[(K, Iterable[T])]</strong><br>将当前RDD中的元素按f映射的key做group操作，结果RDD可根据传入的partitioner来进行分区。源代码中有如下注释：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">* Note: This operation may be very expensive. If you are grouping in order to perform an</span><br><span class="line">* aggregation (such as a sum or average) over each key, using [[PairRDDFunctions.aggregateByKey]]</span><br><span class="line">* or [[PairRDDFunctions.reduceByKey]] will provide much better performance.</span><br><span class="line">*</span><br><span class="line">* Note: As currently implemented, groupByKey must be able to hold all the key-value pairs for any</span><br><span class="line">* key in memory. If a key has too many values, it can result in an [[OutOfMemoryError]].</span><br></pre></td></tr></table></figure></p><p>其中指出当前实现中一个key的所有value会需要保存在内存中，从而可能导致OOM，这可能是combine的过程中必须将所有value保存在内存中有关（推测）。另外，聚合或reduce可以解决大部分问题，而不需要groupBy，依此推测这个操作仅用于一些value较少又不得不获取这个中间结果的场景。</p><p>这篇<a href="https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/best_practices/prefer_reducebykey_over_groupbykey.html" target="_blank" rel="noopener">文章</a>很好的讲述了groupBy引入的内存问题的原因。</p><h4><span id="pipe">pipe</span></h4><p><strong>def pipe(command: String): RDD[String]</strong><br>pipe类似于mapreduce中的streaming，即能通过stdin来把数据发往外部进程，在通过stdout把结果读回来。这篇<a href="http://blog.madhukaraphatak.com/pipe-in-spark/" target="_blank" rel="noopener">文章</a>讲的非常清楚。但是这似乎只是map的过程，并不能包括reduce。</p><p>其内部实现实际上就是把参数中包含的command启动一个进程，然后通过stdin/out来完成上述算子操作过程。</p><h4><span id="zip">zip</span></h4><p><strong>def zip[U: ClassTag](other: RDD[U]): RDD[(T, U)]</strong><br>将当前RDD与other组合成一个新的包含二元组的RDD，要求两个RDD包含相同数量的partition，且每对partition包含相同数量的元素。</p><h4><span id="zippartitions">zipPartitions</span></h4><p><strong>def zipPartitions[B: ClassTag, V: ClassTag](rdd2: RDD[B], preservesPartitioning: Boolean)(f: (Iterator[T], Iterator[B]) =&gt; Iterator[V]): RDD[V]</strong><br>与zip的关系类似map与mapPartitions的关系，但又不完全一样。zip要求对应的partition里包含的元素数量也完全一样，但这里f映射并不需要两个partiton里元素数量相同。但显然可以利用zipPartitions来实现zip的功能，且与zip比较起来应该有更好的效率。</p><h4><span id="subtract">subtract</span></h4><p><strong>def subtract(other: RDD[T], p: Partitioner)(implicit ord: Ordering[T] = null): RDD[T]</strong><br>得到在当前RDD中且不在other中的元素组成的RDD，由于需要按元素做key，属于宽依赖。</p><h4><span id="dataframerepartion-vs-dataframewriterpartitionby">DataFrame.repartion vs. DataFrameWriter.partitionBy</span></h4><p><strong>def repartition(numPartitions: Int, partitionExprs: Column*): DataFrame</strong><br><strong>def partitionBy(colNames: String*): DataFrameWriter</strong><br>这里的<a href="https://stackoverflow.com/questions/40416357/spark-sql-difference-between-df-repartition-and-dataframewriter-partitionby" target="_blank" rel="noopener">讨论</a>非常清楚。repartition的参数是numPartitions和partitionExprs，partitionExprs将指定的列做hash后对numPartitions求模，得到对应的partition的index。这样得到的最终分区数量是numPartitions，但实际上如果numPartitons大于分组数量，可能有一些partition是空的；反之，如果numPartitions小于分组数量，有一些partiton里包含多个分组。partitionBy是把每个partition按照指定的列拆分为一到多个文件。</p><p>一个应用实力：如果希望输出的文件里，每个文件有且仅有一个分组，那么就可以dataframe.repartiton(n, columns).write.partitionBy(columns).csv(xxx)。其中n可以控制并发的数量，跟实际的数据分布有关。</p><h4><span id="zipwithuniqueid">zipWithUniqueId</span></h4><p><strong>def zipWithUniqueId(): RDD[(T, Long)]</strong><br>为了解决zipWithIndex带来的性能问题，这里放松了条件，只要求id是唯一的。zipWithUniqueId只是个算子，第k个partition的元素对应的id分别为k, k+n, k+2n, …，这里的n是partition的数量。</p><h3><span id="rdd中的actions">RDD中的actions</span></h3><h4><span id="foreach">foreach</span></h4><p><strong>def foreach(f: T =&gt; Unit): Unit</strong><br>将映射f应用到每个元素上。</p><h4><span id="foreachpartition">foreachPartition</span></h4><p><strong>def foreachPartition(f: Iterator[T] =&gt; Unit): Unit</strong><br>将映射f应用到每个partition上。</p><h4><span id="collect">collect</span></h4><p><strong>def collect(): Array[T]</strong><br>将RDD中所有元素作为一个数组返回。<strong>注意不要将collect作用于一个过大的RDD，否则会抛出内存异常，可先利用take和takeSample只取一个子集</strong>。</p><h4><span id="reduce">reduce</span></h4><p><strong>def reduce(f: (T, T) =&gt; T): T</strong><br>执行映射f对应的reduce操作。其操作基本步骤是：（1）每个partition执行f映射对应的reduce过程；（2）在driver的host机器上执行基于f映射的reduce过程，输入来自各个partition的输出。步骤（2）的复杂度与partition的数量呈线性增加。</p><h4><span id="treereduce">treeReduce</span></h4><p><strong>def treeReduce(f: (T, T) =&gt; T, depth: Int = 2): T</strong><br>为了改进reduce里步骤（2）的瓶颈问题，对各partition的输出先逐层聚合，最后再到driver处生成最终结果，类似一棵树的聚合过程。在<a href="https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/treereduce_and_treeaggregate_demystified.html" target="_blank" rel="noopener">文章</a>里有详细的描述。reduce和treeReduce的关系类似aggregate和treeAggregate的关系。</p><h4><span id="fold">fold</span></h4><p><strong>def fold(zeroValue: T)(op: (T, T) =&gt; T): T</strong><br>将映射op应用到每对元素上面。在实现过程中，spark不限定元素之间的执行顺序，实际上是先在partition内部做，然后再在partition之间，所以不能保证一个预先设定好的顺序来执行。因此，fold算子适用于那种不需要考虑左右操作元素的顺序，例如max。</p><h4><span id="aggregate">aggregate</span></h4><p><strong>def aggregate<a href="zeroValue: U" target="_blank" rel="noopener">U: ClassTag\</a>(seqOp: (U, T) =&gt; U, combOp: (U, U) =&gt; U): U</strong><br>与fold的不同在于aggregate可以返回一个新的类型U，而不是原来的类型Ｔ。从定义的角度，fold是aggregate的一种特例。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val a = sc.parallelize(1 to 9, 3)</span><br><span class="line">scala&gt; a.fold(0)&#123; _ + _ &#125;</span><br><span class="line">res0: Int = 45</span><br><span class="line"></span><br><span class="line">scala&gt; a.aggregate(0) ( _ + _, _ + _ )</span><br><span class="line">res1: Int = 45</span><br></pre></td></tr></table></figure><h4><span id="treeaggregate">treeAggregate</span></h4><p><strong>def treeAggregate<a href="zeroValue: U" target="_blank" rel="noopener">U: ClassTag</a>(seqOp: (U, T) =&gt; U, combOp: (U, U) =&gt; U, depth: Int = 2): U</strong><br>aggregate与treeAggregate和reduce与treeReduce的关系类似。</p><h4><span id="count">count</span></h4><p><strong>def count(): Long</strong><br>计算整个RDD中元素的个数。</p><h4><span id="countapprox">countApprox</span></h4><p><strong>countApprox(timeout: Long, confidence: Double = 0.95): PartialResult[BoundedDouble]</strong></p><p>在给定timeout期限的情况下，返回RDD中元素个数的估计。其中confidence是认为评估结果符合高斯分布的假设条件下估算的置信度，而<strong>不是结果的可信度</strong>。其核心代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">override def currentResult(): BoundedDouble = &#123;</span><br><span class="line">    if (outputsMerged == totalOutputs) &#123;</span><br><span class="line">      new BoundedDouble(sum, 1.0, sum, sum)</span><br><span class="line">    &#125; else if (outputsMerged == 0) &#123;</span><br><span class="line">      new BoundedDouble(0, 0.0, Double.NegativeInfinity, Double.PositiveInfinity)</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      val p = outputsMerged.toDouble / totalOutputs</span><br><span class="line">      val mean = (sum + 1 - p) / p</span><br><span class="line">      val variance = (sum + 1) * (1 - p) / (p * p)</span><br><span class="line">      val stdev = math.sqrt(variance)</span><br><span class="line">      val confFactor = new NormalDistribution().</span><br><span class="line">        inverseCumulativeProbability(1 - (1 - confidence) / 2)</span><br><span class="line">      val low = mean - confFactor * stdev</span><br><span class="line">      val high = mean + confFactor * stdev</span><br><span class="line">      new BoundedDouble(mean, confidence, low, high)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>其中totalOutputs是partition的个数。上面代码的逻辑是：如果已经计算了所有partition，则返回的结果是100%准确的；如果一个partition都未完成，那么结果完全不可信；否则，按比例计算mean，variance跟已返回比例有关，越多则variance越小，其low/high都是根据confidence和mean算出来的。</p><h4><span id="countbyvalue">countByValue</span></h4><p><strong>def countByValue()(implicit ord: Ordering[T] = null): Map[T, Long]</strong><br>实际上就是一个map + reduce的过程，而所得结果因为需要转化为Map，需要把所得内容完全载入driver的内存，所以只适合不同的value的数量比较小的情况。</p><h4><span id="countbyvalueapprox">countByValueApprox</span></h4><p><strong>def countByValueApprox(timeout: Long, confidence: Double = 0.95)(implicit ord: Ordering[T] = null) : PartialResult[Map[T, BoundedDouble]]</strong><br>与前面提到的countApprox实现类似。</p><h4><span id="zipwithindex">zipWithIndex</span></h4><p><strong>def zipWithIndex(): RDD[(T, Long)]</strong><br>获得一个新的RDD，其中每个元素都是一个二元组，其中value是元素所在RDD中的全局index。该操作不保证重复时index的顺序不变。这个操作表面上是一个算子，但实际上会触发一个spark job，因为在执行之前需要知道每个partition的起始index，而这只能通过count每个partition来得到。</p><h4><span id="take">take</span></h4><p><strong>def take(num: Int): Array[T]</strong><br>take的作用是从一个RDD中获取给定数量num个数的元素，得到一个数组。实现的基本思路是，首先尝试读一个partition，然后根据得到的元素数量与num的比较决定是否需要再探索其它的partition，以及探索的partition数量。这个探索数量的策略似乎比较heuristic，大体上是每次探索的partition数量小于等于已探索的4倍，而具体的值跟已探索到的元素数量与num的关系来定。从实现上看，take返回的所有元素都保存在一个数组内，所以如果num数量过大会引起内存问题。</p><h4><span id="takeordered">takeOrdered</span></h4><p><strong>def takeOrdered(num: Int)(implicit ord: Ordering[T]): Array[T]</strong><br>takeOrdered除了获取num个元素外，还要求这些元素按照ord给出的排序方式排序。其实现的核心代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">val mapRDDs = mapPartitions &#123; items =&gt;</span><br><span class="line">        // Priority keeps the largest elements, so let&apos;s reverse the ordering.</span><br><span class="line">        val queue = new BoundedPriorityQueue[T](num)(ord.reverse)</span><br><span class="line">        queue ++= util.collection.Utils.takeOrdered(items, num)(ord)</span><br><span class="line">        Iterator.single(queue)</span><br><span class="line">      &#125;</span><br><span class="line">      if (mapRDDs.partitions.length == 0) &#123;</span><br><span class="line">        Array.empty</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">        mapRDDs.reduce &#123; (queue1, queue2) =&gt;</span><br><span class="line">          queue1 ++= queue2</span><br><span class="line">          queue1</span><br><span class="line">        &#125;.toArray.sorted(ord)</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><p>首先，对每个partition需要得到一个BoundedPriorityQueue，其大小固定为num。若partition内元素少于num个，则queue不满。随后，在一个reduce中，把每个partition得到的queue拼接为一个queue。BoundedPriorityQueue的拼接会按照每个元素插入队列。根据这个实现，每次takeOrdered或top操作都需要对所有partition排序，然后在结果里拼出一个大小为num的队列，代价是比较大的。</p><h3><span id="常见的rdd派生类">常见的RDD派生类</span></h3><h2><span id="spark-architecture">Spark Architecture</span></h2><blockquote><p><a href="http://datastrophic.io/core-concepts-architecture-and-internals-of-apache-spark/" target="_blank" rel="noopener">http://datastrophic.io/core-concepts-architecture-and-internals-of-apache-spark/</a></p></blockquote><h2><span id="shuffle">Shuffle</span></h2><p>Shuffle的目的是把key相同的记录发送到相同的parition以供后续处理。Mapreduce中同样存在shuffle阶段。回顾mapreduce中shuffle的过程：（1）mapper将数据分为多个partition，然后parition内按照key排序（实际分两步完成），这些partition一部分写入磁盘，一部分缓存在内存里；（2）mapper输出的partition分发到对应的reducer；（3）reducer对已经排好续的记录再次进行合并排序；（4）key相同的记录被group为一个iterable交给reduce方法处理。</p><blockquote><p>补充材料：《Hadoop: The Definitive Guide》英文版，197页</p></blockquote><h3><span id="shuffle的两种方法">Shuffle的两种方法</span></h3><p>Spark中shuffle“目前”有两种实现，分别是基于hash和sort。</p><p>基于hash的方式在spark 1.2.0以前是默认的方式。其实现思路非常简单，对于任意输入RDD中的partition，根据hash结果产生N个文件。N表示“reducer”的数量。由于没有排序，每条记录经过hash后直接写入文件，因此速度较快。对于后续处理不需要排序的情况，基于hash的shuffle性能较好。其缺陷是产生的文件数量较大。</p><p>基于sort的方式达到的效果与mapreduce里的shuffle一样，但实现上有较大的差异。首先，从“mapper”写出的数据是不做本地排序的，只有在“reducer”从远端获取数据时才会触发排序过程。这里需要了解spark中的AppendOnlyMap的数据结构。简单来说，在数据量足够小的情况下，“mapper”输出的数据会保存在内存一个AppendOnlyMap中。如果数据较多，则会将AppendOnlyMap变换为一个priority queue，按key排序后保存到外部文件中。这样一来，一次map操作的所有数据会保存在一个内存里的AppendOnlyMap加若干外部的文件。当“reducer”请求数据的时候，这些数据分片会被组织成一个最小堆，每次读取一个key最小的记录，从而实现了排序的功能。“Reducer“拿到各个数据分片后，采用TimSort来对所有数据排序，而不是mapreduce中的合并排序。</p><blockquote><p>补充材料：<br><a href="https://0x0fff.com/spark-architecture-shuffle/" target="_blank" rel="noopener">Spark Architecture: Shuffle</a><br><a href="http://dataknocker.github.io/2014/07/23/spark-appendonlymap/" target="_blank" rel="noopener">spark的外排:AppendOnlyMap与ExternalAppendOnlyMap</a></p></blockquote><h2><span id="block-manager">Block Manager</span></h2><p>Block Manager在spark中作为一层存储抽象层存在。RDD的iterator方法里有读取缓存的partition的入口getOrCompute，其中block的id定义为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val key = RDDBlockId(rdd.id, partition.index)</span><br><span class="line"></span><br><span class="line">case class RDDBlockId(rddId: Int, splitIndex: Int) extends BlockId &#123;</span><br><span class="line">  override def name: String = &quot;rdd_&quot; + rddId + &quot;_&quot; + splitIndex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从实现上看每个RDD的partition都有一个唯一的key，用于blockmanager存储的键值。一个partition应该与一个block一一对应的。Block的存储完全由block manager来管理。</p><p><a href="https://issues.apache.org/jira/browse/SPARK-6235" target="_blank" rel="noopener">关于block size不能超过2g限制的issue tracker</a></p><p>不错的参考资料<br><a href="http://jerryshao.me/architecture/2013/10/08/spark-storage-module-analysis/" target="_blank" rel="noopener">Spark源码分析之-Storage模块</a><br><a href="http://cholerae.com/2015/03/06/Spark%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/" target="_blank" rel="noopener">Spark缓存机制分析</a><br><a href="http://www.cnblogs.com/hseagle/p/3673138.html" target="_blank" rel="noopener">Apache Spark源码走读之6 – 存储子系统分析</a></p><h2><span id="dag">DAG</span></h2><p><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-dagscheduler.html" target="_blank" rel="noopener">DAGScheduler</a><br><a href="https://issues.apache.org/jira/browse/SPARK-9850" target="_blank" rel="noopener">Adaptive execution in Spark</a></p><h2><span id="dataframe">DataFrame</span></h2><p>可以反复学习的blog<br><a href="http://dataknocker.github.io" target="_blank" rel="noopener">http://dataknocker.github.io</a></p>]]></content>
    
    <summary type="html">
    
      My notes taken for learning spark.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="spark" scheme="liqul.github.io/blog/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Two-phase Commit</title>
    <link href="liqul.github.io/blog/two-phase-commit/"/>
    <id>liqul.github.io/blog/two-phase-commit/</id>
    <published>2017-06-09T06:32:00.000Z</published>
    <updated>2018-03-06T10:52:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>I recently came across a good description of two-phase commit from actordb’s document. I decide to borrow it as a note. The following is copied from <a href="http://www.actordb.com/docs-howitworks.html#h_323" target="_blank" rel="noopener">actordb’s document</a>:</p><p>3.2.3 Multi-actor transactions<br>Multi-actor transactions need to be ACID compliant. They are executed by a transaction manager. The manager is itself an actor. It has name and a transaction number that is incremented for every transaction.</p><p>Sequence of events from the transaction manager point of view:</p><ol><li>Start transaction by writing the number and state (uncommitted) to transaction table of transaction manager actor.</li><li>Go through all actors in the transaction and execute their belonging SQL to check if it can execute, but do not commit it. If actor successfully executes SQL it will lock itself (queue all reads and writes).</li><li>All actors returned success. Change state in transaction table for transaction to committed.</li><li>Inform all actors that they should commit.</li></ol><p>Sequence of events from an actors point of view:</p><ol><li>Actor receives SQL with a transaction ID, transaction number and which node transaction manager belongs to.</li><li>Store the actual SQL statement with transaction info to a transaction table (not execute it).</li><li>Once it is stored, the SQL will be executed but not committed. If there was no error, return success.</li><li>Actor waits for confirm or abort from transaction manager. It will also periodically check back with the transaction manager in case the node where it was running from went down and confirmation message is lost.</li><li>Once it has a confirmation or abort message it executes it and unlocks itself.</li></ol><p>Problem scenarios:</p><ol><li>Node where transaction manager lives goes down before committing transaction: Actors will be checking back to see what state a transaction is in. If transaction manager actor resumes on another node and sees an uncommitted transaction, it will mark it as aborted. Actors will in turn abort the transaction as well.</li><li>Node where transaction manager lives goes down after committing transaction to local state, but before informing actors that transaction was confirmed. Actors checking back will detect a confirmed transaction and commit it.</li><li>Node where one or more actors live goes down after confirming that they can execute transaction. The actual SQL statements are stored in their databases. The next time actors start up, they will notice that transaction. Check back with the transaction manager and either commit or abort it.</li></ol>]]></content>
    
    <summary type="html">
    
      I recently came across a good description of two-phase commit from actordb&#39;s document. I decide to borrow it as a note. The following is copied from actordb&#39;s document
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="transaction" scheme="liqul.github.io/blog/tags/transaction/"/>
    
  </entry>
  
</feed>
