<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Liqun&#39;s Homepage</title>
  
  <subtitle>A place for knowledge</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="liqul.github.io/blog/"/>
  <updated>2018-06-11T14:43:37.673Z</updated>
  <id>liqul.github.io/blog/</id>
  
  <author>
    <name>Liqun Li</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>新闻纪录</title>
    <link href="liqul.github.io/blog/news/"/>
    <id>liqul.github.io/blog/news/</id>
    <published>2018-04-22T15:00:21.000Z</published>
    <updated>2018-06-11T14:43:37.673Z</updated>
    
    <content type="html"><![CDATA[<p>每天读新闻，学习思考一些基本的经济逻辑。</p><a id="more"></a><h3><span id="2018-06-11">2018-06-11</span></h3><blockquote><p>6月14日即将公布美联储议息会议最新利率决议，市场普遍预期此次美联储加息的可能性较大。苏宁金融研究院宏观经济中心主任、高级研究员黄志龙表示，不排除美联储加息之后，中国央行可能跟进调整公开市场操作利率，以维持美元升值趋势下人民币汇率的相对稳定，管控人民币贬值预期进一步加大。另外，从国内经济来看，降准、加息的政策操作组合可能会成为下半年央行保持稳健中性货币政策选项之一。（证券日报）</p></blockquote><p>美联储的下一次加息即将到来，但市场上对于多次加息的反应已经越来越麻木，仿佛这并不意味着任何特别的事情，这正是问题所在。</p><blockquote><p>尽管降准并没有在预期中到来，但各界坚信，当下实体经济稳中向好的态势以及金融市场生态环境的改善都需要央行在货币政策层面给予适时适度的支持。也就是说，降准可能会迟到，但绝不会缺席。高企的存款准备金率仍有进一步下调空间，但央行下调的过程将是谨慎的。未来流动性将会继续注入小微企业、绿色经济等领域。今年以来金融市场、资本市场波动加大，也需要货币政策给予必要的支持。在全国经济一盘棋、金融市场与资本市场联动的大框架下，货币政策应该更敏感一些，反应更快速一些。</p></blockquote><p>加息和降准本就是两面，在单方面降准改成加息的时刻，却去讨论这样的话题，不知道其心究竟想达到什么样的特殊目的呢?</p><h3><span id="2018-06-09">2018-06-09</span></h3><blockquote><p>兴业银行、华福证券首席经济学家鲁政委和兴业研究公司研究员何津津表示，中国央行6月份仍将大概率跟随美联储加息，但对市场利率影响或有限，需要关注金融市场的波动可能对具体政策落地时间点的影响。预计中国年内仍会有降准操作，同时MLF操作仍会延续。（证券日报）</p></blockquote><p>央行也终于要开始加息了，这对于本来就脆弱的金融市场可绝对不是一件好事，拭目以待，开始保持低仓位，没有好的标的绝不轻易出手。</p><h3><span id="2018-06-08">2018-06-08</span></h3><blockquote><p>记者调查发现，个别银行已在全北京范围内将首套按揭房贷利率抬升至基准利率的1.3倍，另有至少5家股份制银行的网点员工透露“额度不多”、“今年基本暂停接单”，甚至直接建议询问国有大行。业内人士分析称，中小银行减少房贷业务是因资金成本偏高，个人申请房贷利率仍有上行空间。（北京商报）</p></blockquote><p>在中国总有个特色，如果一件事情非常难做到，那么那必然意味着利润，房子也是这样的。</p><blockquote><p>截至昨日，内地及香港上市房企中已经有22家公司公布了前五月的销售数据。1-5月，销售金额合计达到1.69万亿元，同比上涨约35%。5月份，大部分龙头企业销售业绩乐观，22家房企销售收入达到了3515.7亿元。（中证报）</p></blockquote><p>去库存进入尾声，按照过去的经验，这将是下一轮调控和涨价。</p><blockquote><p>美国总统特朗普发布推文称，为什么欧盟和加拿大没有告诉公众，多年来他们对美国采用了大规模的贸易关税和非货币贸易壁垒，这对我们的农民，工人和公司是完全不公平的。取消你的关税和障碍，否则我们会比你更多！</p></blockquote><p>美国与加拿大难得如此互相指责。</p><blockquote><p>据悉，中兴通讯董事长、CEO、CTO都将更换，可能还要更换部分执行副总裁（EVP）。中兴很有可能将成为中国首个国企体制，但美国政府监督的全球科技公司。（《财经》）</p></blockquote><p>新时代的买办公司。</p><blockquote><p>【深交所：进一步完善重大违法强制退市实施制度】深交所表示，进一步完善重大违法强制退市实施制度，优化财务类和市场类退市指标体系，对持续经营能力存疑或存在重大不确定事项的高风险公司加大风险警示力度，不断夯实制度基础，防范系统性金融风险，促进深市多层次资本市场健康稳定发展。</p></blockquote><p>越是要加强金融风险控制，不正是意味着风险较大么？综合各个方面的指标和政策，个人觉得危机已经快来临了，当然这个快也并不是一两个月，而是可能在未来的一两年内。</p><h3><span id="2018-06-07">2018-06-07</span></h3><blockquote><p>在今日商务部召开例行新闻发布会上，外媒记者向发言人提问：“华尔街日报的消息说，中国提出来，如果美方放弃新的进口关税，中方愿意购买近700亿美元的农业制造和能源产品，请问这个消息是不是真的？”对此，商务部新闻发言人高峰表示：中美双方在上周末的磋商中，就一些具体的贸易合作领域，特别是农产品、能源领域进行了深入、具体的探讨；中方愿意在相向而行的前提下，扩大自美进口。</p></blockquote><p>这个消息恐怕是真的。</p><blockquote><p>美国商务部部长罗斯表示，美国与中兴达成协议；将对中兴通讯罚款10亿美元；中兴通讯必须30天内更换董事会和管理层；美国将会挑选人员进入中兴通讯的合规团队。（万得）</p></blockquote><p>中兴成为了一个被美国直接监管的国企。</p><blockquote><p>“股神”巴菲特：自己现在是股票市场的净买入者；打赌欧元将在未来十年继续存在；对股市的决策应该独立于当前的商业前景；毫无疑问，美国将在未来10年、20年和30年遥遥领先。</p></blockquote><p>美国的确有资格引领未来的10年、20年，但未必是30年，而且这个差距必然是在缩小的。</p><blockquote><p>桥水基金开始做空大批金融资产，认为金融危机已经快来临了，其核心指标如下：</p></blockquote><div class="tip"><br>1.资金正在以2008年金融危机以来前所未见的速度从股市中抽离；<br><br>2.穆迪$(MCO)$警告，垃圾债券违约的大浪潮正在来临。垃圾债券通常可以视作是大的金融危机到来前的预警信号；<br><br>3.联邦存款保险公司（FDIC）数据显示，一个被市场密切关注的指标——银行不良资产规模在2018年第一季度扩大了3倍，这意味着一些较大规模的银行正处在资产不良的区间；<br><br>4.今年美国债券的开局表现是大萧条以来的最糟糕的一次；<br><br>5.抵押贷款利率创出了7年新高，同时这一利率正在以50年来最快的速度增长，这对于房地产行业而言绝对是一个灾难；<br><br>6.零售行业债务违约率在2018年创了历史新高；<br><br>7.目前正处在零售商店关闭情况最糟糕的一年；<br><br>8.全球最大的两个经济体贸易摩擦仍在继续；<br><br>9.世界第九大经济体意大利正面临着金融体系的崩溃，事实上这还不是最糟糕的，因为不排除意大利困局的负面影响可能会传导至欧元区的其他国家；<br><br>10.意大利的银行类股近期出现了大幅的下跌；<br><br>11.意大利10年债券收益率创出了2014年以来的最高水平；<br><br>12.德国银行巨头德意志银行$(DB)$近期宣布将会裁员7000名以寻求扭亏为盈，事实上德意志银行已经连续亏损多年，如果2018年德意志银行破产的话从本质上而言只是让市场见证了另一雷曼兄弟倒闭。<br></div><blockquote><p>德意志银行计划今年把员工数量裁减至93000人以下。</p></blockquote><p>果然德意志银行存在问题。</p><h3><span id="2018-06-06">2018-06-06</span></h3><blockquote><p>近期碧桂园、富力地产、合生创展等多家房企发债中止，引发市场在流动性紧张背景下的担忧。专家预计，今年下半年会有较多的中小房企违约风险事件发生，中小房企或加速退出市场，行业集中度提升速度料进一步加快。与此同时，众多房企亦在探索新融资模式。（中证报）</p></blockquote><p>房地产的上涨不是政府能随意操控的，释放出的几万亿如洪水猛兽，无法简单的遏制。正如当年大禹治水，不能靠堵，而是要疏导。而这个疏导的出口在哪呢？是非常有价值的问题！</p><h3><span id="2018-06-05">2018-06-05</span></h3><blockquote><p>可以断言，房产税一旦开征，整个社会对于楼市未来走向的预期必然逆转。拥有大量房产的人一定会积极抛售多余的房子，而有了房子的人再也不会把房子当做最佳投资品而想着要去多买几套。楼市供求格局大变也就势在必然。政策与其抡起大棒直接朝房价砸下去，还不如尽快把房产税推出来。</p></blockquote><p>得出这样的结论，不是蠢就是坏！房产税的拐点在于税收的量可以超过今天靠卖地的土地财政，而不是为了平均分配房子。</p><h3><span id="2018-06-03">2018-06-03</span></h3><blockquote><p>今日，今日头条官方表示，腾讯利用垄断地位以各种理由、多次进行不正当竞争的行为。针对其中的“腾讯QQ空间拦截、屏蔽头条网页链接” “腾讯安全管家作为安全软件拦截、屏蔽头条网页链接”，今日头条已经起诉腾讯，目前两案都已于6月1日获得海淀区人民法院立案相关证据都已经提供给法院，详见起诉状。</p></blockquote><p>如果头条可以成功，那么阿里为什么不这么做呢？而且头条的形象还不如阿里正面，感觉在今天的中国，这只是引起人们注意的一种方式而已。</p><h3><span id="2018-05-31">2018-05-31</span></h3><blockquote><p>消息人士透露，美国有99.9%的可能性将对加拿大、墨西哥和欧盟征收钢铝关税，决定将很快做出。（CNBC）</p></blockquote><p>有趣，这是在声东击西吗？这个西又是什么呢？</p><h3><span id="2018-05-30">2018-05-30</span></h3><blockquote><p>白宫周二在声明中表示，美国将对500亿美元含有“重要工业技术”的中国进口商品加征25%的关税，包括与“中国制造2025”相关的技术。最终清单将在6月15日之前公布，关税将在此后不久施行。</p></blockquote><p>美国政府的内部似乎已经很难达成一种相对一致的意见，这在过去一段时间内已经充分体现出来了。</p><h3><span id="2018-05-25">2018-05-25</span></h3><blockquote><p>朝鲜副外相金桂冠称，朝方愿意在任何时候与美国对话。特朗普取消美朝峰会的决定与全世界的希望相悖。朝鲜最高领导人金正恩已尽最大努力，来与特朗普会谈。（朝中社）</p></blockquote><p>朝鲜问题如果圆满解决，那么美国在日韩驻军的合法性就存在问题了，那么现在美国掌权的保守主义还能开心吗？所以即使特朗普非常希望在自己的政绩上加上一笔，但也要那些人点头才行。</p><h3><span id="2018-05-24">2018-05-24</span></h3><blockquote><p>俄罗斯能源部长：将在6月讨论逐步恢复原油产量，预计2018年油价均价将在60美元/桶上方。</p></blockquote><p>俄罗斯原本是希望油价上涨的，但在一些其它目标的驱动下主动放弃了短期的利益。</p><h3><span id="2018-05-23">2018-05-23</span></h3><blockquote><p>据香港经济日报报道，香港改革上市制度后，再有巨型新经济企业拟到港上市。内地最大网约车平台“滴滴出行”最快下半年启动上市，已初步决定落户香港，并考虑不同上市架构，不排除以同股不同权形式上市。消息称，滴滴正积极寻觅主要投资者，询价相当约估值约550亿美元，与去年底最新一轮融资时估值相若，预计滴滴最终上市时市值或能达700亿至800亿美元，随时超越全球另一网约车龙头Uber的约700亿美元估值。</p></blockquote><p>这是个做空的好机会。</p><blockquote><p>我国养老保险基金支出规模仍在快速增加。人社部21日发布的《2017年度人力资源和社会保障事业发展统计公报》显示，2017年职工基本养老保险基金总支出38052亿元，同比增长19.5%，相比2013年的18470亿元增长106%，这意味着近四年职工养老保险基金支出翻了一倍多。此外，基金征缴收入与基金支出缺口持续扩大，制度对于财政补助资金的依赖程度不断提高。</p></blockquote><p>必须自己考虑自己的养老问题。</p><blockquote><p>据华尔街日报：改革多德弗兰克法案的议案以258-159的票数获得众议院通过。改革多德弗兰克法案的议案旨在减少金融危机后对小型银行与社区银行所实施的监管限制。</p></blockquote><p>民粹主义开始流行起来了，金融危机的伏笔各种显现。</p><blockquote><p>房企供应链ABS井喷，规模已达782亿元，至少14家公司涉足以解资金之渴。近日有消息称，恒大拟于5月23日左右发行供应链ABS，由深交所发行。据悉，恒大已获100亿元储架发行额度，期限不超过1年，第一期规模约10亿元。</p></blockquote><p>房企没钱了，但后续会怎么发展呢？</p><blockquote><p>阿根廷央行维持七天回购利率在40.00%不变。</p></blockquote><p>阿根廷金融危机已经爆发。</p><blockquote><p>欧盟委员会：若当前宽松货币政策立场逆转，意大利可能出现风险。由于最近的政策措施和不利的人口趋势，意大利的长期财政可持续性也在减弱。意大利的中期可持续性风险仍然很高，因结构性初步盈余不足以促成公共债务迅速减少。短期内意大利面临的再融资风险似乎有限，主要因市场流动性充裕以及外部环境改善。</p></blockquote><p>意大利总是火药桶的角色。</p><blockquote><p>土耳其里拉兑美元下跌超过3%，跌破4.81里拉。<br>土耳其10年期国债收益率升至15.30%</p></blockquote><p>土耳其经融危机已经爆发。在美元环流的影响下，这些当年无节制借钱的国家很快就尝到苦果了。</p><blockquote><p>意大利5年期信用违约掉期（CDS）升至152个基点，触及近12个月以来最高。</p></blockquote><p>违约掉期上涨意味着大家一致觉得会出现违约。</p><h3><span id="2018-05-21">2018-05-21</span></h3><blockquote><p>央行《一季度货币政策执行报告》在宏观杠杆率、未来货币政策侧重点、金融监管思路转变等方面的表述，与以往有着“明显”不同。宏观杠杆率方面，提出“宏观杠杆率增速放缓，金融体系控制内部杠杆取得阶段性成效”，一改以往强调积极推进“去杠杆”的表述；未来货币政策侧重点方面，将“去杠杆”调整为“调结构”；金融监管思路转变方面，删去“统筹政策力度和节奏，防止叠加共振”，新增“全面清理整顿金融秩序”。“这不免让一些金融机构认为，随着去杠杆接近尾声，各部门金融严监管政策协调力度相对减弱，货币政策侧重点开始转向调结构促经济发展，未来货币政策存在趋松空间，资金流动性较一季度更加宽裕。”某股份制银行信贷部主管表示。</p></blockquote><p>去完杠杆是否会走入下一轮调控？这个恶性循环能否被打破？</p><h3><span id="2018-05-20">2018-05-20</span></h3><blockquote><p>《中美联合声明》<br>   双方同意，将采取有效措施实质性减少美对华货物贸易逆差。为满足中国人民不断增长的消费需求和促进高质量经济发展，中方将大量增加自美购买商品和服务。这也有助于美国经济增长和就业。<br>　　双方同意有意义地增加美国农产品和能源出口，美方将派团赴华讨论具体事项。<br>　　双方就扩大制造业产品和服务贸易进行了讨论，就创造有利条件增加上述领域的贸易达成共识。<br>　　双方高度重视知识产权保护，同意加强合作。中方将推进包括《专利法》在内的相关法律法规修订工作。<br>　　双方同意鼓励双向投资，将努力创造公平竞争营商环境。<br>　　双方同意继续就此保持高层沟通，积极寻求解决各自关注的经贸问题</p></blockquote><p>按照宋鸿兵的解读：美方真正获得利益方首推华尔街金融业，其次是制药公司，再是农业。中国的金融开放如何避免风险？这将是未来一段时间要观察的要点。农业的打击可能很深远，这对中国社会将会产生什么影响？制药公司会不断制造焦虑，中国人真是多灾多难，在任何一个最基础的需求上挣扎着。</p><h3><span id="2018-05-19">2018-05-19</span></h3><blockquote><p>【易方达基金詹余引：接近50%的公募基金投资者持有时间在一年以内】 易方达基金公司董事长詹余引19日在“2018清华五道口全球金融论坛”上表示，现在公募基金的投资者持股是比较短期的，有数据显示，持有单只基金超过5年的投资者大概只有12%左右，有45%到50%的投资者持有时间只在一年以内，投资者的结构会影响基金投资理念的发挥。（中国证券网）</p></blockquote><p>这个统计无情的批判着各种价值投机者。银行螺丝钉的粉丝自从指数下降以后明显就不热情了，之前可是各种价值投资理论烂熟于胸的。</p><blockquote><p>【央行研究局局长徐忠：防范金融风险和经济转型，要提高资产回报率】中国人民银行研究局局长徐忠表示，未来3-5年，中国经济主要把握两条主线：一是经济转型，要从高速增长向高质量发展，要提高全要素生产率；二是防范金融风险。发达国家货币政策也在做结构性改革，全球金融危机以后十年，主要经济体谁的结构性改革走到前面谁走的好，可能对今后二十年全球经济格局的演变有非常重要的作用。提高资产的回报率、提高全要素生产率，是经济转型的需要，也是防范风险的需要。（21世纪经济报道）</p></blockquote><p>“提高资产回报率”这不正好是要投资资产的机会吗？</p><h3><span id="2018-05-18">2018-05-18</span></h3><blockquote><p>近期有关部门召集部分券商进行座谈，就股票质押式回购业务风控、两融绕标套现融资等具体问题展开了讨论。据悉。有关部门在会上叫停了两融绕标套现融资的操作模式，再次强调了股票质押违约处置的流程，要求各家公司控制集中度，并督促各家券商谨慎开展股票质押式回购业务，不得低价竞争，促进行业良性发展。（上证报）</p></blockquote><p>影子银行的控制只能通过座谈？</p><blockquote><p>法国总统马克龙：将维护法国企业的合法权益。欧洲将采取报复措施来捍卫自己的利益。即将召开关于伊朗导弹项目和地区活动的会谈。确认欧洲将维护伊核协议的成果。</p></blockquote><p>马克龙还需要真正做点事情。</p><h3><span id="2018-05-15">2018-05-15</span></h3><blockquote><p>人民日报海外版头版评论文章称，中国将继续坚持对外开放基本国策，坚定不移地推进经济全球化、贸易投资自由化。预计未来五年，中国货物进口额累计超过10万亿美元，对外投资超过1万亿美元，出境旅游人数超过7亿人次，出国留学人员超过350万人，提交PCT国际专利申请量超过30万件。中国发展，世界受益；中国扩大开放，助力世界繁荣。</p></blockquote><p>真正的开放是中国的企业走出去，而不是外国的企业走进来，尤其是金融企业。</p><blockquote><p>美国驻华大使Branstad：特朗普希望大幅度增加对中国的农产品出口。（彭博）</p></blockquote><p>特朗普的希望马上就会成真，只是苦了中国的农民补贴了美国的农民。</p><blockquote><p>美国商务部长威尔伯罗斯美国东部时间5月14日表示，愿意尽快改变对中国手机制造商中兴通讯的销售禁令，此前一天美国总统特朗普表示，要求美国商务部帮助中兴通讯恢复运营。“中兴确实做了一些不合适的事情。 他们已经承认这一点”。罗斯在美国全国新闻俱乐部的活动中说。 “问题是：我们最初提出的措施是否有其他替代方案？ 这将是我们将非常、非常迅速地研究的地方。”（央视）</p></blockquote><p>说谎的最高境界就是明目张胆的说谎，但没有人敢站出来说不。</p><blockquote><p>隔夜纽约原油期货上涨0.4%，收于每桶70.96美元，而布伦特原油收涨1.4%，自2014年底以来首次升至每桶78美元上方。50多名巴勒斯坦人在抗议美国驻耶路撒冷大使馆开馆典礼时遇害，凸显该地区的紧张局势；一周前，特朗普政府重新恢复对OPEC第三大原油生产国伊朗的制裁。</p></blockquote><p>油价节节攀升。</p><h3><span id="2018-05-14">2018-05-14</span></h3><blockquote><p>近两个月楼市出现升温迹象，成交量环比上升，新房价格环比涨幅有所扩大。面对楼市新变化，近半月，住建部约谈12个城市并再次强调楼市调控目标不变，各地楼市再次迎来调控密集期。（中国新闻网）</p></blockquote><p>一轮又一轮，这样做真的有意思吗？</p><blockquote><p>特朗普发推称：我们正在为中兴通讯提供一种快速恢复业务的途径。（因中兴业务无法正常开展使得）中国有太多的工作岗位流失，我已告知商务部要尽快完成这项工作。</p></blockquote><p>中兴柳暗花明。哎，实际上制裁中心美国的芯片公司会损失惨重，那么中兴可能被制裁吗？</p><h3><span id="2018-05-11">2018-05-11</span></h3><blockquote><p>特朗普：将于6月12日在新加坡会见朝鲜领导人金正恩。</p></blockquote><p>时间敲定，但美国必然是没有诚意的。</p><h3><span id="2018-05-10">2018-05-10</span></h3><blockquote><p>去年“317新政”后，北京二手房成交量和成交价持续走低。近两个月以来，北京二手房交易量出现回升，价格趋稳。有分析称，这只是朝着正常交易水平恢复而已，过热并未出现，市场仍旧稳定。（中新网）</p></blockquote><p>压抑资本的投资需求是难以为继的。</p><blockquote><p>美国能源调查公司Rystad Energy：美国重新实施对伊朗的制裁，将导致伊朗原油出口量到今年11月减少70万桶/日。</p></blockquote><p>制裁伊朗的一个重要结果就是要提升石油价格，这符合沙特的预期。</p><blockquote><p>美国WTI 6月原油期货实盘价格周三收涨2.08美元，涨幅3%，报71.14美元/桶。</p></blockquote><p>石油这种大宗商品能跳涨3%算是少有的了。</p><blockquote><p>美国财政部拍卖250亿美元10年期国债，得标利率2.995%、创2014年1月份以来新高，投标倍数2.56、前次为2.46。</p></blockquote><p>10年国债利率在上涨。</p><blockquote><p>沙特能源大臣：美国决定退出伊朗核协议之后，确认沙特出于对产油国和石油消费者利益的考虑而维持原油市场稳定性的承诺。 与OPEC轮值主席国、俄罗斯、以及美国保持密切联系，未来数日，沙特还将接触其他产油国和重要消费者，以确保市场稳定。</p></blockquote><p>沙特的内心里充满了微笑。</p><blockquote><p>美国能源信息署（EIA）：美国5月4日当周EIA石油产出1070万桶/日，创单周历史新高。</p></blockquote><p>美国的页岩油也在欢庆量价提升。</p><h3><span id="2018-05-09">2018-05-09</span></h3><blockquote><p>德国外长：特朗普退出伊朗核协议的决定不算太令人意外。 我们将与盟友一起努力阻止中东局势升级。 我们的目标是继续维持伊朗核协议，协议是有效的。 我们呼吁伊朗坚持核协议下做出的承诺。 我们将留意美国退出伊核协议给企业带来的影响，并考虑欧洲的整体应对措施。</p></blockquote><p>按照鸿学院的分析，伊朗目前来看是走着最保守的路，也不是美国、以色列、沙特希望他走的路。在美国金融制裁的压力下，未来会发生什么变数呢？拭目以待，这可能是近10年最大的一场政治风波。不过，石油看来要涨。</p><h3><span id="2018-05-08">2018-05-08</span></h3><blockquote><p>美国东部时间5月7日下午，白宫称中共中央政治局委员、中国国务院副总理刘鹤将于下周访问美国首都华盛顿，与美国经贸官员继续举行经贸磋商。（财新）</p></blockquote><p>关注谈判局势。</p><blockquote><p>纽约原油跳水跌超3%，因为外媒报道美国总统特朗普可能将不会退出伊朗核协议。</p></blockquote><p>石油居然能在极短时间大幅跳水，有趣。</p><blockquote><p>美国总统特朗普：周二（5月8日）当地时间14:00（北京时间周三02:00）将宣布伊朗核协议决定。</p></blockquote><p>不出意外肯定退出。</p><blockquote><p>意大利五星运动党党首Di Maio：五星运动党不会支持中性政府，呼吁7月份大选。</p></blockquote><p>如果五星运动无法达到足够的选票比例，看起来意大利大选将毫无意义的一轮又一轮。</p><blockquote><p>京东第一季度调整后每ADS收益0.71元人民币，市场预期0.82元人民币。 第一季度营收1001亿元人民币，市场预期989.9亿元人民币。 第一季度商品交易总额（GMV）3,302亿元人民币。 京东预计第二季度营收1200亿~1240亿元人民币，市场预期1223.9亿元人民币。 京东预计全年营收增长29%~33%。</p></blockquote><p>不及预期，跌吧。经过这么多年，京东真的应该证明自己有足够强的护城河和盈利能力，否则这么多钱砸进去，出来个啥呢？只为改善人们生活？</p><h3><span id="2018-05-04">2018-05-04</span></h3><blockquote><p>鸿学院有关芯片问题的讨论。</p></blockquote><p>中国人普遍的系统性思维不足。</p><p>美国推行单边的强权政治导致规矩的破坏，不守规矩会导致维护成本上升，芯片的成本必然上升。</p><p>凡是地大物博的国家都比较粗放，难以形成所谓的“匠人”。</p><p>美国是谈判的高手，可以无中生有制造筹码。</p><blockquote><p>阿里巴巴大肆收购引发投资者疑虑，担忧其盈利能力或遭遇冲击。随着利润和收入增长放缓，阿里巴巴频频收购的行为或终于开始令其盈利受到影响。而该公司市值相比高点损失610亿美元，也反映了投资者的不满情绪。</p></blockquote><p>最近一段时间阿里的表现毫无亮点，护城河上毫无建树，反倒马云天天在国际上各种呼吁。</p><h3><span id="2018-04-23">2018-04-23</span></h3><blockquote><p>分析人士认为，此次海南发布的限购政策，条件异常苛刻，包含户籍、社保、贷款、年限等多重调控手段，这意味着外地新增炒房资金在数年内几乎无法进入海南楼市，前几年流入海南楼市的数千亿炒房资金面临着被“关门打狗”的尴尬局面。易居研究院智库中心研究总监严跃进指出，从限购的广度来说，较其他城市因城施策不一样，海南省全域限购是非常罕见的。（每经）</p></blockquote><p>中国人对房地产的狂热是过去十多年来培养出来的，政府一遍遍惩罚那些没有买房的人，不断去强化房子必须涨价的预期，才造成了像现在这种现象。要纠正这种情况，不可能通过限购，限购只是为了降低房价的杠杆，减少系统风险。</p><blockquote><p>这一建议初听让人热血沸腾，但冷静思考发现，它并不可行，甚至很危险。产业化的芯片业与“两弹一星”服从完全不同的经济规律。夸大“两弹一星”中的独立自主和人定胜天因素，并据此不计成本、闭门发展芯片业，更是有陷入过度社会动员的风险。脱离常识，一门心思想着弯道超车恐怕是欲速而不达。守正出奇才是正确的态度。产业环境和社会人文环境改善了，规模大了，基础厚实了，逆袭才有可能发生。真正的国家意志应该是创造环境，培植基础，而非亲自去做逆袭的计划，逆袭意志的主体只能是企业，并且是民营企业。</p></blockquote><p>两弹一星中领军人员与一线国家的差距要更小，而且只是一锤子买卖，而芯片如果没法赚钱，是不可能不计成本烧钱的。</p><blockquote><p>近期网约车在多城市开展“烧钱大战”引发社会强烈反响。针对这一现象，交通运输部微信号近期连发三篇评论性文章，指出“烧钱大战”不可持续，呼吁网约车发展要“脱虚向实”，运输市场要公平竞争。（中国交通报）</p></blockquote><p>再多的钱也烧不了多久了，赚司机的辛苦钱，是支撑不了成千上万码农的工资的。</p><h3><span id="2018-04-22">2018-04-22</span></h3><blockquote><p>刚成立的公司，如果有很像高管的高管，那这公司也长不了。 – 《知乎》</p></blockquote><p>对于刚成立的公司，每个人都必须实心用事。</p><blockquote><p>国资委报告，在此事件中，中兴通讯公司一系列应对都十分愚蠢和被动，美国的制裁对中兴通讯公司自身及其他中央企业都可能带来高危影响。一定程度上，不仅通讯行业，也不仅国有企业，国内很多企业都在为中兴通讯公司的短视和无诚信经营付出惨痛代价，我国外交布局和国家形象也不可避免地受到影响。</p></blockquote><p>这抹黑的不仅仅是企业，也是一大批充满神秘色彩的“老总们”，他们不再神乎其神，也会犯愚蠢的错误。</p><blockquote><p>鸿学院有关金融对外开放的讨论。</p></blockquote><p>弗洛伦撒之所以能兴起，成为欧洲的金融中心，主要靠三点：</p><ol><li>商人走出去，形成遍布欧洲的商业网络；</li><li>商业网络为教会服务，收取十一税，形成稳定的商业活动；</li><li>参与国家政府融资项目，获取税收等垄断权；</li></ol><p>作为反例，西班牙虽然有发现美洲的优势，但在本国没有形成相应的金融优势，使自己的胜利果实被热那亚商人攫取。而中国要开放，首要问题是这种开放是“对外”还是“对内”。对外意味着中国的商业大规模要走出国门，去服务世界各国；而对内意味着国际金融网络接入国内资本，中国的国有银行将面临全球的竞争，几乎毫无胜算！</p><p>中国的芯片虽然落后，但不过几十年而已。而金融的落后，政治的落后，与发达国家相比相差有数百年，真的需要密切关注这块的发展，因为它关系到每个人的财富变化。</p><h3><span id="2018-04-21">2018-04-21</span></h3><blockquote><p>朝中社报道，朝鲜最高领导人金正恩20日宣布，朝鲜将从21日开始不再进行任何核试验和洲际弹道导弹发射，废弃朝鲜北部核试验场。只要朝鲜不受核威胁挑衅，朝鲜绝对不使用核武器，不泄露核武器和核技术，集中全部力量发展经济，并将与周边国家和国际社会积极展开紧密联系和对话。（央视)</p></blockquote><p>朝鲜果断停止核试验并开始改革开放，这早就在鸿学院里提到，不出意料。下一步，如果有机会购买朝鲜的资产或许是一种很好的投资。</p><blockquote><p>Bitstamp平台数据显示，比特币最近24小时涨7.47%，刷新3月25日以来高位至8888美元。</p></blockquote><p>比特币已经彻底成为各种交易平台炒作赚钱的手段，这8888美元不正好是一种讽刺吗？</p><blockquote><p>美国10年期国债收益率涨至2.955%，为2014年1月以来最高。</p></blockquote><p>国债收益率提高意味着股市下跌。</p><blockquote><p>苹果跌幅达到4.2%。</p></blockquote><p>像苹果这样的大公司也能一天下跌4.2%，还有什么是不可能的呢？</p><blockquote><p>中国企业被诟病过太久，重资产轻人力，行业从业者待遇普遍不高。</p></blockquote><p>这句话很好的描述了中国的现象，正是<strong>“重资产而轻人力”</strong>。无论什么项目，似乎首先做的总是批地、盖楼，然后找一两个凑合的人才，带领一帮水平低下的人开始搞项目。似乎只要找对了方向，人才不是重点。可问题是现在的项目不是搬砖，不是靠蛮力就能搞定的。但我们的政府或企业往往没有长期规划，大批项目的重点不是把好东西做出来，而是要应对各级领导的参观和工作指导。可笑的是，如果一个企业只踏踏实实做事，往往是难以成功的，因为必须得到政府的“支持”，否则银行连贷款都不会给你。</p><h3><span id="2018-04-20">2018-04-20</span></h3><blockquote><p>深圳某投资机构负责人认为，“互联网泡沫2.0”有可能就在未来几年爆发，O2O、互联网金融、大数据、AI可能是“高危地带”，而在这些大领域的“独角兽”企业占比达半数以上。这意味着，可能有一批“独角兽”企业要倒下。“即使没倒下，‘挤泡沫’也是很难避免的。制度设计要避免二级市场泡沫提前向一级市场转移，对于“独角兽”企业IPO前一年内突击入股的投资人需延长锁定期，降低投机色彩。</p></blockquote><p>这种认识我个人非常认同，因为现在的互联网存在大量靠债务支撑的公司，不断融资，拆东墙补西墙却迟迟上不了岸，这种泡沫最终总会以某种形式破裂。</p><h3><span id="2018-03-13">2018-03-13</span></h3><blockquote><p>截至2017年9月30日，美国政府助学贷款总额达1.4万亿美元，有近500万人违约，违约率高达22%。</p></blockquote><p>直接反映美国就业形势并不好，至少工资离债务存在较大的距离。</p><blockquote><p>美国白宫：特朗普总统将在3月20日与沙特王储穆罕默德·本·萨勒曼举行会面。</p></blockquote><p>OPEC对石油的价格无法达成一致，美国页岩油产量还在增加，所以沙特面临较大的财政风险，所以这么着急会面。</p><blockquote><p><a href="https://www.reddit.com/r/investing/comments/83wctc/junk_bonds_diverging_from_sp_500/" target="_blank" rel="noopener">https://www.reddit.com/r/investing/comments/83wctc/junk_bonds_diverging_from_sp_500/</a></p></blockquote><p><img src="https://i.imgur.com/GvYflei.png" alt="pic"></p><p>该网友指出了自己的一个指标：观察junk bounds yield与S&amp;P 500 return之间的关系。他发现最近一段时间两者出现一定的背离，即S&amp;P一直在涨而PHDAX出现明显的下降。这种现象的出现不能直接解读成某种问题，直接反映的可能是资本变得更加倾向一些体量大的公司，就好比前一段时间在A股上证50的涨幅远超过沪深300，更是远超过中小板。这两者始终会一致，所以一方面可能是大盘股回调或小盘股追赶。</p><h3><span id="2018-03-14">2018-03-14</span></h3><blockquote><p>穆迪：将油价预估从45美元/桶上调至65美元/桶，因全球原油减产且需求增速强劲。</p></blockquote><p>最近的油价很焦灼，沙特和伊朗之间的分歧不知道最终会走向何方，沙特依靠美国对伊朗施压的效果究竟会不会提高油价？在3月底可能会有一定的消息透露出来。</p><blockquote><p>美国3月9日当周API原油库存 +115.6万桶，前值 +566万桶。库欣地区原油库存 -15.6万桶，前值 -79万桶。 汽油库存 -126.2万桶，前值 -454万桶。 精炼油库存 -425.8万桶，前值 +149万桶。</p></blockquote><p>原油库存下降有利于油价上升。</p><blockquote><p>“新债王”Gundlach：预计美国政府预算赤字将在2019年达到1.3万亿美元。</p></blockquote><p>美国财政赤字还在加大，系统风险继续加大。</p><blockquote><p>“新债王”Gundlach：考虑到规模为6000亿美元的量化紧缩（QT），美国债市可能会出现大约2万亿美元的债券供应。</p></blockquote><p>各国都在资金回笼过程，人民币也是这样，从而影响到一些垃圾创业公司的生存问题。</p><blockquote><p> 蚂蚁金服1.845亿美元入股巴基斯坦TMB 打造当地版“支付宝”：北京时间3月13日晚，挪威Telenor集团和蚂蚁金服联合宣布，双方已达成战略合作伙伴关系。蚂蚁金服将出资1．845亿美元，购入前者在巴基斯坦的子公司TMB（TelenorMicrofinanceBank）45%股权。</p></blockquote><p>蚂蚁金服可能出现系统风险。一方面国内频繁投资垃圾公司（最近还包括多家共享单车）；另一方面海外的高风险投资可能点燃导火索。</p><h3><span id="2018-03-15">2018-03-15</span></h3><blockquote><p> 全国50大热点城市的土地出让金高达6452.3亿：国家统计局数据显示，1-2月全国楼市（商品住宅）销售面积增速收窄至2.3%。但与楼市销售持续放缓相反的是，房企拿地的热情仍然不减。最新数据显示，在2018年的前2个月里，全国50大热点城市的土地出让金高达6452.3亿，与2017年前两个月的4019.2亿土地出让金相比同比上涨了60.5%。</p></blockquote><p>又是一轮地王？房企视政策于不顾，真的是有作死的感觉了。需要考察一些龙头企业在这次的表现。@新闻里提到龙头企业带头拿地…果然政府的政策都是搞笑的么？政策的执行上还是有些问题。</p><blockquote><p> 央行将进行200亿元人民币7天期逆回购、200亿元人民币28天期逆回购。央行公开市场今日净投放400亿元人民币。</p></blockquote><p>仔细阅读数量，资金实际上是净回笼的，对应了稍紧的货币政策。</p><blockquote><p> 蚂蚁金服消费贷款达 6000 亿人民币，是建行的 3.7 倍。彭博社援引知情人士称，尽管政府监管加强，但通过花呗、借呗业务，阿里巴巴旗下蚂蚁金服的消费贷款规模 2017 年至今增长了一倍。这一规模很可能进一步引发严格的监管措施，影响公司的增长速度。</p></blockquote><p>蚂蚁金服贷款的增加可能来自其互联网征信机制的高效率，但也不能排除其这么大的盘子里的系统风险问题。尚不清楚其违约情况。</p><h3><span id="2018-03-16">2018-03-16</span></h3><blockquote><p>美国1月长期资本净流入 621亿，前值 273亿。国际资本净流入 1197亿，前值 -1193亿。</p></blockquote><p>所谓的国际资本给美国人接盘，其实不能完全这样讲，毕竟美国仍然是世界上最为强大的国家，自然有人愿意来接美国的盘，而不是其它国家。因此，与其说美国有风险，其它国家同样有风险。</p><blockquote><p> 加拿大楼市出现崩跌 房屋销售创五年新低：加拿大地产协会（CREA）最新统计显示，2月加拿大的成屋销售环比跌6.5%，创近五年最低，也较去年12月的峰值连续两个月回落。未经季调的实际销售活动同比下跌16.9%，也为五年新低，并较10年均值低了7%。</p></blockquote><p>如上一条，加拿大这种“度假型”国家太弱，其房地产在金融风险出现时就会出现暴跌。估计不少国内炒房客也在其中吧。</p><h3><span id="2018-03-17">2018-03-17</span></h3><blockquote><p> 美国债务首次触及21万亿美元。美国财政部最新数据显示，联邦债务水平3月15日首次触及21万亿美元。自特朗普2017年1月就职以来，债务增长超过1万亿美元。</p></blockquote><p>系统风险仍然在增加。</p><blockquote><p> 从横向整合到垂直整合 全球芯片业并购愈演愈烈。随着芯片业成本压力与竞争压力加剧，行业龙头纷纷通过并购提升竞争力与市场份额。国际半导体产业协会预计，未来十年芯片产业或从横向整合进入到上下游垂直整合阶段。通过并购，芯片厂商的综合实力将越来越强，产业集中度将越来越高，寡头垄断格局将进一步强化。（中证）</p></blockquote><p>芯片业出现了与以往不同的发展，需要持续关注。Intel自然有它的技术优势，但是这种老牌公司内部的问题往往也根深蒂固，不好说将会如何。</p><blockquote><p>百度申请发行两批次美元债。百度申请发行两批次高级无担保债券，但没有言明每批次的发行额度。</p></blockquote><p>美元的加息对美债形成越来越大的压力。</p><blockquote><p>17日，上海证券交易所公司债券项目信息平台显示，中信证券-滴滴第【N】期CP资产支持专项计划于昨日受理。该计划显示，此次滴滴拟融资金额为100亿元，品种为持证券-ABS。滴滴出行营销副总裁李敏确认该消息属实，但对于滴滴外卖业务他三缄其口。（21世纪经济报道）</p></blockquote><p>最近垃圾公司呈现出许多有趣的特征，比如垃圾公司A与垃圾公司B合作就以为能变成非垃圾公司，比如垃圾公司A开展各种乱七八糟的业务就变成非垃圾公司。滴滴这家公司搞不好就是下一个乐视。当然，它也有一个强劲的竞争对手，美团。</p><div class="tip"><br><br>ABS（Asset-Backed Security）通常的用法是在公司在主营业务之外开辟新的产品时，将新的产品线作为资产抵押借贷。如果该业务失败，那么损失也不会波及原有的主营业务。这对投资人来讲是风险很大的。<br><br></div><h3><span id="2018-03-18">2018-03-18</span></h3><blockquote><p>《鸿学院——朝鲜与美国的会晤》</p></blockquote><blockquote><p>战略就必须有敌人和朋友</p></blockquote><blockquote><p>东北问题的根源是地缘环境恶劣，而改善的关键也在环境改变</p></blockquote><blockquote><p>如果你要投资一个无法放弃的棋子，就必须做到它感恩戴德，否则就是为他人做嫁衣裳</p></blockquote><blockquote><p>如果朝鲜真的走向改革开放，那么将会出现巨大的商机</p></blockquote><p>关注东北与一带一路；关注朝鲜改革开放的机遇。</p><blockquote><p> 英媒称，2017年全球不动产投资创下1.62万亿美元的历史新高，来自亚洲的投资占比超过半数。但伦敦仍是最受青睐的全球不动产投资目的地，因为对英国脱欧的担忧已被英镑贬值的影响抵消。</p></blockquote><p>中国炒房客的爱好：伦敦、澳洲、加拿大。</p><blockquote><p>日前，碧桂园400亿ABS获审批通过，一时间，非标转身ABS似乎成为非标转型最确定的出路。部分非标业务吃重的银行、券商正在山重水复之时，仿佛迎来柳暗花明的前景。但有业内人士表示，部分ABS底层资产涉及项目多，合规难度大，投资勿盲目入场。（中证）</p></blockquote><p>在这种时候提高债务的风险很大，美元加息的压力，非主营业务的风险等等，投资要避开这样的流氓公司。</p><blockquote><p>深圳市交委称3月17日凌晨收到相关举报，经调查，滴滴出行本次违规投放青桔单车约2万辆，该委联合市城管局、交警局于3月17日下午约谈滴滴出行，责令整改并立即收回违规投放车辆。（南方网）</p></blockquote><p>垃圾公司制造垃圾。</p><h3><span id="2018-03-19">2018-03-19</span></h3><blockquote><p>黑龙江省围绕“哈欧班列”已经建成“哈尔滨－汉堡”、“哈尔滨－明斯克”、“大庆－泽布鲁日”、“哈尔滨－莫斯科”四条核心线路，并形成了相应跨境产业链条。黑龙江省这个传统意义上的东北边陲省份，正借力“一带一路”加速成为我国向北开放的前沿地带。</p></blockquote><p>这才是正路！但朝鲜问题是否能顺利解决呢？有待进一步观察。</p><h3><span id="2018-03-20">2018-03-20</span></h3><blockquote><p>OPEC秘书长Mohammad Barkindo：OPEC和伙伴国家目前的焦点是全面、及时执行协议控制原油产出直至2018年底。</p></blockquote><p>油价在2018年底之前应该能保持不会出现大的波动。</p><blockquote><p>据媒体报道，全球最大的消费类无人机制造商大疆正在与投资者进行洽谈，希望能够以150亿美元的估值进行新一轮融资。此次募集的资金大约在5亿至10亿美元之间，交易细节尚未最终确定。“此次融资可能是以股权融资与债务融资结合的方式进行。”一位熟悉交易的内部人士表示，这也是大疆迄今为止规模最大的一轮融资。</p></blockquote><p>智能硬件仍然没有哪家企业真正走出消亡的命运。</p><blockquote><p>被称为固收衍生品交易界的传奇人物、全球最大债基PIMCO前基金经理Harley Bassman，撰文阐释了“美股熊市真正到来的信号”：美股与美债收益率的相关性由正转负时。据他列出的条件，这很可能出现在今年末。参考 <a href="https://www.zerohedge.com/news/2018-03-20/trading-legend-reveals-how-he-will-know-when-real-bear-market-starts" target="_blank" rel="noopener">1</a>和 <a href="https://www.blackrockblog.com/2018/02/21/rates-stocks-rise-together/?utm_source=BlackRock+Blog&amp;utm_campaign=4695393636-RSS_EMAIL_CAMPAIGN&amp;utm_medium=email&amp;utm_term=0_7beec13d69-4695393636-305445649" target="_blank" rel="noopener">2</a>。</p></blockquote><p>读了一遍，里面的逻辑感觉有互相矛盾的地方，感觉并不靠谱。</p><blockquote><p>摩根士丹利：预计美债收益率将在9月份发生倒挂。</p></blockquote><p>倒挂的形势最近一个月时间里变得越来越明显。</p><blockquote><p>白宫发言人桑德斯：美国总统特朗普和沙特王储的会面取得了进展。</p></blockquote><p>石油与军火的交易。</p><blockquote><p>近日，记者多次收到低佣金开户的广告，“无论资金量大小，均可享受万分之二点五的超低佣金率。”部分中小券商实际给出的佣金率更低，万分之二甚至是万分之一点八的佣金率已经不再是资金量大的客户的“专利”。此外，记者还了解到，为争夺优质客户，多家券商已经打破两融业务中的融资基准利率8%以上的行业惯例，融资基准利率在6%到7%之间。（证券日报）</p></blockquote><p>客户的争夺意味着金融市场的不稳定性还在上涨，越来越多的韭菜进入市场了。</p><h3><span id="2018-03-21">2018-03-21</span></h3><blockquote><p>中国商务部：拟对美对华出口的改性乙醇、无缝钢管等加征15%的关税。</p></blockquote><p>中美贸易战的回应。</p><blockquote><p>美国国家安全顾问McMaster将辞职，届时将由John Bolton接任。（纽约时报）</p></blockquote><p>温和派改成了鹰派。</p><blockquote><p>周四（3月22日）纽约尾盘，美国10年期基准国债收益率跌5.86个基点，报2.8244%，财政部拍卖TIPS后不久一度跌至2.7971%。两年期美债收益率跌2.69个基点，报2.2786%，财政部拍卖TIPS后不久一度跌至2.2538%、意味着美联储3月决议声明宣布加息以来的跌幅达到10.36个基点。</p></blockquote><p>股市和债市终于出现此消彼长的现象了，这是QE以来未出现过的状态。是否说明QE的退出已经接近尾声？这正是熊市来临的信号吗？</p><h3><span id="2018-03-22">2018-03-22</span></h3><blockquote><p>沙特能源部长al-Falih：OPEC与非OPEC将持续合作至2019年。原油市场三分之二的供应过剩已经得到解决。沙特有大量可用作燃料的铀储备。</p></blockquote><p>鼓励油价上涨的消息。</p><blockquote><p>新华社华盛顿3月22日电：美国总统特朗普22日签署总统备忘录，依据“301调查”结果，将对从中国进口的商品大规模征收关税，并限制中国企业对美投资并购。特朗普在白宫签字前对媒体说，涉及征税的中国商品规模可达600亿美元。中国商务部此前表示，中方绝不会坐视合法权益受到损害，必将采取所有必要措施，坚决捍卫自身合法权益。</p></blockquote><p>贸易战的硝烟，但只是硝烟。</p><blockquote><p>特朗普律师辞职。（纽约时报）</p></blockquote><p>特兰普身边的人换了一个又一个，如果真出现金融危机，那么特朗普就算是完蛋了。而他肯定不会让危机这么快到来，会尽量拖延，但总有个时间节点是无法抑制住的。</p><blockquote><p>道指跌幅再度超过400点，标普跌约1.6%，纳指跌约1.7%。据纽约时报报道，特朗普律师Johyn Dowd辞职，Dowd负责调查“通俄门”特别检察官Mueller。</p></blockquote><p>中美贸易战升级，股指暴跌。但评论基本上持有这只是一次谈判而已，因为中美经济纠葛太深，如果真的贸易战双方都不会有好结果。</p><h3><span id="2018-03-23">2018-03-23</span></h3><blockquote><p>林毅夫在 #中国发展高层论坛# 称，从计划经济向市场经济转型，中国不是唯一的国家，而很多转型中的国家出现了经济崩溃，危机不断，但中国却是稳定并快速发展，这其中的奥秘或许就是“新人新办法，老人老办法”。</p></blockquote><p>这不正是保守主义的做法吗？一刀切是政治上很不理智的行为，或者说是一种政治幼稚的表现。</p><blockquote><p>3月24日上午，中央政治局委员、国务院副总理、中财办主任、中美全面经济对话中方牵头人刘鹤应约与美国财政部长姆努钦通话。姆努钦向中方通报了美方公布301调查报告最新情况。刘鹤表示，美方近日公布301调查报告，违背国际贸易规则，不利于中方利益，不利于美方利益，不利于全球利益。中方已经做好准备，有实力捍卫国家利益，希望双方保持理性，共同努力，维护中美经贸关系总体稳定的大局。双方同意继续就此保持沟通。（新华社）</p></blockquote><p>贸易战照会后马上开始谈判。</p><blockquote><p>3月23日，在第二届中国直播与短视频峰会上发布的《2017年中国直播行业研究报告》显示，2017年，我国直播行业市场总收入超过300亿元，比上年增长39%。从数据来看，行业仍然在走上坡路。2017年，直播行业用户人数达到了4.2亿，无论是游戏直播用户，还是秀场直播用户，同比增速都超过了50%。直播行业用户规模呈现良好增长态势。（广州日报）</p></blockquote><p>我原本认为直播是一种不靠谱的行业，但自从理解每个人都有选择自己生活的原则后，开始认真审视这个行业。直播实际上满足了相当大一部分人的工作需求和消费需求，那么这就是一个合理的行业。而直播与许多互联网行业不同，它有着非常清晰的变现模式，在互联网这个十分不靠谱的环境下，直播俨然一种清流式的存在。严重看好YY。</p><h3><span id="2018-03-24">2018-03-24</span></h3><blockquote><p>宗庆后在中国发展高层论坛谈到“新零售”时表示，最终来讲互联网的成本更高，“它要把商品送到消费者那里去，最后又要回归到实体零售来”。“我不太认可互联网颠覆，全部颠覆我们不都死掉了？” <a href="http://t.cn/RnCURRJ" target="_blank" rel="noopener">http://t.cn/RnCURRJ</a></p></blockquote><p>这里的讨论非常有价值。随着网络零售对实体店的冲击，造成实体店盈利困难，间接肯定会造成实体店租金下降，从而慢慢压低实体店的成本。随着可能的无人零售的到来，这将与网络零售造成冲击，因为无人零售在人力成本上远远低于快递送达业务。下一步应该密切关注无人零售的发展。但注意这不是指自动贩卖机，自动贩卖机已经在很大程度上证明是入不敷出的，而且是个竞争极其激烈的行业。无人零售特指大型商超，而人力成本又极地的情况，这更像美国商超的状态。从这个角度，每个WMT和COSCO在亚马逊面前并非无力一战！</p><h3><span id="2018-03-25">2018-03-25</span></h3><blockquote><p>沙特王储：OPEC寻求与俄罗斯和其他产油国实现10-20年的供应合作。与俄罗斯就“整体情况”达成共识，正致力于磋商长期性石油合作的细节性内容。</p></blockquote><p>俄罗斯有非常强大的动机要跟沙特合作，而沙特刚刚访问美国，从这个角度来看似乎沙特王储访美并没有达到自己的目的，否则以美国的立场必然要求沙特拒绝与俄罗斯合作，这个政治格局有点意外，可能跟美国本土的石油行业有一定关系。如果是这样，那么沙特和俄罗斯的合作将对石油价格造成很强的影响，而美国因为本国一些利益，失去了沙特在中东的影响力。</p><h3><span id="2018-03-27">2018-03-27</span></h3><blockquote><p>今日，长沙市住建委印发《关于实施差别化购房措施的通知》。长沙市限购区域内“限房价、竞地价”的商品住房项目（不含定向限价房）和新建商品住房项目中144平方米（含）以下户型的普通商品住房，将优先满足首套刚需购房群体。首套购房刚需群体为长沙市户籍的无房家庭和个人（文件施行后离婚且不满1年的不包括在内）、自签订征收协议之日起1年内的被征收人以及符合长沙市限购政策的本市以外户籍无房家庭。</p></blockquote><p>确定这不是突破限购的借口吗？</p><blockquote><p>美国10年期国债收益率跌破2.8%。</p></blockquote><p>10年国债的变化是否符合经济危机的趋势？</p><blockquote><p>美国财政部拍卖350亿美元五年期国债，得标利率2.612%，投标倍数2.50、前次为2.44。</p></blockquote><p>美国发债仍在继续，而收益率还在下降，似乎说明人们把钱都投入债券。</p><blockquote><p>美国30年期国债收益率跌破3%，为2月6日以来首次。</p></blockquote><p>倒挂似乎在加剧，需要关注2年国债收益变化情况，如果其收益上升则说明问题。</p><h3><span id="2018-03-28">2018-03-28</span></h3><blockquote><p>巴克莱：预计WTI原油在下半年会跌至51美元/桶，布伦特原油年底会跌至57美元/桶。</p></blockquote><p>这个预测很别出心裁。。沙特要完？石油是个政治游戏啊！如果真是这样，沙特指定要跟美国翻脸了。从最近沙特与俄罗斯走得很近来看，这不是不可能。</p><blockquote><p>随着上市房企2017年年报的陆续披露，上市房企的融资情况相继浮出水面。从融资成本来看，银行贷款、中票、公司债等方式融资成本多在4%-5%之间，与信托融资相比优势明显。整理目前已披露2017年年报的30余家上市房企信托融资数据发现，上市房企信托融资成本大多集中在6%-10%之间，个别公司的信托融资成本达11%。（证券日报）</p></blockquote><p>这样高的债务利息，看来去杠杆的效果还没真正提现出来，值得警惕了。</p><h3><span id="2018-03-29">2018-03-29</span></h3><blockquote><p>周四（3月29日）纽约尾盘，美国10年期基准国债收益率跌4.18个基点，报2.7389%，美股盘中一度跌至2.7389%，为2月5日以来盘中新低；第一季度，10年期美债收益率累计上涨33.35个基点。两年期美债收益率跌1.81个基点，报2.2661%，美股收盘前一度跌至2.2620%，3月21日美联储发布FOMC利率决议声明前，一度涨至2.3574%、为2008年9月9日以来盘中最高位；第一季度，两年期美债收益率累计上涨38.31个基点。</p></blockquote><p>我一直觉得指望靠国债来避险是个非常幼稚的行为，而考虑10年甚至30年的预期是个绝顶幼稚的行为，购买竞争力足够强大的企业股票才是正道，跟巴菲特的思路才是王道。</p><blockquote><p>CNN恐惧与贪婪指数周四(3月29日)读数8，表明市场处在极度恐慌状态，较上日涨2个点；CNN恐惧与贪婪指数，和“VIX恐慌指数”差不多的功能；当CNN恐惧与贪婪指数处在贪婪状态，相当于VIX恐慌指数处在低位，利好风险资产，不利避险资产；相反，CNN恐惧与贪婪指数处在恐惧状态，相当于VIX恐慌指数处在高位，不利风险资产，利好避险资产。</p></blockquote><p>又一个指数，市场总是不理性的。</p><div class="tip"><br><br>这是一次补记，因为实在比较重要。金正恩临时访华，想必是决定跟中国就访美先交个底？金正恩访美的进程值得关注。<br><br></div><h3><span id="2018-03-30">2018-03-30</span></h3><blockquote><p>摩根大通：预计近期LIBOR/OIS利差扩大会给相应的业务领域带来110亿美元利率成本，并使得家庭利率成本增加50亿美元。 近期LIBOR/OIS利差扩大仅仅是金融条件“非常小幅度的收紧”，不足以促使改变对宏观经济前景的预期。</p></blockquote><p>同意。难道宏观经济有问题就不生活了吗？这不过是政治问题周期性的发酵而已。既不能消除，也没必要过于恐惧。</p><blockquote><p>美联储：美联储主席鲍威尔4月6日将在芝加哥针对经济发表讲话。</p></blockquote><p>已关注。（更新）符合市场预期，并没有什么值得说的。</p><h3><span id="2018-03-31">2018-03-31</span></h3><blockquote><p>湖南能源监管办发布的《湖南省电力企业2017年财务经营情况通报》显示，纳入监测范畴的58家电力企业2017年累计利润总额为8.46亿元，同比下降77.89%。其中，17家火电厂发电599.91亿千瓦时，同比增长17.68%，亏损15.23亿元，同比利润减少19.93亿元，共有14家亏损，占82.4%。</p></blockquote><p>火电在增长的情况下亏损还是如此严重，说明什么问题呢？电价在大幅下降？</p><h3><span id="2018-04-02">2018-04-02</span></h3><blockquote><p>财政部网站1日发布通告称，经国务院批准，国务院关税税则委员会决定对原产于美国的部分进口商品中止关税减让义务，自2018年4月2日起实施。中国对原产于美国的7类128项进口商品中止关税减让义务，在现行适用关税税率基础上加征关税，对水果及制品等120项进口商品加征关税税率为15%，对猪肉及制品等8项进口商品加征关税税率为25%。</p></blockquote><p>种种迹象，我感觉这次贸易战是真的要开打了。从朝鲜、沙特、俄罗斯等国的行为，看起来美国正处于特朗普一个人的个人show time，而这种并没有政治框架的莽夫，注定要经受一次考验了。</p><h3><span id="2018-04-05">2018-04-05</span></h3><blockquote><p>俄罗斯能源部长Novak：与沙特能源部长讨论了当前减产协议过后的长期合作；当前合作机制是有效的；长期合作可能包括监督石油市场，交换信息和采取一些联合行动；目前尚无联合文件公布，但在进行讨论。</p></blockquote><blockquote><p>OPEC主席称，俄罗斯在石油减产计划中是一个“好伙伴”。</p></blockquote><p>沙特与俄罗斯关系暧昧，充分说明美国在放弃自己在中东的立场，也可以理解为何麦克马斯特会辞职了。</p><blockquote><p>近日，在腾讯董事会主席兼CEO马化腾的牵线之下，美团点评正式谈妥投资入股摩拜单车事宜，且投资股权占比较大。另一边，ofo第一大股东滴滴亦最终同意蚂蚁金服投资ofo，此前蚂蚁金服对ofo的借债得以实现债转股，双方就投资细节尚在谈判中。（财新）</p></blockquote><p>祝贺摩拜已上岸。有些无法理解腾讯的立场，难道只是为了支付的流量入口？</p><h3><span id="2018-04-06">2018-04-06</span></h3><blockquote><p>据路透社报道，就在特朗普下令考虑对中国1000亿美元商品加征关税后，美国政府一位高级官员表示，美国愿意与中国就贸易问题进行谈判，但前提是谈判是认真的，因为以往的努力没有取得什么进展。双方尚未安排正式的谈判会议，“目前正与中方就贸易问题进行沟通”。</p></blockquote><p>贸易战再次升级，中方应该已经做好准备，等待特兰普的下一步show。</p><blockquote><p>消息称，欧盟和日本加入美国针对中国技术许可要求提起的世贸组织磋商请求。</p></blockquote><p>欧洲为何要追随美国？这次的态度值得深思。按理说这不符合欧盟的根本利益才对。</p><h3><span id="2018-04-07">2018-04-07</span></h3><blockquote><p>波音从美国航空获得123亿美元的47架梦想飞机协议。</p></blockquote><p>美国似乎也在准备着，给受伤的企业发一点甜枣，但这根本不解决问题。离开中国这个全球最大的市场来谈经济是一种愚蠢的决定。</p><blockquote><p>特朗普致函美国国会参议院金融委员会共和党籍主席Orrin Hatch和众议院共和党籍议长Ryan，解释商务部如何审查国家安全、并发现钢铁和铝进口适用于3月23日所实施的25%钢铁进口关税和10%的铝进口关税。特朗普称，对阿根廷、澳大利亚、巴西、加拿大、墨西哥、欧盟成员国、以及韩国等征收的金属关税被推迟至5月1日。</p></blockquote><p>一些有趣的观察，发现日本不在美国的第一批推迟执行关税国家里，这是不好理解的问题。美国与墨西哥仍然就边境墙的问题在做出一些相互攻击的言论。现在国际局势变得有些微妙，还需要进一步观察。如果EU不能在这件事上保持自己独立的立场，让人无法相信EU真的有复兴的一天，仍然是美国的跟屁虫而已。</p><blockquote><p>I think it’s fascinating to watch how Trump keeps testing his power and discovering that there are very real limits to it. Before entering politics, he has probably had to deal mostly with two categories of people - yes men, and people he could bully. Whether he’s bad at business or not, he has billions of dollars, and lawyers, and a private security force. He could certainly intimidate or bankrupt most people he didn’t like.</p></blockquote><blockquote><p>So then he becomes President and thinks he now has much more power because he still has all the money, but is now also in charge of the world’s largest economy and military. And then he discovers that the President’s power is limited by design. With his travel ban, Trump discovered that the judicial branch doesn’t work for him and can work against him. Then, as he discovered with Sessions and Mueller, even the executive branch can work against him, or at least not the way he’d like. Trump discovered that no, the Department of Justice isn’t like having his own team of attorneys, and the FBI isn’t the President’s personal police force.</p></blockquote><blockquote><p>Then Trump, who apparently doesn’t quite understand what a trade deficit is and how tariffs work, starts talking about tariffs left and right, feeling that it’s him/the US throwing his weight around. Only for him to discover that no, the Chinese government cannot be easily intimidated, and can retaliate by introducing tariffs in kind.</p></blockquote><p>另一个有趣的评论。</p><blockquote><p>The Trump organization is privately owned and run like a family business.</p></blockquote><blockquote><p>I’ve found that family businesses have no room for true meritocracy; they depend on kowtowing to the man at the top. Succession is not by rising through the ranks. It is by being related to the family.</p></blockquote><blockquote><p>If Trump was the CEO of a large publicly traded firm - like Rex Tillerson - he’d have a very different opinion on how decisions are made and how to build consensus.</p></blockquote><blockquote><p>But because he was the CEO of a family business, he still believes in those old-school ideas</p></blockquote><p>Reddit上的有趣的评论。</p><p>最近在看《大明王朝1566》，里面海瑞的格局实在是最高的，能看到封建王朝末期，大地主阶级土地兼并而导致的贫富分化，终于将走向无法调和，导致大明王朝的覆灭。古代200~300年才会出现一次轮回，而现代社会这个周期要短的多。如果不是核武器的发展使大家不再通过战争来解决争端，想必第三次、第四次世界大战也早就打完了。最近的中美贸易战，一方面可以认为是中国和美国之间的矛盾，其实更是全球化和逆全球化之间的矛盾。看起来全球化能加快经济发展，但这使得那些可以通过全球化获利的人的财富积累远远快过普通老百姓，从而加剧了贫富分化。在这场斗争中，没有谁对谁错，只是大家的立场不同而已。逆全球化实际上并不真正解决问题，解决问题的是让那些前几十年得到大量好处的阶层把利益分享出来，否则只是走形式主义，没有用。特朗普能帮助美国解决这个根本问题么？我觉得没戏，因为到目前为止仍然看不到他究竟做了什么有价值的事情。美国之所以强大，是因为他为强大提供了最好的土壤，自由平等包容，这些才是创造力的肥料，而今天他打算闭关来把这些好的留下，怎么可能呢？背道而驰。他真正该做的是在美国人民中提倡教育，发动那些整体无所事事的美国人做一些更有意义的事业，而不是只会吃喝玩乐，享乐生活。在过去的相当长的时间里，美国依靠的是来自其它国家的先进的生产力在维持它自身的高速发展，而最近这些优势在逐步散失。中国正相反，环境在变得越来越好，政府在有意识的吸引优秀人才，这是个非常好的趋势。中国也有贫富分化的问题，而19大已经明确把这件事当成中国社会的主要矛盾来说，不得不感慨中国政府真的做到了与时俱进，而反观美国政府，仍然在一些边缘问题上磨磨唧唧，不敢指出问题的要害。如果问题都提错了，怎么可能解决好呢？这次的“贸易战”于中国正是一次好的机会，一次表明自己立场的机会，正如宋鸿兵所说，如果你有战略却没有敌人，别人怎么敢跟你站队呢？没错，美国就是中国的敌人，而中国的朋友要向西发展，中东、东欧、西欧、非洲，都是中国非常重视的要发展的朋友，而孤悬海外的美国，如果还做着自己“天朝上国”的美梦，就跟清朝差不多了。</p><h3><span id="2018-04-08">2018-04-08</span></h3><blockquote><p>罗奇：特朗普应该好好照照镜子！美国是“扛不住的”</p></blockquote><p>作为一个中国人，实在是一种没有选择的选择，而我目前来说还是觉得中国在经济上会超越美国的，当然前提是中国人的基本观念不发生变化，这依赖政府时刻保持高度警戒，抓住社会的主要矛盾不断深化改革，这的确很难。我越来越佩服我们的政府了，要是我肯定做不到那么全面。</p><h3><span id="2018-04-09">2018-04-09</span></h3><blockquote><p>阿里巴巴董事局主席马云今天向员工发出了一封内部信宣布，彭蕾将卸任蚂蚁金服董事长，蚂蚁金服CEO井贤栋将兼任董事长一职。</p></blockquote><p>阿里内部的变化也挺有意思，蚂蚁金服在这个时候换人究竟传达了一种什么信号呢？</p><h3><span id="2018-04-13">2018-04-13</span></h3><blockquote><p>2018年以来，两市质押股数同比下降16.22%、质押市值下降23%。股票质押市场如今出现“量跌价升”状况，即便出质人降低价格要求，仍难以做成业务，在当前一段时间里的处于“有价无市”状态。2017年期间股票质押的融资利率一般在6%～6.5%之间，如今主流的股票质押利率一般在7%左右，6.5%的质押利率已经少见。 有一些券商，在综合考虑目前的风险与资金成本后，则直接将利率在8%以下的质押业务拒之门外。（证券时报）</p></blockquote><p>似乎反映了金融市场对不确定性（即风险）的感知在加深，7%~8%的利率已经较高了。</p><blockquote><p>美债收益率大涨，特朗普表态暂时缓和投资者对中东局势的担忧。周四（4月12日）纽约尾盘，美国10年期基准国债收益率涨5.50个基点，报2.8358%，盘中交投于2.7698%-2.8413%区间。两年期美债收益率涨4.10个基点，报2.3480%，盘中交投于2.2989%-2.3521%区间。</p></blockquote><p>资金又从债市去了股市？</p><blockquote><p>新媒体信息平台的发展，呼唤并推动着监管机制的创新，特别是更加重视人工智能算法的治理。而即便如此，仅靠监管部门也是不够的，互联网时代需要更加重视用户的力量，建立更具响应能力的举报渠道，发挥好用户作为内容生产者的正面作用。同时，也可以从用户的角度出发，更科学、更合理地对内容、平台进行分类管理。网络治理有了“用户思维”，才能从根本上改变内容生产的生态。</p></blockquote><p>互联网健康监控绝对是AI的好应用场景。</p><blockquote><p>中国证券报头版刊文称，对资本市场尤其是债市而言，除非未来资金面超预期宽松，否则资金面对债市的正面贡献可能逐渐衰弱。目前来看，随着收益率的快速回落，稳货币带来的流动性悲观预期的修复似乎已逐渐反映在市场预期中，且债券供给压力和4、5月存在连续大额财政收税的考验也逐渐临近，后续资金面宽松程度趋于收敛将是大概率事件。</p></blockquote><p>在美元加息的前提下，全球资金量还是以紧缩为基本趋势。</p><blockquote><p>外媒报道称小米正在考虑是否收购运动相机制造商GoPro，消息传出后，GoPro股价飙升近8.8%。根据惠普在2010年收购同样生产艰难的Palm时的出价，GoPro可能售价10亿美元。消息人士表示，尽管小米有收购意向，但不代表公司愿意出高价。 <a href="http://t.cn/Rm9yzwK" target="_blank" rel="noopener">http://t.cn/Rm9yzwK</a></p></blockquote><p>还是那句话，单纯的智能硬件产商很难生存下去，GoPro当年可不是一般的火。小米的根基在手机和家电，这是赚生活费的生意，而其它的各种“玩具”硬件都缺乏现金牛这重保险。</p><blockquote><p>OPEC秘书长默罕默德·巴金多：全球原油过剩自2017年开始有效的下降了十分之九。</p></blockquote><p>最近油价涨的厉害，但也要考虑整体经济下行的压力。</p><blockquote><p>特朗普：只有在TPP协议比奥巴马的版本更好的情况下，才会重新加入。我们已与TPP11个成员国中的6个达成双边协定，正致力于与最大成员国日本达成协议，后者多年来给我们在贸易上带来沉重打击！</p></blockquote><p>连日本都要敲打，这位总统在走钢丝呢。</p><blockquote><p>在此前的一次由中国汽车行业组织的高端论坛上，有相关负责人曾透露特斯拉将会在2018年正式在华独资建厂，这个消息似乎也从侧面佐证了上述汽车产业合资股比放开将在年内正式落地的消息。（经济观察报）</p></blockquote><p>特斯拉股票得涨~</p><blockquote><p>联社4月13日讯，中国央行据悉将放宽对商业银行存款利率上限的非正式指导。（新浪）</p></blockquote><p>如果这是真的，那么将意味着重大的金融改革。中国的银行体系终于能慢慢走出权威政府模式，这带给银行业许多机遇和挑战，例如需要银行加强信用评级体系，强化风控意识等等，而广大的中小企业也将慢慢获得相对优惠的银行贷款。银行的储蓄利率和放贷利率之间的差额在充分竞争后缩小到合理的区间。如果真的能做到这些，余额宝之类的“替代品”将受到严重的威胁。</p><blockquote><p>4 月 13 日，由小米投资的黑鲨科技发布了国内第一款游戏手机。</p></blockquote><p>当年PC游戏火爆的时代，游戏本并没有走出失败的命运；今天，一款面向手游的手机，能否改变这个宿命呢？个人并不看好。手机游戏本质上比PC游戏更加体现休闲，打发碎片化的时间，这似乎离hard core模式更加遥远。</p><h3><span id="2018-04-14">2018-04-14</span></h3><blockquote><p>从A股自身的供给侧改革来看，当前阶段亟需更多增量资金入场，而互联互通额度扩大，提升国际化水平，将对A股营造优胜劣汰生态环境、塑造价值导向具有重要意义。从全球资产配置来看，当前外资对A股整体严重低配，且以被动型基金覆盖为主，这与我国位列世界第二大经济体的地位存在巨大错位矛盾，亟需优化；同时，吸引“独角兽”企业前来A股上市，内地监管层也持欢迎态度，这就需要进一步营造充沛的资金环境，创建高效的估值体系。</p></blockquote><p>感觉证券市场改革是最近一段时间的主流，而国家终于开始认真重视这块了，对A股和中国的所有企业都是一种利好。中国企业依赖银行内部关系的时代是否要终结了？</p><blockquote><p>朱啸虎首次承认已清仓ofo：我们是财务投资人，战略投资人诉求跟我们不一样。</p></blockquote><p>垃圾公司，能有多远躲多远。</p><blockquote><p>新华社记者14日凌晨在叙利亚首都大马士革听到空中传来巨大爆炸声，叙利亚国家电视台说美英法三国对叙利亚“发动了侵略”。（新华社）</p></blockquote><p>弱国无外交。</p><blockquote><p>鸿学院有关叙利亚问题的讨论。</p></blockquote><p><img src="/blog/assets/syria.png" alt="syria"></p><p>当前世界的主要矛盾是民族主义和全球化之间的矛盾，叙利亚只是这种矛盾下的一个旁支，有一定的关联和体现，但不是纯主线。</p><p><strong>天然气</strong> 地理上占据了中东天然气输入欧洲的路线，在俄罗斯和伊朗的支持下加强了这两者对欧洲的天然气控制权。而美国本土的天然气输出与此矛盾。英法试图减弱对俄罗斯在天然气方面的依赖。</p><p><strong>库尔德问题</strong> 库尔德人独立是英法美的一张牌，但打出来同样会损害土耳其的利益，将导致土耳其倒向对手。</p><p><strong>石油价格</strong> 沙特依赖美国巩固其在中东的地位，美国依赖沙特联合打压俄罗斯油价。但最近的形势出现变化，OPEC与俄罗斯达成了协议来提高油价。石油价格上涨根本上也符合美国本土页岩油利益集团的期望，但也跟霸权主义不符。</p><p><strong>化武事件</strong> 3月份英俄之间的神经毒气事件“意外”发酵，也为4月美国对俄罗斯的经济制裁做了铺垫，更为英法美对叙利亚因化学武器的空袭做了铺垫。</p><p><strong>三派势力</strong> 新保守主义、新自由主义、新民粹主义三派势力强弱目前依次递减。前20年新自由主义一直是中国的支持者，但在中国提出一带一路和智能制造2025以后决定转支持为对抗；新民粹主义痛恨中国抢走了他们的制造业，在全球化问题上与中国对抗。</p><p><strong>通俄门</strong> 特朗普上台后即通俄门不断，反应了其它利益集团对民粹主义的不满。本质上特朗普和普京都是反全球化的，在这一点是他们的利益一致。</p><p>一个有趣的问题：中国当前是这三者哪个成分居多呢？</p><h3><span id="2018-04-15">2018-04-15</span></h3><blockquote><p>腾讯智能音箱“腾讯听听”4月20日上市。</p></blockquote><p>智能音箱已经成为红海，各大厂商都有自己的产品，但智能音箱的竞争是资本的竞争，只有足够的钱才能买足够优质的媒体版权，才能雇佣优秀的人工智能人才，才能不计成本推广自己的产品。在这场竞争中，百度是最没有希望的，一个对自己过去的产品三心二意的公司是无法做出好的产品的；腾讯有一定的希望，因为它足够财大气粗，但腾讯的强项是社交，除非沉溺社交的用户，否则来一个跟钉钉一样的使用体验真的很糟糕吧；阿里也财大气粗，但除非这货敢往里面加广告，否则与其已有的业务关联不大，不过这与其做平台的思路是一致的，搭建一个生态系统，让别家来完善；小米似乎有最正当的理由来做这件事，因为智能音箱正好是智能家居的入口，但真正geek到生活的人毕竟少数，而且由于其在媒体资源上相对弱，所以版权上不占优势；京东做这个真心不看好，基本没有什么技术积累和优势；喜马拉雅和yeelight都属于小厂，没法通过补贴推广自己的设备，比较难有前途。</p><p>现在我倒是期待网易的表现，毕竟它一直是以一种有格调的生活为定位的，且其版权资源也算不错。</p><h3><span id="2018-04-17">2018-04-17</span></h3><blockquote><p>美国财政部公布的2018年2月数据显示，中国所持美国国债规模较上月增加85亿美元至1.1767万亿美元，为美国第一大债权国。而在1月，中国则减持了167亿美元，当时持仓规模创下去年7月来的新低。</p></blockquote><p>中国仍然是美债的最大买家。</p><blockquote><p>美国商务部向中兴通讯发出出口权限禁止令。针对中兴通讯发出出口权限禁止令意味着，该公司将被禁止参与接受美国政府出口管理条例管辖的“任何形式的任何交易”，美国出口管理条例管制范围涵盖敏感技术的海外出口。(彭博)</p></blockquote><blockquote><p>招商电子4月17日研报关注中兴通讯禁运事件。招商电子认为，中兴通讯的三大应用领域里，芯片门槛最高的板块是RRU基站，这一领域要想实现国产替代，需要较长时间。光通信和手机产业链门槛相对较低，一些细分领域的国产芯片方案甚至于成为了国际龙头，但整体来看，还是偏低端应用。本次中兴通讯的禁运事件，对于通信产业冲击较大，也敲响了半导体产业的警钟，自主可控不仅仅是口号，而是涉及到国家安全，国计民生的要务。</p></blockquote><blockquote><p>美国商务部禁止美国公司向中兴出售零部件等产品 7 年。美国商务部称，2016 年 3 月中兴已被限制出口，由于中兴在缓期执行期间再次向美国政府做出虚假陈述，违反之前关于向伊朗和朝鲜非法出口电信设备的“和解协议”，商务部依据协议颁布出口禁令，禁止所有美国企业和个人以任何方式向中兴出售硬件、软件、技术服务，期限 7 年，立即执行。中兴手机等产品也将受制裁影响，无法获得零部件</p></blockquote><p>这次贸易战时刻提醒中国的国家安全仍然受到很强的挑战。如果没有微软、Intel、Google中国的IT产业起码倒退20年…因此，应该极度看好中国本土的芯片产业，例如紫光国芯（虽然这货已经很贵），只有拥有可选择的余地才能保障自身安全。</p><blockquote><p>李大霄：降准对稳定经济增长和股市有正面作用 今日央行决定4月25日起下调部分金融机构存款准备金率1个百分点。对此，英大证券首席经济学家李大霄表示，央行对部分金融机构降准及置换中期借贷便利（MLF）的操作，目的在于增加长期资金供应，降低企业融资成本，释放4000亿元增量资金，增加了小微企业贷款的低成本资金来源，解决小微企业融资难融资贵的问题，对于稳定经济增长有正面作用，对于股票市场的稳定也有非常好的正面作用，属重大利好消息。</p></blockquote><blockquote><p>国金李立峰：货币政策由中性偏紧转向适度扩大内需 中国人民银行决定，从2018年4月25日起，下调大型商业银行、股份制商业银行、城市商业银行、非县域农村商业银行、外资银行人民币存款准备金率1个百分点。对此，国金证券李立峰表示，随着外需今年的高度不确定性，今年货币政策理应有所转向，由中性偏紧转向适度扩大内需。今天披露的“央行针对部分银行实施定向降低存款准备金率”，正印证了我们的这一看法：货币政策在微调转向。</p></blockquote><p>货币政策在由严转宽，这似乎意味着某种资产（股票或房子）又开始要涨价了。所谓“照顾”中小企业不知道能怎么执行。接下来应该关注房产限购方面的变化。</p><blockquote><p>俄罗斯政府：普京和默克尔通电话探讨了叙利亚问题。</p></blockquote><p>似乎从某个时间点起英法就已经与美国穿一条裤子了，已经不再独立思考问题了。而德国则有一定的独立性，在此中扮演一种特定的角色。</p><blockquote><p>美国财长Mnuchin：特朗普有关中俄汇率的言论是对两国的“鸣枪警告”，特朗普希望确保中国不会像过去那样让本币贬值。</p></blockquote><p>中美金融战远远没有结束，也不会以这种不清不楚的形式结束。</p><h3><span id="2018-04-18">2018-04-18</span></h3><blockquote><p>美国总统特朗普确认已与朝鲜领导人金正恩直接通话。</p></blockquote><p>期待有进一步的内容曝露。</p><blockquote><p>记者17日从国家发改委获悉：新的外商负面清单将于今年上半年尽早公布实施，包括2018年及未来几年的开放措施。新的外商投资负面清单将把制造业开放作为重点。汽车行业将分类型实行过渡期开放，2018年取消专用车、新能源汽车外资股比限制；2020年取消商用车外资股比限制；2022年取消乘用车外资股比限制，同时取消合资企业不超过两家的限制。通过5年过渡期，汽车行业将全部取消限制。</p></blockquote><p>国产汽车扶植这么多年了，也没见什么起色，而现在放开估计也有外部的压力吧。对于汽车行业真不是好消息，回头想想中国的国产服装，随着国外品牌的进入，什么美特斯邦威、森马、班尼路之流都消失不见了。实际上，随着人们消费能力的上升，并非不能支撑起好的品牌，只是现在资金大都流入一些新兴行业，传统行业的从业人员收入不够，无法聚集足够好的人才，归根结底还是钱的问题。</p><blockquote><p>华尔街日报：以色列据称在美国对叙利亚行动上与美国进行了协商。</p></blockquote><p>美国无法亲自出面的情况下，是否会依赖这个中东盟友做点什么呢？</p><blockquote><p>福特表示对于中国有关外资股比限制的公告感到鼓舞。福特发言人在一封电子邮件声明中表示：“中国发改委的声明让我们感到鼓舞，这清楚地表明了中国政府进一步开放汽车行业的承诺。”</p></blockquote><p>对于福特和特斯拉，这的确是利好。</p><blockquote><p>美联储Williams：真正的收益率曲线倒挂会发出强有力的经济衰退信号。</p></blockquote><p>过去的一个月变化不明显。</p><blockquote><p>美国商务部向中兴通讯发出出口权限禁止，将禁止美国公司向中兴通讯销售零部件、商品、软件和技术7年。去年底工信部发布中国光电子器件产业技术发展路线图（2018-2022年）指出，核心、高端光电子器件落后已经成为制约我国信息产业发展瓶颈。目前高速率光芯片国产化率仅3%左右。政策要求在2022年中低端光电子芯片的国产化率超过60%，高端光电子芯片国产化率突破20%。A股公司可关注光迅科技、新易盛。</p></blockquote><blockquote><p>路透社援引知情人士消息称，美国限制中兴通讯使用美国制造的零部件之后，中兴通讯可能无法在其移动设备上使用谷歌的Android操作系统。消息人士补充称，中兴通讯和Alphabet公司一直在讨论美国政府禁令的影响，不过截至周二上午，两家公司尚未就中兴使用Android的问题做出决定。（中新社）</p></blockquote><p>Andorid都被限制，各种软硬件的限制很严重。</p><blockquote><p>根据美国4月17日提交WTO的文件《美国对来自中国的某些商品的关税措施》，美国表示愿意与中国进行磋商。</p></blockquote><p>终于要走到谈判桌前了吗？</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;每天读新闻，学习思考一些基本的经济逻辑。&lt;/p&gt;
    
    </summary>
    
    
      <category term="investment" scheme="liqul.github.io/blog/tags/investment/"/>
    
  </entry>
  
  <entry>
    <title>Things about replication in Elasticsearch</title>
    <link href="liqul.github.io/blog/things-about-replication-in-elasticsearch/"/>
    <id>liqul.github.io/blog/things-about-replication-in-elasticsearch/</id>
    <published>2018-04-18T13:33:09.000Z</published>
    <updated>2018-04-18T13:33:55.000Z</updated>
    
    <content type="html"><![CDATA[<div class="tip"><br>Updated on 2018-04-18<br></div><p>Elasticsearch is evolving fast in the past few years. There have been quite some discussions on data loss during node crashes, which can be found <a href="https://github.com/elastic/elasticsearch/issues/10933" target="_blank" rel="noopener">here</a> and <a href="https://github.com/elastic/elasticsearch/issues/14252" target="_blank" rel="noopener">here</a>. Most of the issues have been fixed as described <a href="https://www.elastic.co/guide/en/elasticsearch/resiliency/current/index.html" target="_blank" rel="noopener">here</a>. However, since Elasticsearch carried out a major upgrade to version 5+, some serious issues still remain for low versions, e.g., the stale replica problem described <a href="https://github.com/elastic/elasticsearch/issues/14671" target="_blank" rel="noopener">here</a>. </p><a id="more"></a><p>I already discussed in the original article about the two node issue. I recently carried out an experiment with 3 nodes which is actually the recommended minimum size for an Elasticsearch cluster. With 3 nodes, the quorum size is 2 and the minimum master nodes is 2 (discovery.zen.minimum_master_nodes). Therefore, there is always an overlap where some nodes have the latest state. Let me explain this with an example. The nodes are A, B, and C. We go through the following test steps:</p><ol><li>Create a new index with 2 replicas, i.e., 3 copies in total;</li><li>Shut down A;</li><li>Index 1 document on index B and C successfully;</li><li>Shut down B and C;</li><li>Turn on A;</li></ol><p>What about the state for the index? The replica on A will not be allocated as the primary shard since there is only one alive node less than the minimum master nodes 2. Now, we turn on B. As B has the latest state, B propagate the latest state to A. </p><p>Most of open sourced distributed system rely on a mature consensus approach such as Raft or Zookeeper. However, Elasticsearch decided to invent its own. This actually leads to most of those serious issues. This really drive me crazy :( </p><p>So far as I know, the most close setting to make elasticsearch strong consistent in a 3 node cluster consists of:</p><ul><li>A minimun master nodes = 2</li><li>write consistency = quorum</li><li>write/read/search preference = primary</li><li>check if index succeeds on &gt;= 2 nodes</li><li>always refresh before search (assume search is an infrequent operation)    </li></ul><p>========</p><p>Replication is a key feature for Elasticsearch from two aspects: (1) When some machines fail, the alive ones can still serve requests; (2) Replication boosts the read speed since read can retrieve data from multiple nodes simultaneously. </p><p>Elasticsearch follows a primary-secondary fashion for replication. When a write request (e.g., create, index, update, delete) arrives, it is first forward to the primary replica. The primary replica finishes the request, and then, concurrently forward the requests to all alive secondary replicas. There are a few details about this process. </p><p>First, there is a concept of write consistency level in Elasticsearch, with available options one, quorum, and all. This concept is a bit different from what we normally find for other systems such as Kafka. It barely forces the primary replica to check if there are enough alive replicas available receiving a write request. For instance, suppose we have a cluster of 3 nodes with replica number 2, i.e., each shard is with one primary replica and 2 secondary replicas. If we set the write consistency level to quorum, when the primary replica receives a index request, it checks if there are at least 2 replicas available (i.e., &gt;=replicas/2+1). If the check passes, the primary replica will start the action of index, after which it forward the request to all replicas. One should note that the consistency level is only for the check. This means there is a chance when a replica fails after the check, and right before the action.</p><p>Second, we need to answer the question: when shall the primary replica respond to the client? It turns out that there are two modes, sync and async as discussed <a href="https://discuss.elastic.co/t/es-default-async-or-sync/19654" target="_blank" rel="noopener">here</a>. The sync mode means the primary replica only responds the client if “all” secondary replicas have finished the request. Note that the “all” here, which has nothing to do with the selected write consistency level. Under the async mode, the primary replica responds to the client right after itself finishing the request. The request is then forward to other replicas in an async way. This accelerate the response timing for the client, which however may lead to overload for the Elasticsearch cluster. Mean while, since the request propagates eventually to the replicas, there will be no read-write consistency guarantee even inside the same session if the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.3/search-request-preference.html" target="_blank" rel="noopener">read preference</a> is not set to primary. </p><p>In normal case, there is only one primary replica for each shard. Once the primary replica fails, a secondary replica is elected to serve as primary. In some special situations, the primary replica may lose connection to other replicas, leading to multiple primary replicas in the system, which is called the split brain problem as discussed <a href="https://qbox.io/blog/split-brain-problem-elasticsearch" target="_blank" rel="noopener">here</a>. The cue to this problem is by setting the discovery.zen.minimum_master_nodes to &gt;= half of nodes + 1. For example, if you have 3 nodes, the minimum_master_nodes should be set to 2. By setting the minimum_master_nodes we ensure that the service is only available if there are more than minimum_master_nodes living nodes within one master domain. In other words, there can not be two masters in the system. </p><p>Finally, I want to discuss the problem of stale shard which I read recently from <a href="https://www.elastic.co/blog/tracking-in-sync-shard-copies" target="_blank" rel="noopener">here</a>. Let’s start by use a concrete example. Say if we have two nodes and each shard has two replicas (one primary and the other secondary). We first index 10 documents with the secondary shard node turned off. Then, we turn off the primary shard node, and bring up the secondary shard node. The question here is whether the secondary shard will be promoted to primary? If it is, how about the 10 documents we indexed before? According to this <a href="https://www.elastic.co/blog/tracking-in-sync-shard-copies" target="_blank" rel="noopener">blog</a>, with Elasticsearch v5+, the primary shard will not only do the index, but also inform the master about in-sync shards. In this case, the answer to our questions are no. Because the secondary shard is not in in-sync state after being brought up. I didn’t experiment it myself about this since I don’t have a Elasticsearch v5+ environment. I only tested this with Elasticsearch 2.4.5 where I found different answer. After secondary shard node was brought up, the secondary shard was indeed promoted to primary, and the 10 documents were lost if I then brought up the previous primary shard node. This is indeed a problem if such special situation happens, which however should be quite rare in practice especially if you have more than 2 nodes, and with quorum write consistency level.</p>]]></content>
    
    <summary type="html">
    
      Notes on what I learn about replication in Elasticsearch.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="consistency" scheme="liqul.github.io/blog/tags/consistency/"/>
    
      <category term="elasticsearch" scheme="liqul.github.io/blog/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Notes on HBase</title>
    <link href="liqul.github.io/blog/hbase/"/>
    <id>liqul.github.io/blog/hbase/</id>
    <published>2018-04-17T14:47:09.000Z</published>
    <updated>2018-04-17T15:05:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>So far as I know, HBase is the first open source “table” style storage in the big data scope. It is an implementation of the <a href="https://research.google.com/archive/bigtable-osdi06.pdf" target="_blank" rel="noopener">BigTable paper</a> presented by Google. If you read the paper or the <a href="https://hbase.apache.org/book.html" target="_blank" rel="noopener">reference guide</a>, HBase does not look like a table. The paper tells you that it is a </p><blockquote><p>sparse, distributed, persistent, multidimensional sorted map.</p></blockquote><a id="more"></a><p>There are so many details in this definition. If you want to find out what each of these terms means, you can go through this <a href="https://dzone.com/articles/understanding-hbase-and-bigtab" target="_blank" rel="noopener">article</a>. After reading it, you’d rather call HBase a map, instead of a table, because the data structure is</p><blockquote><p>(row key, column family:qualifier, timestamp) -&gt; value</p></blockquote><p>From the perspective of RDBM, each table in HBase could still be thought of as, for example, a table in MySQL. Data is organized into rows and each row is composed of columns (grouped into column families). A cell is specified by its row key and column name. So far, everything is the same with RDBM. You can insert rows, manipulate fields within a row, retrieve a row by its row key, and so on. The <strong>timestamp</strong> is actually an internal concept, <a href="https://www.ngdata.com/bending-time-in-hbase" target="_blank" rel="noopener">which should not be used by the user</a> or even put in the data model. In fact, timestamp is used as a version number. Therefore, to the user, there are still two dimensions (row and column) like in an ordinary RDBM table. </p><p>HBase has been out there for quite a few years, so it is not hard to find a good introduction about what is going on inside. This <a href="https://mapr.com/blog/in-depth-look-hbase-architecture/" target="_blank" rel="noopener">blog</a> has really nice diagrams. It covers comprehensively some of the most important building blocks of HBase, which I’d like to elaborate a few below. </p><h3><span id="data-organization">Data Organization</span></h3><p>Each row in a HBase table is break into cells for persistence. And each cell is in fact a key-value pair, where the key is (row key, column family:qualifier, timestamp). Data is first written to a memory cache called MemStore. Once the MemStore accumulates enough data, the data is flushed into a persistent file called HFile. Both data in the MemStore and in the HFile are sorted by their keys. Each flush may generate more than one HFiles. Each row of data is break down by defined column families. For instance, if the table is with two column families, each flush will get two separate HFiles. </p><p>A row is not stored as a whole, especially if the row has been manipulated later after insertion. Therefore, each time the client read a row, HBase goes through the MemStore and maybe, a few HFiles to bring together all fields to assemble the row. This is called the <strong>read amplification</strong> problem. </p><p>HBase keeps its metadata inside a special HBase table called METADATA. The metadata maintains a set of pointers where the key is a three-value tuple [table, region start key, region id] and the value is the RegionServer. If the client wants to find a specific row key, it will go through the metadata to find the right RegionServer. Then, the RegionServer go through its managed regions to find the required data. A HFile is with multiple layers of index, bloom filters, and time range information to skip as much unnecessary data as possible. </p><h3><span id="data-write">Data Write</span></h3><p>Writing data into HBase has three steps. Firstly, the data is written to a WAL on HDFS. Secondly, the data is written to the MemStore. Finally, when the MemStore size reaches a threshold, the data is flushed into HDFS. In fact, once the data is recorded into the WAL, the write is already successful, though the data is invisible at that moment. If the RegionServer crashes before writing to the MemStore, the data can still be loaded into MemStore once the server recovers. </p><p>HBase does not support cross row transactions. However, it does support atomic intra-row operations, and we know that a row is actually a set of key-value pairs. Therefore, <strong>I think</strong> the set of key-value pairs are grouped into a transaction. </p><p>HBase provides strong consistency for read and write, which means every read gets exactly the same result. The result depends solely on the timestamp the request is received by HBase. In the HBase architecture, strong consistency is achieved based on HDFS. In other words, the HBase provides a consistent global view to the WAL for all RegionServers. </p><h3><span id="compaction-and-split">Compaction and Split</span></h3><p>HDFS is designed for batch process, and therefore, huge number of small files can cause a unacceptable memory footprint to the NameNode. There are two kinds of compaction, the minor compaction and the major compaction. A minor compaction collects a set of HFiles (belonging to the same column family) and merge them into one. A major compaction merge all HFiles belonging to the same column family into one. Since a major compaction consumes quite a lot of resources, it is recommended to be carried out carefully. From this point of view, HBase is not really suitable for use cases where data is manipulated frequently.</p><p>A region is a consecutive range of row keys. Once a region reaches a certain size (e.g., 1G), the region is split into two. This is to keep the size of a region from being too big. Big region is bad since <strong>region</strong> is the unit of parallal access in HBase. For instance, a mapreduce program treat each region a split. The region is split in an automatic way in default. But the user could also predefine the split boundaries when creating the table. </p><p>If the regions are split automatically, one need to be careful about the row key design. For instance, if the row key is mono-increasing numbers, the new arriving data will always be inserted to the newly split region, creating write hotspot. In generally, the row keys should be random enough to prevent both read hotspot and write hotspot. </p><p><br><br><br></p><p>Finally, I’d like to give my two cents on HBase:</p><ul><li>Better documentation: The current document is not well written. The text contains a lot of references to Jira issues and external articles which is really disrupting. As discussed above, HBase is really about <strong>tables</strong>, not some complicated maps. I understand the differences, but as a beginner, I prefer concepts closer to my existing mindset. </li><li>SQL interface: Providing a SQL-like interface is much more friendly than raw Java apis. Such an interface helps users to play with HBase much more easily. </li><li>Predefined partition: Predined partition feels more controllable than the automatic split. Though there is a way of defining the split boundaries which is still quite indirect. In practice, people usually know how to partition their data to achieve the best performance. This is the well adopted use case for RDBMs. </li><li>Local filesystem: HDFS is designed for batch access which HBase can be used for random access, even with frequent manipulations. Local filesystems might be a better choice. </li></ul><p>I also read about Kudu and MapR-DB. From the architecture point of view, they actually share a lot of design patterns. Only, Kudu and MapR-DB are built on the shoulder of HBase, so they can avoid pitfalls. Anyway, HBase is still a very good designed software which provide a very good study case. Thanks to the community and the contributors.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;So far as I know, HBase is the first open source “table” style storage in the big data scope. It is an implementation of the &lt;a href=&quot;https://research.google.com/archive/bigtable-osdi06.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;BigTable paper&lt;/a&gt; presented by Google. If you read the paper or the &lt;a href=&quot;https://hbase.apache.org/book.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;reference guide&lt;/a&gt;, HBase does not look like a table. The paper tells you that it is a &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;sparse, distributed, persistent, multidimensional sorted map.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="HBase" scheme="liqul.github.io/blog/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>投资的心法</title>
    <link href="liqul.github.io/blog/invest/"/>
    <id>liqul.github.io/blog/invest/</id>
    <published>2018-04-12T13:45:21.000Z</published>
    <updated>2018-04-12T14:14:22.000Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="为什么要投资">为什么要投资？</span></h2><p>自从货币与黄金脱钩以后，整体的发展趋势总是超发的。政治家还经常会以各种借口来增发货币，比如“量化宽松”这个听起来不知所云的名词，本质就是货币超发。你辛苦工作后换来的货币随着时间流逝，其内在价值在逐渐变少。怎么能尽量减少由于一些不确定性造成的经济损失呢？一般人除了投资似乎没有别的办法。</p><a id="more"></a><h2><span id="巴菲特的估值核心护城河-安全边际">巴菲特的估值核心：护城河 + 安全边际</span></h2><p>基本概念有两个，</p><ul><li>护城河：企业有足够强的竞争优势甚至是垄断，并且企业在不断加大这种优势，同时企业本身的业务是具有长久的生命力的</li><li>安全边际：只有企业的股价与其内在价值相比足够便宜（如5折）的情况下的购买才是相对安全的</li></ul><p>护城河用一句话来概括：</p><p><div class="tip"><br>“如果你不能拥有一支股票10年，那么就不要拥有它10分钟”。<br></div><br>护城河实际上比起安全边际更加重要（除非现在的价格已经严重背离其内在价值），因为一家伟大的公司即使现在落魄，将来还是很有希望回归的。</p><h2><span id="etf的优势和劣势">ETF的优势和劣势</span></h2><p>ETF的优势在于其天然具备良好的“护城河”，因为你永远不用担心一个ETF会破产，或者ETF对应的企业不是行业里优秀的（因为通常ETF都会有一定的优胜劣汰机制）。其劣势是由于ETF足够“宽”，所以也意味着你获得的收益不如某些个股表现突出。但对于一般投资者来说，要准确找出这些个股的难度太大了，而历史上真正长期（10年以上）做到这一点的专业投资人凤毛麟角，所以投资ETF的实际收益要远远好于投资个股。另一方面，ETF的价格相对个股比较稳定，从而也更难买到足够便宜的，除非市场出现重大的波动。</p><h2><span id="永远不要动用生活费">永远不要动用生活费</span></h2><p>只有在不动用生活费的前提下才能使自己的损失更少。股指的短期波动是难以预料的，如果短期的下跌并不影响你的生活，那么为什么要着急把股票卖掉呢？而如果并不影响你的生活，你又为什么那么在意股指在短期内的波动呢？如果你坚信你所购买股票的公司是经过你认真分析的（前面提到的护城河），不会在短期内倒闭（如果是ETF那根本不会发生），那么请把你的钱留在股市里，因为“健全”的股市迟早有一天会回到这样的高度。你担心股市永远不会回到这样的高度？如果是那样的话，必然已经有一些更加令人担心的事情出现了（比如战争），那这些钱是在股市还是银行真的有区别吗？</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;为什么要投资？&quot;&gt;&lt;a href=&quot;#为什么要投资？&quot; class=&quot;headerlink&quot; title=&quot;为什么要投资？&quot;&gt;&lt;/a&gt;为什么要投资？&lt;/h2&gt;&lt;p&gt;自从货币与黄金脱钩以后，整体的发展趋势总是超发的。政治家还经常会以各种借口来增发货币，比如“量化宽松”这个听起来不知所云的名词，本质就是货币超发。你辛苦工作后换来的货币随着时间流逝，其内在价值在逐渐变少。怎么能尽量减少由于一些不确定性造成的经济损失呢？一般人除了投资似乎没有别的办法。&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="investment" scheme="liqul.github.io/blog/tags/investment/"/>
    
  </entry>
  
  <entry>
    <title>Eventual Consistency vs. Strong Consistency</title>
    <link href="liqul.github.io/blog/consistency_model/"/>
    <id>liqul.github.io/blog/consistency_model/</id>
    <published>2018-03-16T07:05:39.000Z</published>
    <updated>2018-04-12T13:33:38.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://cloud.google.com/datastore/docs/articles/balancing-strong-and-eventual-consistency-with-google-cloud-datastore/" target="_blank" rel="noopener">Here</a> is a very good explanation about eventual consistency and strong consistency. I’d like to borrow the two figures on that page below:</p><p><img src="/blog/assets/eventual-consistency.png"><br>Fig. 1 figure for eventual consistency</p><a id="more"></a><p>In this example above, Node A is the master, which replicate X to its followers Node B and C. Suppose the time when X is successfully writen to Node A is t_1, and the time when X  is replicated to Node B is t_2. Any time between t_1 and t_2, if a client reads from Node A, it gets the latest value of X. But if the client reads from Node B, it gets an old version of X. In other words, the result of a read depends on which Node the client reads from, and therefore, the storage service presents an inconsistent global view for the client. </p><p>In contrast, if the storage service provides a strong consistency semantic, the client should always read the same result. This figure below illustrates an example of strong consistency. </p><p><img src="/blog/assets/strong-consistency.png"><br>Fig. 2 figure for strong consistency</p><p>The single difference between Fig. 1 and Fig. 2 is that before X has been successfully replicated to Node B and C, a read request of X to Node B and C should be blocked. How about reading from Node A before all replications done? It should be blocked as well, and therefore, there is a missing  ‘lock’ symbol in Fig. 2. The full picture should has the following steps:</p><ol><li>A client issues a write request of X to Node A;</li><li>Node A locks X globally to prevent any read or write to X;</li><li>Node A store X locally, and then replicate X to Node B and C;</li><li>Node B and C store X locally and send Node A a response;</li><li>After receiving from Node B and C, Node A release the lock of X and respond to the client;</li></ol><p>These steps are only used to understand the basic idea of strong consistency, which is not necessary a best practice. If you want to know more details, research some real systems such as Spanner or Kudu.</p><p>While sounds more understandable for developers, strong consistency trades Availability for Consistency. In the instance shown in Fig. 2, a client may need to wait for a while before it reads the value of X. If the networking fails apart (for example, Node C is partitioned from Node A and B), any write requests to Node A will fail if each value is forced to have 3 replications. In addition, if the global lock service fails, the storage service will also be unavailable. In general, a storage service with strong consistency has much higher requirements to the infrastructure in order to function well, and therefore, is more difficult to scale compared to one with eventual consistency.</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel" target="_blank" rel="noopener">AWS S3’s consistency model</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://cloud.google.com/datastore/docs/articles/balancing-strong-and-eventual-consistency-with-google-cloud-datastore/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Here&lt;/a&gt; is a very good explanation about eventual consistency and strong consistency. I’d like to borrow the two figures on that page below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/eventual-consistency.png&quot;&gt;&lt;br&gt;Fig. 1 figure for eventual consistency&lt;/p&gt;
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="distributed" scheme="liqul.github.io/blog/tags/distributed/"/>
    
      <category term="consistency" scheme="liqul.github.io/blog/tags/consistency/"/>
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
  </entry>
  
  <entry>
    <title>Reading &quot;State Management in Apache Flink&quot;</title>
    <link href="liqul.github.io/blog/flink/"/>
    <id>liqul.github.io/blog/flink/</id>
    <published>2018-02-05T12:47:09.000Z</published>
    <updated>2018-04-12T13:34:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="tip"><br>Updated on 2018-02-05<br></div><p>I recently read an excellent <a href="https://streaml.io/blog/exactly-once/" target="_blank" rel="noopener">blog</a> about exactly-once streaming processing. It details typical solutions for exactly-once processing used by various open source projects. No matter if the solution is based on streaming or mini-batch, exactly-once processing incurs a inevitably latency. For example in Flink, the state at each operation can only be read at each checkpoint, in order not to read something that might be rollbacked during a crash. </p><a id="more"></a><p>===</p><p>I recently read the VLDB’17 paper “State Management in Apache Flink”. In one sentence,</p><blockquote><p>The Apache Flink system is an open-source project that provides a full software stack for programming, compiling and running distributed continuous data processing pipelines.</p></blockquote><p>For me, Flink sounds yet another computation framework alternative to Spark and Mapreduce with a workflow management tool. However,</p><blockquote><p>In contrast to batch-centric job management which prioritizes reconfiguration and coordination, Flink employs a schedule-once, long-running allocation of tasks. </p></blockquote><p>How exactly does a streaming-centric framework differ from a batch-centric framework? Conceptually, there is no fundamental difference between the two. Any batch processing framework can work “like” a streaming processing framework by reducing the size of each batch to 1. However, in practice, they are indeed different. A batch-centric framework usually involve a working procedure such as </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">batch 1 start</span><br><span class="line">do some job</span><br><span class="line">batch 1 end</span><br><span class="line">update some state</span><br><span class="line"></span><br><span class="line">batch 2 start</span><br><span class="line">do some job</span><br><span class="line">batch 2 end</span><br><span class="line">update some state</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>Note that the job is started and ended within each batch. In contrast, for a streaming-centric framework, </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">start a job</span><br><span class="line"></span><br><span class="line">receiving a new data</span><br><span class="line">process the data</span><br><span class="line">update some state</span><br><span class="line">pass the data to the next job</span><br><span class="line"></span><br><span class="line">receiving a new data</span><br><span class="line">process the data</span><br><span class="line">update some state</span><br><span class="line">pass the data to the next job</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">end the job</span><br></pre></td></tr></table></figure><p>This comparison is clear. A job in the streaming-centric framework usually work continuously without being started/stopped multiple times as in a batch-centric framework. Starting and stopping a job usually incur some cost. Therefore, a batch-centric framework usually performs less efficiently compared to a streaming-centric one. Additionally, if the application is mission critical (e.g., malicious event detection), processing data in batch usually means high latency. However, if the task is batch-by-batch in nature, a batch-centric framework usually performs as efficiently as a streaming-centric one. </p><p>Another problem is about snapshotting. Snapshotting is a key capability for a processing pipeline. A snapshot is consist of both the state and data. The global state of the pipeline is composed of the sub-state of each operator. Each state is either a <em>Keyed state</em> or a <em>Operator state</em>. The former represents all type of states indexed by the key from data (e.g., count by key); the latter is more an operator-aware state (e.g., the offset of data). Snapshotting the data is tricky where Flink assumes that </p><blockquote><p>Input data streams are durably logged and indexed externally allowing dataflow sources to re-consume their input, upon recovery, from a specific logical time (offset) by restoring their state. This functionality is typically provided by file systems and message queues such as Apache Kafka</p></blockquote><p>Each operator snapshots the current state once processing a mark in the dataflow. With the marks and the snapshotted states of each operator, we can always restore the system state from the last snapshot. One should note that the keyed state is associated with an operator, and therefore, the data with the same key should be physically processed at the same node. Otherwise, there should be a scalability issue. Consequently, there should be a shuffle before such operators, or the data is already prepared to ensure data with the same key is processed at a single node.</p><p>In conclusion, Flink is great as streaming-centric frameworks have some fundamental advantages over batch-centric frameworks. However, since batch-centric frameworks such as Mapreduce and Spark are already widely applied, there should be really strong motivations to migrate existing systems to this new framework. Moreover, the implementation quality and contributor community are two very important facts for the adoption of a new born framework, while Spark has been a really popular project. Maybe, a higher level project such as the <a href="https://beam.apache.org/" target="_blank" rel="noopener">Apache Beam</a> is a good direction. Beam hides the low-level execution engine by unifying the interface. Any application written in Beam is then compiled to run on an execution engine such as Spark or Flink.</p>]]></content>
    
    <summary type="html">
    
      Understanding the concepts in Apache Flink.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="flink" scheme="liqul.github.io/blog/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Notes on MR memory issues</title>
    <link href="liqul.github.io/blog/experience_with_mr_memory_parameters/"/>
    <id>liqul.github.io/blog/experience_with_mr_memory_parameters/</id>
    <published>2018-02-05T03:29:09.000Z</published>
    <updated>2018-04-12T13:37:19.000Z</updated>
    
    <content type="html"><![CDATA[<div class="tip"><br>Updated on 2018-02-05<br></div><p>I recently encountered several OOMs from mapper tasks reading parquet files. The yarn container is killed due to running out of physical memory. Since I already set the JVM memory to 0.8 of the container size, I’m pretty sure that this is due to off-heap memory allocation issues. I found the two jira issues <a href="https://issues.apache.org/jira/browse/SPARK-4073" target="_blank" rel="noopener">here</a> and <a href="https://issues.apache.org/jira/browse/PARQUET-118" target="_blank" rel="noopener">here</a>, pointing me to the snappy codec used by parquet for decompression. There aren’t so much I can do except allocating more memory beside the JVM.  </p><a id="more"></a><p>===</p><p>I recently experienced two OOM problems running a mapreduce application. The MR application reads from a group of parquet files, shuffles the input rows, and writes into parquet files, too. </p><p>The first OOM is thrown by the mapper with error logs look like following</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2017-06-22 09:59:10.978 STDIO [ERROR] [WORKER] [129] Container [pid=14638,containerID=container_e26_1495868456939_0784_01_000066] is running beyond physical memory limits. Current usage: 1.0 GB of 1 GB physical memory used; 1.5 GB of 2.1 GB virtual memory used. Killing container.</span><br><span class="line">Dump of the process-tree for container_e26_1495868456939_0784_01_000066 :</span><br><span class="line">    |- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE</span><br><span class="line">    |- 14638 14632 14638 14638 (bash) 0 0 17096704 774 /bin/bash -c /usr/lib/jvm/java-7-oracle-cloudera/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx1024m -Djava.io.tmpdir=/disk1/yarn/nm/usercache/hdfs/appcache/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/disk2/yarn/container-logs/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.130.123 46432 attempt_1495868456939_0784_m_000020_1 28587302322242 1&gt;/disk2/yarn/container-logs/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066/stdout 2&gt;/disk2/yarn/container-logs/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066/stderr  </span><br><span class="line">    |- 14655 14638 14638 14638 (java) 4654 290 1616650240 272880 /usr/lib/jvm/java-7-oracle-cloudera/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx1024m -Djava.io.tmpdir=/disk1/yarn/nm/usercache/hdfs/appcache/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/disk2/yarn/container-logs/application_1495868456939_0784/container_e26_1495868456939_0784_01_000066 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 192.168.130.123 46432 attempt_1495868456939_0784_m_000020_1 28587302322242</span><br></pre></td></tr></table></figure><p>After some investigation, I realized this is due to a misconfiguration of the mapper container memory limit (mapreduce.map.memory.mb) and the mapper JVM memory limit (mapreduce.map.java.opts). Basically, the latter should be smaller than the former, because the mapper container consumes some memory itself. After setting mapreduce.map.java.opts = mapreduce.map.memory.mb * 0.8, the OOM problem is gone. I note that this also applies for the reducer, which has two corresponding parameters (mapreduce.reduce.java.opts and mapreduce.reduce.memory.mb). This <a href="https://discuss.pivotal.io/hc/en-us/articles/201462036-MapReduce-YARN-Memory-Parameters" target="_blank" rel="noopener">article</a> explains nicely.</p><p>The second OOM issue is much harder to address, which comes with the shuffle phase. I saw error logs like following</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">2017-06-21 20:22:42.294 STDIO [ERROR] [WORKER] [100] Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)</span><br><span class="line">    at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)</span><br><span class="line">    at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)</span><br><span class="line">    at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">    at javax.security.auth.Subject.doAs(Subject.java:415)</span><br><span class="line">    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)</span><br><span class="line">    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)</span><br><span class="line">Caused by: java.lang.OutOfMemoryError: Java heap space</span><br><span class="line">    at org.apache.hadoop.io.BoundedByteArrayOutputStream.&lt;init&gt;(BoundedByteArrayOutputStream.java:56)</span><br><span class="line">    at org.apache.hadoop.io.BoundedByteArrayOutputStream.&lt;init&gt;(BoundedByteArrayOutputStream.java:46)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.&lt;init&gt;(InMemoryMapOutput.java:63)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.unconditionalReserve(MergeManagerImpl.java:309)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.reserve(MergeManagerImpl.java:299)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:514)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:336)</span><br><span class="line">    at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)</span><br></pre></td></tr></table></figure><p>This is not an old problem which could be found in <a href="https://issues.apache.org/jira/browse/MAPREDUCE-6447" target="_blank" rel="noopener">here</a> and <a href="https://issues.apache.org/jira/browse/MAPREDUCE-6108" target="_blank" rel="noopener">here</a>. Most of the solutions suggest tuning the three parameters:</p><ul><li>mapreduce.reduce.shuffle.input.buffer.percent (default 0.7): how much memory shuffle can use to store data pulled from mappers for in-memory sort.</li><li>mapreduce.reduce.shuffle.memory.limit.percent (default 0.25): how much memory each shuffle thread uses for pulling data from mappers into memory. </li><li>mapreduce.reduce.shuffle.parallelcopies (default 10): the number of shuffle thread can run in parallel</li></ul><p>Some solutions claims that we should have </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mapreduce.reduce.shuffle.input.buffer.percent * mapreduce.reduce.shuffle.memory.limit.percent * mapreduce.reduce.shuffle.parallelcopies &lt; 1</span><br></pre></td></tr></table></figure><p>which is actually not correct. MergeManager allocates memory to shuffle threads which is used for copying mapper output into memory. Each time a shuffle thread applies for a copy action, the MergeManager determines if the application is granted by checking (1) if the appliedMemory size is more than the max memory each shuffle thread can have. This is controlled by mapreduce.reduce.shuffle.input.buffer.percent * mapreduce.reduce.shuffle.memory.limit.percent. Suppose the reducer JVM has 3.5G heap size, each shuffle can apply no more than 3500*0.7*0.25=612M with default settings. (2) if the usedMemory is more than memoryLimit. The used memory accounts for memory used by shuffles and in-memory merge. The memory limit is calculated by 3.5*0.7 = 2.45G with 3.5G JVM heap size. Now, if the usedMemory is 2.44G and appliedMemory is 612M, the real memory used by shuffle could be more than 3G !!! </p><p>This is not a bug, since there is a detailed comments in MergeManagerImpl.reserve. The comments explain why the actually used memory could be one shuffle larger than the limit. From the other side, this could cause OOM. Due to this issue, there’s no 100% safe way to fix the OOM by tuning the parameters. We can only mitigate this problem by reducing mapreduce.reduce.shuffle.input.buffer.percent and/or mapreduce.reduce.shuffle.memory.limit.percent. One should carefully calculate these parameters according to the real workload. Especially, the memory each shuffle can use limit the max size of output from each mapper. For example, if the mapper produces a 300M intermediate file, the shuffle should be able to allocate memory more than 300M. Otherwise, all sort will be done on disk. </p><p>One more thing is about the parquet format. It is a highly compressed format, and therefore the decompressed mapper output is much larger than the input split size. I think this is why OOM happens more frequently for parquet files than other file formats.</p>]]></content>
    
    <summary type="html">
    
      I recently experienced two OOM problems running a mapreduce application. The MR application reads from a group of parquet files, shuffles the input rows, and writes into parquet files, too. 
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="Mapreduce" scheme="liqul.github.io/blog/tags/Mapreduce/"/>
    
      <category term="OOM" scheme="liqul.github.io/blog/tags/OOM/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the SSD</title>
    <link href="liqul.github.io/blog/ssd/"/>
    <id>liqul.github.io/blog/ssd/</id>
    <published>2017-12-07T12:47:09.000Z</published>
    <updated>2018-04-12T13:37:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>Reading the chapter 13.5 “Arranging data on disk” in the book “DATABASE SYSTEM: IMPLEMENTATION” makes me think of a question: How data should be arranged on a SSD (Solid-State Drive)? This is indeed an old question, so after doing some research with Google, I find some very good explanations. </p><p><a href="http://site.aleratec.com/blog/2011/09/22/overview-pages-blocks-ftls-solidstate-drive-ssd/" target="_blank" rel="noopener">An Overview of Pages, Blocks and FTLs in a Solid-State Drive (SSD)</a></p><p><a href="https://www.extremetech.com/extreme/210492-extremetech-explains-how-do-ssds-work" target="_blank" rel="noopener">How Do SSDs Work?</a></p><a id="more"></a><p>The two articles above describes how SSD works differently from a HDD. Some key points to take away are:</p><ul><li>The minimum read/write unit for a SSD is a <em>page</em>. A <em>block</em> is made up of a set of pages.</li><li>A dirty page (with data) can <em>not</em> be overwritten before being erased.</li><li>The minimum erase unit for a SSD is a <em>block</em>.</li><li>Each block has a finite program/erase cycles (P/E cycles).</li></ul><p>Within a SSD, data can only be erased by block. <em>Garbage collection</em> need to run to reclaim logically deleted pages (e.g., due to update). Therefore, data in blocks with deleted pages are packed and rewrite to another empty block. A piece of data might be rewritten over and over again, which is called the <em>write amplification</em> problem. This also leads to the fact that data is moving constantly which is quite different from data stored within a HDD.</p><p><a href="https://blog.2ndquadrant.com/tables-and-indexes-vs-hdd-and-ssd/" target="_blank" rel="noopener">Tables and indexes vs. HDD and SSD</a></p><p>This article above discussed about the strategy of storing table data and indexes on HDD vs. SSD. The results are clearly shown by those charts. Also, the discussion in the comments is worthwhile for reading. </p><p><a href="http://codecapsule.com/2014/02/12/coding-for-ssds-part-1-introduction-and-table-of-contents/" target="_blank" rel="noopener">Coding for SSDs</a></p><p>Finally, I found a very interesting serial of blogs “Coding for SSDs”. The author built a key-value store optimized for SSDs. There are quite a lot of insights in these blogs. </p><p>In conclusion, SSDs outperform HDDs from almost every aspects today, except the price per bit. However, I envision that in the near future, the price could be made low enough to replace most HDDs. SSDs are almost drop-in replacement for HDDs. However, to get the best performance from SSDs, developers do need to take care about the data access characteristics of SSDs.</p>]]></content>
    
    <summary type="html">
    
      Understanding the characteristics of SSD.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="ssd" scheme="liqul.github.io/blog/tags/ssd/"/>
    
  </entry>
  
  <entry>
    <title>读《洪业：清朝开国史》有感</title>
    <link href="liqul.github.io/blog/ming_lessons/"/>
    <id>liqul.github.io/blog/ming_lessons/</id>
    <published>2017-10-28T12:47:09.000Z</published>
    <updated>2018-04-12T13:39:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>读<a href="https://www.amazon.cn/%E6%B4%AA%E4%B8%9A-%E6%B8%85%E6%9C%9D%E5%BC%80%E5%9B%BD%E5%8F%B2-%E9%AD%8F%E6%96%90%E5%BE%B7/dp/B06XFTC5TJ/ref=sr_1_1?ie=UTF8&amp;qid=1509194106&amp;sr=8-1&amp;keywords=%E6%B4%AA%E4%B8%9A" target="_blank" rel="noopener">《洪业：清朝开国史》</a>关于崇祯的一些感受。</p><a id="more"></a><h2><span id="魏忠贤问题">魏忠贤问题</span></h2><ul><li>上策：保持互相制衡，两方敲打，改革弊政</li><li>中策：无所作为</li><li>下策：杀魏忠贤导致文臣势力过大</li></ul><h2><span id="皇太极的问题">皇太极的问题</span></h2><ul><li>上策：联络岱善，内部瓦解后金统治阶级</li><li>中策：同意与皇太极议和，攘外必先安内，剿灭李自成</li><li>下策：同时面对两股敌人</li></ul><h2><span id="用人的问题">用人的问题</span></h2><ul><li>上策：黑猫白猫，不在意细节，以能力取人</li><li>中策：坚持用人时间长一点，不随意更替</li><li>下策：动辄得咎，反复无情，换人如流水</li></ul><h2><span id="自杀的问题">自杀的问题</span></h2><ul><li>上策：未知</li><li>中策：南下或北上。南下学宋高宗，虽末世无法与南宋比肩，但仍有一战的实力；北上联系后金，一同剿灭李自成，有崇祯在后金不那么容易南侵，何况还有吴三桂</li><li>下策：自杀身死，连太子也没有放过</li></ul>]]></content>
    
    <summary type="html">
    
      读《洪业：清朝开国史》有感。
    
    </summary>
    
      <category term="Book Reading" scheme="liqul.github.io/blog/categories/Book-Reading/"/>
    
    
      <category term="洪业" scheme="liqul.github.io/blog/tags/%E6%B4%AA%E4%B8%9A/"/>
    
  </entry>
  
  <entry>
    <title>Quorum in Amazon Aurora</title>
    <link href="liqul.github.io/blog/quorum_in_amazon_aurora/"/>
    <id>liqul.github.io/blog/quorum_in_amazon_aurora/</id>
    <published>2017-10-27T08:12:09.000Z</published>
    <updated>2018-04-12T13:39:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>I recently read a serial of posts about the quorum mechanism in Amazon Aurora, which is a distributed relational database. These posts are: </p><ul><li><a href="/blog/assets/Amazon Aurora under the hood_ quorums and correlated failure _ AWS Database Blog.pdf">post1</a>: quorums and correlated failure.</li><li><a href="/blog/assets/Amazon Aurora Under the Hood_ Quorum Reads and Mutating State _ AWS Database Blog.pdf">post2</a>: quorum reads and mutating state.</li><li><a href="/blog/assets/Amazon Aurora Under the Hood_ Reducing Costs Using Quorum Sets _ AWS Database Blog.pdf">post3</a>: reducing costs using quorum sets.</li><li><a href="/blog/assets/Amazon Aurora Under the Hood_ Quorum Membership _ AWS Database Blog.pdf">post4</a>: quorum membership.<a id="more"></a></li></ul><p>Besides, there is actually a Sigmod’17 paper about Amazon Aurora which could be found <a href="http://www.allthingsdistributed.com/files/p1041-verbitski.pdf" target="_blank" rel="noopener">here</a>. I only briefly went through that paper which spends most of words talking about the basic architecture. </p><p>I like this serial of posts which is a very good tutorial if you want to learn practical usage of quorum. By definition, a quorum model is </p><blockquote><p>Formally, a quorum system that employs V copies must obey two rules. First, the read set, Vr, and the write set, Vw, must overlap on at least one copy.</p></blockquote><blockquote><p>Second, you need to ensure that the quorum used for a write overlaps with prior write quorums, which is easily done by ensuring that Vw &gt; V/2. </p></blockquote><p>At the heart of this model is that each read/write to the cluster of nodes overlaps at least one node with each other. </p><p>While it is cool to enjoy the replication benefit with the quorum model, there comes cost for both read and write. For read, a client may need to consult multiple nodes (i.e., the read set) in order to ensure reading the latest state. For write, the multiple copies need to be materialized in order to maintain the quorum model. The author introduced the basic ideas of solving these two problems in post2 and post3. Especially, for the read penalty, the master maintains a cache of the status of all successful replicas, including their latency estimations. Therefore, a client need only to find information from the master in order to read the latest information. </p><p>Membership management is discussed in post4 where they use the approach of overlapping quorums to solve the node failure problem. One nice feature is that this approach is robust given new failures happening right during the handling process. </p><p>Finally, I’d like to end up with the following sentence from the posts:</p><blockquote><p>State is often considered a dirty word in distributed systems—it is hard to manage and coordinate consistent state as you scale nodes and encounters faults. Of course, the entire purpose of database systems is to manage state, providing atomicity, consistency, isolation, and durability (ACID).</p></blockquote>]]></content>
    
    <summary type="html">
    
      Notes on the quorum mechanism in Amazon Aurora.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="quorum" scheme="liqul.github.io/blog/tags/quorum/"/>
    
      <category term="amazon aurora" scheme="liqul.github.io/blog/tags/amazon-aurora/"/>
    
  </entry>
  
  <entry>
    <title>Reading the New Apache HBase MOB Compaction Policy</title>
    <link href="liqul.github.io/blog/new_apache_hbase_mob_compaction_policy/"/>
    <id>liqul.github.io/blog/new_apache_hbase_mob_compaction_policy/</id>
    <published>2017-08-29T02:19:09.000Z</published>
    <updated>2018-04-12T13:40:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>In case you want to understand more on MOB (Moderate Object Storage), you may refer to this <a href="https://issues.apache.org/jira/browse/HBASE-11339" target="_blank" rel="noopener">issue</a>. Basically, hbase was first introduced with capability of storing mainly small objects (&lt;100k). Moderate objects stand for files from 100k to 10m. </p><p>Recently, there is a <a href="https://blog.cloudera.com/blog/2017/06/introducing-apache-hbase-medium-object-storage-mob-compaction-partition-policies/?elqTrackId=2a7ed08f6935464e84b51ad5a8f15cb2&amp;elq=896612af50b741d7b8bf576ac30276e4&amp;elqaid=4662&amp;elqat=1&amp;elqCampaignId=2850" target="_blank" rel="noopener">blog</a> introducing the new compaction policy for MOB files. The problem with the initial approach is multiple compaction. For instance, the goal is to compact the objects created in one calendar day into one big file. The compaction process starts after the first hour. The objects created in the first hour are compacted into a temporal file. Then, the objects created in the second hour, and the temporal file created for the first hour are compacted into a new temporal file…</p><a id="more"></a><p>In this way, finally, all objects created in one day is compacted into one file. However, the objects in the first hour is compacted quite a few of times, wasting IO. The new method is based on partition. For instance, we may compact the objects in each hour of day, which is the first stage. Then, the temporal files in each hour are compacted into the final file, which is the second stage. This saves a lot of IO in comparison with the initial approach. Actually, this improvement is quite straightforward. </p><p>What I found really insightful is about the compaction partitioned by the created time. Note that the creation time of each object is never changed during its life time. Therefore, suppose a set of objects is compacted into a big file which say contains objects between 2017-08-23 ~ 2017-08-24. After a while, some objects in that set may be deleted (with tombstone in hbase), or replaced with newer versioned metadata. However can we remove these objects physically? The answer is easy. We search for all objects created between 2017-08-23 ~ 2017-08-24, which should result in a subset of the original set of objects. We then extract the remain objects into a new big file, and delete the old big file. There are two other essential points to achieve the clear process described above: (1) the metadata should be 1:1 mapping with the objects. In other words, there should be no more than 1 metadata pointing to the same object. (2) the creation time and the pointer to file should be always updated atomically.</p>]]></content>
    
    <summary type="html">
    
      Notes on the new apache hbase mob compaction policy.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="hbase" scheme="liqul.github.io/blog/tags/hbase/"/>
    
      <category term="compaction" scheme="liqul.github.io/blog/tags/compaction/"/>
    
  </entry>
  
  <entry>
    <title>Understanding Chain Replication</title>
    <link href="liqul.github.io/blog/notes-chain-replication/"/>
    <id>liqul.github.io/blog/notes-chain-replication/</id>
    <published>2017-07-28T10:05:39.000Z</published>
    <updated>2018-04-12T13:40:43.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/blog/assets/chain_replication.svg" alt="Chain Replication"></p><p>I learned the idea of chain replication from <a href="https://github.com/hibari/hibari" target="_blank" rel="noopener">hibari</a>,</p><blockquote><p>Hibari is a production-ready, distributed, ordered key-value, big data store. Hibari uses chain replication for strong consistency, high-availability, and durability. Hibari has excellent performance especially for read and large value operations.</p></blockquote><a id="more"></a><p>The term “strong consistency” indeed caught my attention as I already know a few key-value storage services with only eventually consistency, e.g., openstack swift. I read its doc to find out the key tech sitting in the core is called “chain replication”. I did some investigation about this concept which actually back to very early days in 2004 in a OSDI <a href="http://www.cs.cornell.edu/home/rvr/papers/OSDI04.pdf" target="_blank" rel="noopener">paper</a>. </p><p>The idea is actually very easy to understand. The service maintains a set of chains. Each chain is a sequence of servers, where one server is called the <em>head</em>, and one is called the <em>tail</em>; all servers in between are <em>middle</em> servers. The figure in the very beginning shows such an example with two middle servers. Each write request is directed to the head server, and the update is pipelined from the head server to the tail server though the chain. Read requests are directed to only tail servers. What a client can read from the chain is definitely replicated across all servers belonging to the chain, and therefore, strong consistency is guaranteed. </p><p>Though the idea sounds straightforward, there are few practical issues. First of all, the traffic load at tail servers is higher than other servers, since they handle both write and read traffics. A load balancing aware chain organization algorithm is needed to balance the load across all servers. For instance, one server may be middle server of one chain and meanwhile tail server of another chain (see Fig. 3 in the <a href="http://www.snookles.com/scott/publications/erlang2010-slf.pdf" target="_blank" rel="noopener">Hibari paper</a>). Another problem is failure handling. There should be a way of detecting failed servers, which turns out to be non-trivial in such distributed world. There are also plenty of issues about recovering from failures, replication, and migration. In conclusion, this “simple” idea comes with a bunch of tough issues. </p><p>There are only few open source projects based on chain replication, such as <a href="https://github.com/hibari/hibari" target="_blank" rel="noopener">Hibari</a> and <a href="https://github.com/CorfuDB/CorfuDB" target="_blank" rel="noopener">CorfuDB</a>. One fundamental reason may be the cost paid for strong consistency is too high. One killer application for object storage is handling highly massive objects such as user data in social network companies. However, the chain can never cross data centers in order for low latency. The idea of using chained servers is not really new. HDFS also use a pipeline to optimize data transfer latency while achieving strong consistency. Therefore, if the number of files is not a issue, storing them directly on HDFS might be a reasonable choice, given the advantage of naive integration with other Hadoop components.</p>]]></content>
    
    <summary type="html">
    
      A brief understanding about chain replication.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="distributed" scheme="liqul.github.io/blog/tags/distributed/"/>
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="replication" scheme="liqul.github.io/blog/tags/replication/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习笔记</title>
    <link href="liqul.github.io/blog/notes-learning-spark/"/>
    <id>liqul.github.io/blog/notes-learning-spark/</id>
    <published>2017-07-07T11:19:09.000Z</published>
    <updated>2018-04-12T13:41:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="spark与scala">Spark与Scala</span></h2><p>在学习Spark之前务必对Scala有所理解，否则面对完全陌生的语法是很痛苦的。</p><p>Scala的一种入门方式是：</p><ol><li>学习<a href="https://www.coursera.org/learn/progfun1/home/welcome" target="_blank" rel="noopener">Scala 函数式程序设计原理</a>。这是Scala作者自己开的课程。没什么比语言作者更加能理解这门语言的了，是切入Scala编程的最好入门方式。课程习题参考了《计算机程序的构造和解释》一书，非常经典。</li><li>阅读《Scala in depth》一书，对一些Scala的重点概念有更加详细的讨论。</li><li>根据特定的topic，Google各种网络资料。</li></ol><a id="more"></a><h2><span id="rdd-resilient-distributed-datasets">RDD (Resilient Distributed Datasets)</span></h2><h3><span id="rdd的含义">RDD的含义</span></h3><p>RDD是spark中用于记录数据的数据结构。根据具体的RDD类型，数据有不同的组织形式。一个RDD包含多个partition，partition是并行的基本单位。RDD可能存在内存中，也可能存在硬盘里，或者两者皆有。一个RDD可以由数据源创建，也可能由其它RDD计算得到，所有参与计算RDD的RDD称为父RDD。若对mapreduce有所了解，可以把partition看作mapper的一个split。</p><h3><span id="rdd中的窄依赖narrow-dependency和宽依赖wide-dependency">RDD中的窄依赖（Narrow Dependency）和宽依赖（Wide Dependency）</span></h3><p>若一个RDD中每一条记录仅仅依赖父RDD中唯一一条记录，则其为窄依赖，否则为宽依赖。比如在map中，每一条子RDD中的记录就对应着唯一父RDD中的对应记录。而groupByKey这样的操作中，子RDD中的一条记录，我们并不知道它究竟来自哪个父RDD中的哪个partition。</p><p>利用mapreduce的概念来理解，一组连续的窄依赖操作可以用一个mapper来实现，而宽依赖操作则只能依赖reducer。正因如此，一组连续窄依赖中产生的“中间结果”（实际并不需要产生这些中间结果）是没有存在的意义的，只要知道输入、操作就能直接计算输出了。举个具体的例子：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resRDD = srcRDD.map(_ + <span class="number">1</span>).map(_ + <span class="number">2</span>).filter( _ % <span class="number">2</span> == <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>中的transformation链可以看作mapreduce下的一个mapper，一条记录从左到右执行不依赖其它记录。若把上面例子改为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resRDD = srcRDD.map(_ + <span class="number">1</span>).distinct().filter( _ % <span class="number">2</span> == <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>其中加入了distinct意味着一条记录从左到右无法利用一个mapper就完成，必须截断加入一个reducer。这里需要理解mapreduce中的一个mapper并不是等价于spark中的一个map操作，而是对应所有窄操作的组合，例如filter、flatMap、union等等。</p><blockquote><p>补充材料：<a href="https://martin.atlassian.net/wiki/pages/viewpage.action?pageId=67043332" target="_blank" rel="noopener">why spark’s mapPartitions transformation is faster than map</a>。其中的一句话讲的非常清楚——you probably know that “narrow” transformations/tasks happen independently on each of the partitions. 即窄操作在单机即可完成，不需要依赖保存在其它主机上的partition。</p></blockquote><h3><span id="rdd中persist和checkpoint的逻辑">RDD中persist和checkpoint的逻辑</span></h3><p>persist的目的是为了加快后续对该RDD的操作；checkpoint的目的是为了减少长执行链失败带来的开销。由于目的不同，如果persist的RDD丢失了，可以重新计算一遍（这就是普通cache的基本逻辑）。反过来，如果checkpoint丢失了，则无法重新计算，因为该checkpoint之前的内容都遗忘了。cache只是persist的一个子操作，其storage level为memory_only。</p><p>persist和checkpoint都是异步操作，执行persist或checkpoint命令仅仅给对应的RDD加上一个mark，后续交给block manager完成具体的物化操作（？？？）。persist有多种storage level，包括memory, off heap memory, disk等等。在spark中，block manager负责所有的数据存储管理，包括persist、checkpoint、或shuffle产生的中间数据等。</p><p>值得一提的是关于off heap memory的<a href="http://stackoverflow.com/questions/6091615/difference-between-on-heap-and-off-heap" target="_blank" rel="noopener">概念说明</a>。简而言之，off heap memory就是不受JVM管控的一块内存空间，由于不受管控所以不存在GC的开销；另一方面由于并非JVM native环境，所以并不能识别其中存储的Java对象这样的结构，需要序列化和反序列化来支持。off heap memory的典型应用场景则是缓存一些较大的静态数据。</p><h3><span id="重要的方法">重要的方法</span></h3><h4><span id="compute">compute</span></h4><p><strong>def compute(split: Partition, context: TaskContext): Iterator[T]</strong><br>根据给定的partition计算一个interator，可以遍历该partition下的所有记录。有意思的是partition的名字为split，与mapreduce下mapper的处理单位名字一样。</p><h3><span id="rdd中的基础transformation">RDD中的基础transformation</span></h3><h4><span id="map">map</span></h4><p><strong>def map[U: ClassTag](f: T =&gt; U): RDD[U]</strong><br>返回的RDD为MapPartitionsRDD类型，其compute方法会对其父RDD中的记录执行f映射。</p><h4><span id="mappartitions">mapPartitions</span></h4><p><strong>def mapPartitions[U: ClassTag](f: Iterator[T] =&gt; Iterator[U], preservesPartitioning: Boolean = false): RDD[U]</strong><br>与map的区别在于映射f的作用对象是整个partition，而不是一条partition中的记录。在一些初始化代价较高的场景下，mapPartition比map更加合理和高效。</p><blockquote><p>补充材料：<a href="https://martin.atlassian.net/wiki/pages/viewpage.action?pageId=67043332" target="_blank" rel="noopener">why spark’s mapPartitions transformation is faster than map</a>。</p></blockquote><h4><span id="flatmap">flatMap</span></h4><p><strong>def flatMap[U: ClassTag](f: T =&gt; TraversableOnce[U]): RDD[U]</strong><br>与map类似，仅仅将对iterator的map操作换成flatMap操作。这里f映射的输出类型为TraversableOnce，表示只要能完成单次遍历即可，可以是Traversable或Iterable。</p><h4><span id="filter">filter</span></h4><p><strong>def filter(f: T =&gt; Boolean): RDD[T]</strong><br>与map类似，仅仅将对iterator的map操作换作filter操作。</p><h4><span id="distinct">distinct</span></h4><p><strong>def distinct(numPartitions: Int)(implicit ord: Ordering[T] = null): RDD[T]</strong><br>首先这个方法存在一个implicit的参数ord，类型为scala.math.Ordering。Ordering中实现了各种基础类型（Int, Long, Double, String等）的比较方法，这意味着如果T是一种基础类型则无须实现自己的比较方法，只需要import scala.math.Ordering即可。</p><p>与前几种transformation最大的不同在于distinct依赖reduce，即它是一种宽依赖操作。其具体实现代码如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map(x =&gt; (x, <span class="literal">null</span>)).reduceByKey((x, y) =&gt; x, numPartitions).map(_._1)</span><br></pre></td></tr></table></figure><p>可见其首先将一条记录映射为一个pair，然后执行reduceByKey的操作。这里reduceByKey方法并非RDD所有，之所以可以调用是因为object RDD里定义了从RDD转换为PairRDDFunctions的implicit方法。这种针对特定情况下的RDD增加操作的抽象方式可以学习。reduceByKey中给出了合并两个value的方式，即把相同的key的alue合并为一个（在此为null），然后根据给定的numPartitions数量进行hash partition。最终结果通过map仅保留key即可。</p><p>与mapreduce一致，这里的合并会发生在本地和reducer处，类似mapreduce中的combiner。在调用reduceByKey后的调用逻辑为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reduceByKey((x, y) =&gt; x, numPartitions)</span><br><span class="line">combineByKeyWithClassTag(x=&gt;x, (x,y)=&gt;x, (x,y)=&gt;x, <span class="keyword">new</span> <span class="type">HashPartitioner</span>(numPartitions))</span><br></pre></td></tr></table></figure><p>在combineByKeyWithClassTag中会根据传入的三个映射分别创建createCombiner、mergeValue和mergeCombiner。其中，createCombiner用于产生合并的初始值；mergeValue用于合并两条记录；mergeCombiner用于将mergeValue得到的结果再次合并。上述三者组成一个Aggregator对象。</p><h4><span id="coalesce">coalesce</span></h4><p><strong>def coalesce(numPartitions: Int, shuffle: Boolean = false)(implicit ord: Ordering[T] = null) : RDD[T]</strong><br>连接的作用是重新整理原有的RDD。有两种情况：（1）若shuffle\=\=false，表示一种虚拟的RDD分区变化，此时numPartitions应该比原来的少，否则无意义。注意此时是不会发生真实的IO的；（2）若shuffle\=\=true，表示要做一次真实的shuffle，即会带有真实的数据IO。对于第二种情况，在coalesce方法内部会做一次随机的mapping操作，把每个元素与结果RDD中的partition做一次mapping。在第二种情况下，numPartitions可以比父RDD的分区数量更多。</p><p>虽然前一种情况只是虚拟的分区变化，但究竟把哪些父partition分入同一个子partition是可以考虑locality因素的，CoalescedRDD的balanceSlack参数用来控制locality在分配父partition时起的权重。</p><p>看代码中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// include a shuffle step so that our upstream tasks are still distributed</span><br><span class="line">      new CoalescedRDD(</span><br><span class="line">        new ShuffledRDD[Int, T, T](mapPartitionsWithIndex(distributePartition),</span><br><span class="line">        new HashPartitioner(numPartitions)),</span><br><span class="line">        numPartitions).values</span><br></pre></td></tr></table></figure></p><p>这段话比较难懂，而实际上是做了几件事：首先，在ShuffledRDD中根据随机生成的key将父RDD各partiton中的数据分散到子RDD的各partiton中；然后，隐式转换为PairRDDFunctions的values方法转换成普通的RDD。</p><h4><span id="sample">sample</span></h4><p><strong>def sample(withReplacement: Boolean, fraction: Double, seed: Long = Utils.random.nextLong): RDD[T] = withScope</strong><br>对当前RDD的每个partition进行一次sample。withReplacement用于控制是否可出现重复sample，fraction控制sample的比例，seed即随机种子。</p><h4><span id="randomsplit">randomSplit</span></h4><p><strong>def randomSplit(weights: Array[Double], seed: Long = Utils.random.nextLong): Array[RDD[T]]</strong><br>给定一组weights，例如Array(2.0,3.0,5.0)，将父RDD按这样的比例划分，得到一个子RDD数组。<br>示例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val rdd = sc.makeRDD(1 to 10,10)</span><br><span class="line">rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at makeRDD at &lt;console&gt;:27</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.collect</span><br><span class="line">res1: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) </span><br><span class="line"></span><br><span class="line">scala&gt; val randomSplittedRDD = rdd.randomSplit(Array(2.0, 3.0, 5.0))</span><br><span class="line">randomSplittedRDD: Array[org.apache.spark.rdd.RDD[Int]] = Array(MapPartitionsRDD[12] at randomSplit at &lt;console&gt;:29, MapPartitionsRDD[13] at randomSplit at &lt;console&gt;:29, MapPartitionsRDD[14] at randomSplit at &lt;console&gt;:29)</span><br><span class="line"></span><br><span class="line">scala&gt; randomSplittedRDD.foreach(x =&gt; println(x.collect.mkString(&quot; &quot;)))</span><br><span class="line">9 10</span><br><span class="line">2 4 8</span><br><span class="line">1 3 5 6 7</span><br></pre></td></tr></table></figure></p><p>其内部实现实际上是利用了BernoulliCellSampler完成的，每次把父RDD的某个partition做一次sample得到一个子partition，通过一个MapPartitionsRDD实现从父RDD到子RDD的映射。但由于产生的是一组子RDD，因此每多一个子RDD就需要把父RDD做一次sample。由于每次调用时random seed是在内部保持不变的，所以即使多次sample，也不会导致某个元素被分到不同的子RDD里去。这一点是开始一直想不通的，因为我一直以为只需要sample一遍就能完成整个过程。</p><h4><span id="takesample">takeSample</span></h4><p><strong>def takeSample(withReplacement: Boolean, num: Int, seed: Long = Utils.random.nextLong): Array[T]</strong><br>返回指定数量的sample。</p><h4><span id="union同">union（同++）</span></h4><p><strong>def union(other: RDD[T]): RDD[T]</strong><br>获取两个RDD的并集，若一个元素出现多次，并不会通过union操作去重，因此union本身属于窄依赖。根据partitioner的情况，分两种情况处理：（1）如果两个RDD的partitioner都定义了且相同，那两RDD的partition数量一样，得到的并集RDD也有相同数量的partition。在考虑locality时，会按照多数原则处理，即如果大多数属于某个并集partition的父partition都倾向某个locality选择，那么就以此多数为准；（2）如果不满足（1）的情况，则并集RDD的partition数量为两父RDD的数量之和，即简单的合并关系。</p><h4><span id="keyby">keyBy</span></h4><p><strong>def keyBy[K](f: T =&gt; K): RDD[(K, T)]</strong><br>根据映射f抽取原RDD中每条记录的key，使结果RDD中每条记录为一个kv二元组。</p><h4><span id="sortby">sortBy</span></h4><p><strong>def sortBy[K](f: (T) =&gt; K, ascending: Boolean = true, numPartitions: Int = this.partitions.length)(implicit ord: Ordering[K], ctag: ClassTag[K]): RDD[T]</strong><br>对RDD排序，key由映射f抽取。这个方法的实现比较有趣，如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">this.keyBy[K](f)  //生成一个基于kv二元组的RDD</span><br><span class="line">        .sortByKey(ascending, numPartitions)  //sortByKey是OrderedRDDFunctions中的方法，由隐式转换rddToOrderedRDDFunctions支持</span><br><span class="line">        .values //排好序的RDD再退化由原来的元素组成，也是隐式转换支持</span><br></pre></td></tr></table></figure></p><p>实现过程经过两次隐式转换，非常有scala的特色，这种隐式转换往往发生在特殊的RDD之上。排序的具体过程参考Shuffle一节。</p><h4><span id="intersection">intersection</span></h4><p><strong>def intersection(other: RDD[T]): RDD[T]</strong><br>计算两个父RDD的交集，得到子RDD，交集元素无重复。实现如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">this.map(v =&gt; (v, null)).cogroup(other.map(v =&gt; (v, null))) //map成kv二元组后，隐式转换PairRDDFunctions调用其cogroup方法得到(k, (v1, v2))的结构</span><br><span class="line">        .filter &#123; case (_, (leftGroup, rightGroup)) =&gt; leftGroup.nonEmpty &amp;&amp; rightGroup.nonEmpty &#125;  //把两边都不是空的情况筛选出来</span><br><span class="line">        .keys //退化为普通的RDD</span><br></pre></td></tr></table></figure></p><p>其中cogroup依赖shuffle，所以是宽依赖操作。intersection操作还有一些重载，但基本实现是相同的。</p><h4><span id="glom">glom</span></h4><p><strong>def glom(): RDD[Array[T]]</strong><br>将原来的RDD变成新的RDD，其原有的每个partition变成一个数组。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val a = sc.parallelize(1 to 9, 3)</span><br><span class="line"></span><br><span class="line">scala&gt; a.glom.collect</span><br><span class="line">res66: Array[Array[Int]] = Array(Array(1, 2, 3), Array(4, 5, 6), Array(7, 8, 9))</span><br></pre></td></tr></table></figure></p><p>这篇<a href="http://blog.madhukaraphatak.com/glom-in-spark/" target="_blank" rel="noopener">文章</a>把glom的作用讲的非常清楚。其中的例1和例2都是在处理一个数组要比挨个处理每个元素好很多的时候。当然，这消耗的内存要更大（<strong>TODO</strong>: 具体使用情况如何？是否会导致OOM？），是一个折衷。</p><h4><span id="cartesian">cartesian</span></h4><p><strong>def cartesian[U: ClassTag](other: RDD[U]): RDD[(T, U)]</strong><br>生成当前RDD与另一个RDD的笛卡尔积，即列举所有a in this和b in other而组成的(a,b)的集合。生成的新RDD的partition数量等于原两个RDD各自的partition数量的乘积。</p><h4><span id="groupby">groupBy</span></h4><p><strong>def groupBy[K](f: T =&gt; K, p: Partitioner)(implicit kt: ClassTag[K], ord: Ordering[K] = null) : RDD[(K, Iterable[T])]</strong><br>将当前RDD中的元素按f映射的key做group操作，结果RDD可根据传入的partitioner来进行分区。源代码中有如下注释：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">* Note: This operation may be very expensive. If you are grouping in order to perform an</span><br><span class="line">* aggregation (such as a sum or average) over each key, using [[PairRDDFunctions.aggregateByKey]]</span><br><span class="line">* or [[PairRDDFunctions.reduceByKey]] will provide much better performance.</span><br><span class="line">*</span><br><span class="line">* Note: As currently implemented, groupByKey must be able to hold all the key-value pairs for any</span><br><span class="line">* key in memory. If a key has too many values, it can result in an [[OutOfMemoryError]].</span><br></pre></td></tr></table></figure></p><p>其中指出当前实现中一个key的所有value会需要保存在内存中，从而可能导致OOM，这可能是combine的过程中必须将所有value保存在内存中有关（推测）。另外，聚合或reduce可以解决大部分问题，而不需要groupBy，依此推测这个操作仅用于一些value较少又不得不获取这个中间结果的场景。</p><p>这篇<a href="https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/best_practices/prefer_reducebykey_over_groupbykey.html" target="_blank" rel="noopener">文章</a>很好的讲述了groupBy引入的内存问题的原因。</p><h4><span id="pipe">pipe</span></h4><p><strong>def pipe(command: String): RDD[String]</strong><br>pipe类似于mapreduce中的streaming，即能通过stdin来把数据发往外部进程，在通过stdout把结果读回来。这篇<a href="http://blog.madhukaraphatak.com/pipe-in-spark/" target="_blank" rel="noopener">文章</a>讲的非常清楚。但是这似乎只是map的过程，并不能包括reduce。</p><p>其内部实现实际上就是把参数中包含的command启动一个进程，然后通过stdin/out来完成上述算子操作过程。</p><h4><span id="zip">zip</span></h4><p><strong>def zip[U: ClassTag](other: RDD[U]): RDD[(T, U)]</strong><br>将当前RDD与other组合成一个新的包含二元组的RDD，要求两个RDD包含相同数量的partition，且每对partition包含相同数量的元素。</p><h4><span id="zippartitions">zipPartitions</span></h4><p><strong>def zipPartitions[B: ClassTag, V: ClassTag](rdd2: RDD[B], preservesPartitioning: Boolean)(f: (Iterator[T], Iterator[B]) =&gt; Iterator[V]): RDD[V]</strong><br>与zip的关系类似map与mapPartitions的关系，但又不完全一样。zip要求对应的partition里包含的元素数量也完全一样，但这里f映射并不需要两个partiton里元素数量相同。但显然可以利用zipPartitions来实现zip的功能，且与zip比较起来应该有更好的效率。</p><h4><span id="subtract">subtract</span></h4><p><strong>def subtract(other: RDD[T], p: Partitioner)(implicit ord: Ordering[T] = null): RDD[T]</strong><br>得到在当前RDD中且不在other中的元素组成的RDD，由于需要按元素做key，属于宽依赖。</p><h4><span id="dataframerepartion-vs-dataframewriterpartitionby">DataFrame.repartion vs. DataFrameWriter.partitionBy</span></h4><p><strong>def repartition(numPartitions: Int, partitionExprs: Column*): DataFrame</strong><br><strong>def partitionBy(colNames: String*): DataFrameWriter</strong><br>这里的<a href="https://stackoverflow.com/questions/40416357/spark-sql-difference-between-df-repartition-and-dataframewriter-partitionby" target="_blank" rel="noopener">讨论</a>非常清楚。repartition的参数是numPartitions和partitionExprs，partitionExprs将指定的列做hash后对numPartitions求模，得到对应的partition的index。这样得到的最终分区数量是numPartitions，但实际上如果numPartitons大于分组数量，可能有一些partition是空的；反之，如果numPartitions小于分组数量，有一些partiton里包含多个分组。partitionBy是把每个partition按照指定的列拆分为一到多个文件。</p><p>一个应用实力：如果希望输出的文件里，每个文件有且仅有一个分组，那么就可以dataframe.repartiton(n, columns).write.partitionBy(columns).csv(xxx)。其中n可以控制并发的数量，跟实际的数据分布有关。</p><h4><span id="zipwithuniqueid">zipWithUniqueId</span></h4><p><strong>def zipWithUniqueId(): RDD[(T, Long)]</strong><br>为了解决zipWithIndex带来的性能问题，这里放松了条件，只要求id是唯一的。zipWithUniqueId只是个算子，第k个partition的元素对应的id分别为k, k+n, k+2n, …，这里的n是partition的数量。</p><h3><span id="rdd中的actions">RDD中的actions</span></h3><h4><span id="foreach">foreach</span></h4><p><strong>def foreach(f: T =&gt; Unit): Unit</strong><br>将映射f应用到每个元素上。</p><h4><span id="foreachpartition">foreachPartition</span></h4><p><strong>def foreachPartition(f: Iterator[T] =&gt; Unit): Unit</strong><br>将映射f应用到每个partition上。</p><h4><span id="collect">collect</span></h4><p><strong>def collect(): Array[T]</strong><br>将RDD中所有元素作为一个数组返回。<strong>注意不要将collect作用于一个过大的RDD，否则会抛出内存异常，可先利用take和takeSample只取一个子集</strong>。</p><h4><span id="reduce">reduce</span></h4><p><strong>def reduce(f: (T, T) =&gt; T): T</strong><br>执行映射f对应的reduce操作。其操作基本步骤是：（1）每个partition执行f映射对应的reduce过程；（2）在driver的host机器上执行基于f映射的reduce过程，输入来自各个partition的输出。步骤（2）的复杂度与partition的数量呈线性增加。</p><h4><span id="treereduce">treeReduce</span></h4><p><strong>def treeReduce(f: (T, T) =&gt; T, depth: Int = 2): T</strong><br>为了改进reduce里步骤（2）的瓶颈问题，对各partition的输出先逐层聚合，最后再到driver处生成最终结果，类似一棵树的聚合过程。在<a href="https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/treereduce_and_treeaggregate_demystified.html" target="_blank" rel="noopener">文章</a>里有详细的描述。reduce和treeReduce的关系类似aggregate和treeAggregate的关系。</p><h4><span id="fold">fold</span></h4><p><strong>def fold(zeroValue: T)(op: (T, T) =&gt; T): T</strong><br>将映射op应用到每对元素上面。在实现过程中，spark不限定元素之间的执行顺序，实际上是先在partition内部做，然后再在partition之间，所以不能保证一个预先设定好的顺序来执行。因此，fold算子适用于那种不需要考虑左右操作元素的顺序，例如max。</p><h4><span id="aggregate">aggregate</span></h4><p><strong>def aggregate<a href="zeroValue: U" target="_blank" rel="noopener">U: ClassTag\</a>(seqOp: (U, T) =&gt; U, combOp: (U, U) =&gt; U): U</strong><br>与fold的不同在于aggregate可以返回一个新的类型U，而不是原来的类型Ｔ。从定义的角度，fold是aggregate的一种特例。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val a = sc.parallelize(1 to 9, 3)</span><br><span class="line">scala&gt; a.fold(0)&#123; _ + _ &#125;</span><br><span class="line">res0: Int = 45</span><br><span class="line"></span><br><span class="line">scala&gt; a.aggregate(0) ( _ + _, _ + _ )</span><br><span class="line">res1: Int = 45</span><br></pre></td></tr></table></figure><h4><span id="treeaggregate">treeAggregate</span></h4><p><strong>def treeAggregate<a href="zeroValue: U" target="_blank" rel="noopener">U: ClassTag</a>(seqOp: (U, T) =&gt; U, combOp: (U, U) =&gt; U, depth: Int = 2): U</strong><br>aggregate与treeAggregate和reduce与treeReduce的关系类似。</p><h4><span id="count">count</span></h4><p><strong>def count(): Long</strong><br>计算整个RDD中元素的个数。</p><h4><span id="countapprox">countApprox</span></h4><p><strong>countApprox(timeout: Long, confidence: Double = 0.95): PartialResult[BoundedDouble]</strong></p><p>在给定timeout期限的情况下，返回RDD中元素个数的估计。其中confidence是认为评估结果符合高斯分布的假设条件下估算的置信度，而<strong>不是结果的可信度</strong>。其核心代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">override def currentResult(): BoundedDouble = &#123;</span><br><span class="line">    if (outputsMerged == totalOutputs) &#123;</span><br><span class="line">      new BoundedDouble(sum, 1.0, sum, sum)</span><br><span class="line">    &#125; else if (outputsMerged == 0) &#123;</span><br><span class="line">      new BoundedDouble(0, 0.0, Double.NegativeInfinity, Double.PositiveInfinity)</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      val p = outputsMerged.toDouble / totalOutputs</span><br><span class="line">      val mean = (sum + 1 - p) / p</span><br><span class="line">      val variance = (sum + 1) * (1 - p) / (p * p)</span><br><span class="line">      val stdev = math.sqrt(variance)</span><br><span class="line">      val confFactor = new NormalDistribution().</span><br><span class="line">        inverseCumulativeProbability(1 - (1 - confidence) / 2)</span><br><span class="line">      val low = mean - confFactor * stdev</span><br><span class="line">      val high = mean + confFactor * stdev</span><br><span class="line">      new BoundedDouble(mean, confidence, low, high)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>其中totalOutputs是partition的个数。上面代码的逻辑是：如果已经计算了所有partition，则返回的结果是100%准确的；如果一个partition都未完成，那么结果完全不可信；否则，按比例计算mean，variance跟已返回比例有关，越多则variance越小，其low/high都是根据confidence和mean算出来的。</p><h4><span id="countbyvalue">countByValue</span></h4><p><strong>def countByValue()(implicit ord: Ordering[T] = null): Map[T, Long]</strong><br>实际上就是一个map + reduce的过程，而所得结果因为需要转化为Map，需要把所得内容完全载入driver的内存，所以只适合不同的value的数量比较小的情况。</p><h4><span id="countbyvalueapprox">countByValueApprox</span></h4><p><strong>def countByValueApprox(timeout: Long, confidence: Double = 0.95)(implicit ord: Ordering[T] = null) : PartialResult[Map[T, BoundedDouble]]</strong><br>与前面提到的countApprox实现类似。</p><h4><span id="zipwithindex">zipWithIndex</span></h4><p><strong>def zipWithIndex(): RDD[(T, Long)]</strong><br>获得一个新的RDD，其中每个元素都是一个二元组，其中value是元素所在RDD中的全局index。该操作不保证重复时index的顺序不变。这个操作表面上是一个算子，但实际上会触发一个spark job，因为在执行之前需要知道每个partition的起始index，而这只能通过count每个partition来得到。</p><h4><span id="take">take</span></h4><p><strong>def take(num: Int): Array[T]</strong><br>take的作用是从一个RDD中获取给定数量num个数的元素，得到一个数组。实现的基本思路是，首先尝试读一个partition，然后根据得到的元素数量与num的比较决定是否需要再探索其它的partition，以及探索的partition数量。这个探索数量的策略似乎比较heuristic，大体上是每次探索的partition数量小于等于已探索的4倍，而具体的值跟已探索到的元素数量与num的关系来定。从实现上看，take返回的所有元素都保存在一个数组内，所以如果num数量过大会引起内存问题。</p><h4><span id="takeordered">takeOrdered</span></h4><p><strong>def takeOrdered(num: Int)(implicit ord: Ordering[T]): Array[T]</strong><br>takeOrdered除了获取num个元素外，还要求这些元素按照ord给出的排序方式排序。其实现的核心代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">val mapRDDs = mapPartitions &#123; items =&gt;</span><br><span class="line">        // Priority keeps the largest elements, so let&apos;s reverse the ordering.</span><br><span class="line">        val queue = new BoundedPriorityQueue[T](num)(ord.reverse)</span><br><span class="line">        queue ++= util.collection.Utils.takeOrdered(items, num)(ord)</span><br><span class="line">        Iterator.single(queue)</span><br><span class="line">      &#125;</span><br><span class="line">      if (mapRDDs.partitions.length == 0) &#123;</span><br><span class="line">        Array.empty</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">        mapRDDs.reduce &#123; (queue1, queue2) =&gt;</span><br><span class="line">          queue1 ++= queue2</span><br><span class="line">          queue1</span><br><span class="line">        &#125;.toArray.sorted(ord)</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><p>首先，对每个partition需要得到一个BoundedPriorityQueue，其大小固定为num。若partition内元素少于num个，则queue不满。随后，在一个reduce中，把每个partition得到的queue拼接为一个queue。BoundedPriorityQueue的拼接会按照每个元素插入队列。根据这个实现，每次takeOrdered或top操作都需要对所有partition排序，然后在结果里拼出一个大小为num的队列，代价是比较大的。</p><h3><span id="常见的rdd派生类">常见的RDD派生类</span></h3><h2><span id="spark-architecture">Spark Architecture</span></h2><blockquote><p><a href="http://datastrophic.io/core-concepts-architecture-and-internals-of-apache-spark/" target="_blank" rel="noopener">http://datastrophic.io/core-concepts-architecture-and-internals-of-apache-spark/</a></p></blockquote><h2><span id="shuffle">Shuffle</span></h2><p>Shuffle的目的是把key相同的记录发送到相同的parition以供后续处理。Mapreduce中同样存在shuffle阶段。回顾mapreduce中shuffle的过程：（1）mapper将数据分为多个partition，然后parition内按照key排序（实际分两步完成），这些partition一部分写入磁盘，一部分缓存在内存里；（2）mapper输出的partition分发到对应的reducer；（3）reducer对已经排好续的记录再次进行合并排序；（4）key相同的记录被group为一个iterable交给reduce方法处理。</p><blockquote><p>补充材料：《Hadoop: The Definitive Guide》英文版，197页</p></blockquote><h3><span id="shuffle的两种方法">Shuffle的两种方法</span></h3><p>Spark中shuffle“目前”有两种实现，分别是基于hash和sort。</p><p>基于hash的方式在spark 1.2.0以前是默认的方式。其实现思路非常简单，对于任意输入RDD中的partition，根据hash结果产生N个文件。N表示“reducer”的数量。由于没有排序，每条记录经过hash后直接写入文件，因此速度较快。对于后续处理不需要排序的情况，基于hash的shuffle性能较好。其缺陷是产生的文件数量较大。</p><p>基于sort的方式达到的效果与mapreduce里的shuffle一样，但实现上有较大的差异。首先，从“mapper”写出的数据是不做本地排序的，只有在“reducer”从远端获取数据时才会触发排序过程。这里需要了解spark中的AppendOnlyMap的数据结构。简单来说，在数据量足够小的情况下，“mapper”输出的数据会保存在内存一个AppendOnlyMap中。如果数据较多，则会将AppendOnlyMap变换为一个priority queue，按key排序后保存到外部文件中。这样一来，一次map操作的所有数据会保存在一个内存里的AppendOnlyMap加若干外部的文件。当“reducer”请求数据的时候，这些数据分片会被组织成一个最小堆，每次读取一个key最小的记录，从而实现了排序的功能。“Reducer“拿到各个数据分片后，采用TimSort来对所有数据排序，而不是mapreduce中的合并排序。</p><blockquote><p>补充材料：<br><a href="https://0x0fff.com/spark-architecture-shuffle/" target="_blank" rel="noopener">Spark Architecture: Shuffle</a><br><a href="http://dataknocker.github.io/2014/07/23/spark-appendonlymap/" target="_blank" rel="noopener">spark的外排:AppendOnlyMap与ExternalAppendOnlyMap</a></p></blockquote><h2><span id="block-manager">Block Manager</span></h2><p>Block Manager在spark中作为一层存储抽象层存在。RDD的iterator方法里有读取缓存的partition的入口getOrCompute，其中block的id定义为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val key = RDDBlockId(rdd.id, partition.index)</span><br><span class="line"></span><br><span class="line">case class RDDBlockId(rddId: Int, splitIndex: Int) extends BlockId &#123;</span><br><span class="line">  override def name: String = &quot;rdd_&quot; + rddId + &quot;_&quot; + splitIndex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从实现上看每个RDD的partition都有一个唯一的key，用于blockmanager存储的键值。一个partition应该与一个block一一对应的。Block的存储完全由block manager来管理。</p><p><a href="https://issues.apache.org/jira/browse/SPARK-6235" target="_blank" rel="noopener">关于block size不能超过2g限制的issue tracker</a></p><p>不错的参考资料<br><a href="http://jerryshao.me/architecture/2013/10/08/spark-storage-module-analysis/" target="_blank" rel="noopener">Spark源码分析之-Storage模块</a><br><a href="http://cholerae.com/2015/03/06/Spark%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/" target="_blank" rel="noopener">Spark缓存机制分析</a><br><a href="http://www.cnblogs.com/hseagle/p/3673138.html" target="_blank" rel="noopener">Apache Spark源码走读之6 – 存储子系统分析</a></p><h2><span id="dag">DAG</span></h2><p><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-dagscheduler.html" target="_blank" rel="noopener">DAGScheduler</a><br><a href="https://issues.apache.org/jira/browse/SPARK-9850" target="_blank" rel="noopener">Adaptive execution in Spark</a></p><h2><span id="dataframe">DataFrame</span></h2><p>可以反复学习的blog<br><a href="http://dataknocker.github.io" target="_blank" rel="noopener">http://dataknocker.github.io</a></p>]]></content>
    
    <summary type="html">
    
      My notes taken for learning spark.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="spark" scheme="liqul.github.io/blog/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Two-phase Commit</title>
    <link href="liqul.github.io/blog/two-phase-commit/"/>
    <id>liqul.github.io/blog/two-phase-commit/</id>
    <published>2017-06-09T06:32:00.000Z</published>
    <updated>2018-03-06T10:52:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>I recently came across a good description of two-phase commit from actordb’s document. I decide to borrow it as a note. The following is copied from <a href="http://www.actordb.com/docs-howitworks.html#h_323" target="_blank" rel="noopener">actordb’s document</a>:</p><p>3.2.3 Multi-actor transactions<br>Multi-actor transactions need to be ACID compliant. They are executed by a transaction manager. The manager is itself an actor. It has name and a transaction number that is incremented for every transaction.</p><p>Sequence of events from the transaction manager point of view:</p><ol><li>Start transaction by writing the number and state (uncommitted) to transaction table of transaction manager actor.</li><li>Go through all actors in the transaction and execute their belonging SQL to check if it can execute, but do not commit it. If actor successfully executes SQL it will lock itself (queue all reads and writes).</li><li>All actors returned success. Change state in transaction table for transaction to committed.</li><li>Inform all actors that they should commit.</li></ol><p>Sequence of events from an actors point of view:</p><ol><li>Actor receives SQL with a transaction ID, transaction number and which node transaction manager belongs to.</li><li>Store the actual SQL statement with transaction info to a transaction table (not execute it).</li><li>Once it is stored, the SQL will be executed but not committed. If there was no error, return success.</li><li>Actor waits for confirm or abort from transaction manager. It will also periodically check back with the transaction manager in case the node where it was running from went down and confirmation message is lost.</li><li>Once it has a confirmation or abort message it executes it and unlocks itself.</li></ol><p>Problem scenarios:</p><ol><li>Node where transaction manager lives goes down before committing transaction: Actors will be checking back to see what state a transaction is in. If transaction manager actor resumes on another node and sees an uncommitted transaction, it will mark it as aborted. Actors will in turn abort the transaction as well.</li><li>Node where transaction manager lives goes down after committing transaction to local state, but before informing actors that transaction was confirmed. Actors checking back will detect a confirmed transaction and commit it.</li><li>Node where one or more actors live goes down after confirming that they can execute transaction. The actual SQL statements are stored in their databases. The next time actors start up, they will notice that transaction. Check back with the transaction manager and either commit or abort it.</li></ol>]]></content>
    
    <summary type="html">
    
      I recently came across a good description of two-phase commit from actordb&#39;s document. I decide to borrow it as a note. The following is copied from actordb&#39;s document
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="transaction" scheme="liqul.github.io/blog/tags/transaction/"/>
    
  </entry>
  
  <entry>
    <title>摄影笔记</title>
    <link href="liqul.github.io/blog/notes-on-photography/"/>
    <id>liqul.github.io/blog/notes-on-photography/</id>
    <published>2017-05-04T01:58:00.000Z</published>
    <updated>2018-03-06T10:52:25.000Z</updated>
    
    <content type="html"><![CDATA[<h3><span id="焦段选择的一些感想">焦段选择的一些感想：</span></h3><p><strong>广角（&lt;35mm)</strong></p><ul><li>场面干净：由于广角会摄入较广的场景，所以必须保证其中不要有不希望被包括的主体</li><li>中心突出：没有中心的广角构图是非常失败的，这比其它焦段更加要求中心突出</li><li>线条整齐对称：没有细密整齐的线条，广角会非常乏味，这些线条可以是建筑、地面的纹路、天际线等等</li><li>身临其境：广角照片给人的印象是身历其境，所以角度一般不能太平庸，要么居高临下，要么自底向上</li><li>多元素：元素可以多一点但最好是能够相互呼应的</li></ul><p><strong>中焦(35mm~70mm)</strong></p><ul><li>现实感：由于其呈现的效果更加接近人眼所以能给人一种“旁观”的感觉，更加适合拍摄纪实的题材，其带来的震撼感要高于其它焦段</li><li>距离变化：在这个焦段范围中，一点点变化都能对拍摄距离产生较大影响</li></ul><p><strong>长焦(&gt;70mm)</strong></p><ul><li>微距：把较远处的主体拍到眼前是长焦的主要作用之一</li><li>压缩场景：由于长焦会把多个主体间的距离弱化，很像中国画的感觉，体现的是一种平面的美感</li><li>少元素：元素尽量少一点，画面简单一点，弱水三千只取一瓢</li><li>虚化加成：由于长焦带来的虚化加成，在稍微大一点的光圈下能达到所谓“空气切割”的感觉</li></ul><h3><span id="场景-vs-焦段">场景 vs. 焦段</span></h3><ul><li>苏州园林：原本是为了人眼优化的布景，更加适合中焦和长焦</li><li>城市建筑：广角更能呈现出震撼的感觉，加上建筑的线条在广角中更具有表现力；一些广场上的建筑由于没有遮挡，在没人的时候也可以用长一点的焦段</li><li>人像：跟场景有关，在场景杂乱的地方就老实用中长焦大光圈虚化；在户外视场景而定广角可以突出人与宏达场景的相映，中焦更接近生活，长焦可以捕捉一些在无干扰情况下的活动，总而言之还是跟背景有关系</li></ul><h3><span id="一些原则">一些原则</span></h3><ul><li>色彩尽量少一点，不要给人一种杂乱的感觉</li><li>一定要有主体，不然没有着眼点</li><li>场景中的元素除非必要尽量不要包括进来</li></ul>]]></content>
    
    <summary type="html">
    
      My naive thoughts on photography...
    
    </summary>
    
      <category term="Photography" scheme="liqul.github.io/blog/categories/Photography/"/>
    
    
      <category term="photography" scheme="liqul.github.io/blog/tags/photography/"/>
    
  </entry>
  
  <entry>
    <title>Setup SBT Development Environment</title>
    <link href="liqul.github.io/blog/setup-sbt-development-environment/"/>
    <id>liqul.github.io/blog/setup-sbt-development-environment/</id>
    <published>2017-04-10T02:52:39.000Z</published>
    <updated>2018-03-06T10:52:05.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>Setup JDK following Oracle guidance.</p></li><li><p>Setup SBT</p></li></ol><p>No matter which platform you are on. I recommend downloading the <a href="https://dl.bintray.com/sbt/native-packages/sbt/0.13.15/sbt-0.13.15.zip" target="_blank" rel="noopener">zip</a> archive directly.</p><p>Put the following into <code>~/.sbt/repositories</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[repositories]</span><br><span class="line"><span class="comment">#local</span></span><br><span class="line">public: http://maven.aliyun.com/nexus/content/groups/public/</span><br><span class="line">typesafe:http://dl.bintray.com/typesafe/ivy-releases/ , [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[<span class="built_in">type</span>]s/[artifact](-[classifier]).[ext], bootOnly</span><br><span class="line">ivy-sbt-plugin:http://dl.bintray.com/sbt/sbt-plugin-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[<span class="built_in">type</span>]s/[artifact](-[classifier]).[ext]</span><br><span class="line">sonatype-oss-releases</span><br><span class="line"></span><br><span class="line">sonatype-oss-snapshots</span><br></pre></td></tr></table></figure><p>Run <code>sbt</code> and <code>sbt console</code>. If you see all downloads from aliyun, you’ve setup it successfully. Test creating a new SBT project in intellij to see if everything ok.</p>]]></content>
    
    <summary type="html">
    
      Deploying SBT is not easy...
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="sbt" scheme="liqul.github.io/blog/tags/sbt/"/>
    
      <category term="scala" scheme="liqul.github.io/blog/tags/scala/"/>
    
  </entry>
  
  <entry>
    <title>Notes on The Raft Consensus Algorithm</title>
    <link href="liqul.github.io/blog/the-raft-consensus-algorithm/"/>
    <id>liqul.github.io/blog/the-raft-consensus-algorithm/</id>
    <published>2017-03-31T06:25:39.000Z</published>
    <updated>2018-03-15T02:34:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>What’s consensus?</p><blockquote><p>It allows a collection of machines to work as a coherent group that can survive the failures of some of its members.</p></blockquote><p>It means not only a group of machines reach a final decision for a request, but also the state machine is replicated across these machines, so that some failures do not affect the functioning. Raft is a consensus algorithm seeking to be correct, implementable, and understandable. </p><p>The <a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="noopener">thesis</a> is very well written. It is much more comprehensive compared to the NSDI paper. Implementing Raft based on the thesis shouldn’t be too difficult (of course, also not trivial). The author also built a <a href="https://raft.github.io/" target="_blank" rel="noopener">website</a> putting all kinds of helping things there. I read the paper and decide to take some notes here.</p><p><img src="/blog/assets/state.png" width="800"></p><p>There are two key parts sitting in the core of the algorithm:</p><p><strong>Leader election</strong></p><p>The election is triggered by a timeout. If a server failed to detect heartbeats from the current leader, it start a new <em>term</em> of election. During the term, it broadcast requests to collect votes from other servers. If equal or more than majority of servers reply with a vote, the server becomes the leader of this term. The “term” here is a monotonically increasing logic time. From the perspective of a server receiving the vote request, it decides whether to give the vote based on a few considerations. First of all, if the sender even falls behind the receiver in terms of log index, the receiver should not vote for it. Also, if the receiver can still hear the heartbeats from current leader, it should not vote too. In this case, the requester might be a <em>disruptive server</em>. In other cases, the receiver should vote for the sender. </p><p><img src="/blog/assets/leader election.png" width="800"></p><p><strong>Log replication</strong></p><p>Once a server becomes the leader, it’s mission is simply replicate it’s log to every other follower. The replication means make the log of a follower <em>exactly</em> the same as the leader. For each pair of leader and follower, the leader first identify the highest index where they reach an agreement. Starting from there, the leader overwrite its log to the follower. The leader handles all requests from clients. Once it receives a new request, it first put the request into its own log. Then, it replicate the request to all followers. If equal or more than majority followers (including the leader itself) answer the replication request with success, the leader apply the request into its state machine (this is called commit). The leader put the new log index into its heartbeats, so followers know if the request has been committed, after which each follower commit the request too.</p><p><img src="/blog/assets/log replication.png" width="800"></p><p>More formal introduction of the core Raft could be found in Fig. 3.1 in the thesis paper. There are also a few extensions to make the algorithm practical to be used in production systems, such as the group management. I also found Fig. 10.1 a very good reference of architecture. </p><p>There are quite a lot of implementations of Raft, which could be found <a href="https://raft.github.io/" target="_blank" rel="noopener">here</a>. I also find a project named Copycat, with code <a href="https://github.com/atomix/copycat" target="_blank" rel="noopener">here</a> and document <a href="http://atomix.io/copycat/" target="_blank" rel="noopener">here</a>. Copycat is a full featured implementation of Raft in java. Building your own application based on Copycat shouldn’t be too difficult. They provide an example of implementing a KV store based on Copycat in their source code <a href="https://github.com/atomix/copycat/tree/master/examples" target="_blank" rel="noopener">here</a>, which is used as the “<a href="http://atomix.io/copycat/docs/getting-started/" target="_blank" rel="noopener">Get Started</a>“ tutorial. Another very important reason, why I think Copycat a good reference, is that it emphases the abstraction of state machine, client, server, and operations. Therefore, going through it’s document enhanced my understanding of Raft. </p><p>If you don’t want to build your own Raft, may be Copycat is worthwhile a try, though I haven’t any real experience beyond a toy project.</p><p>The annotated thesis could be found <a href="/blog/assets/raft-thesis.pdf">here</a>.</p><p><strong>A go-through case for understanding</strong></p><p>A typical request handling process is as follows:</p><ol><li>The client sends a request to the cluster;</li><li>The leader handles the request by putting it to a WAL;</li><li>The leader sends the request to all followers;</li><li>Each follower puts the received request to its WAL, and responds to the leader;</li><li>Once the leader has heard a majority number of responses from its followers, the leader commit the request by applying the WAL to its state machine;</li><li>The leader inform the client that the request has been handled properly, and then, put the index of the request into its heartbeat to let all followers know the status of each request;</li><li>Once the follower knows that the request has been committed by the leader, the follower commit the request too by applying it to its own state machine. </li></ol><p>There are a few key points to understand in the process above:</p><p>1.Does the client always know if its request has been handled properly?</p><p>No. If the leader commits the request and then crashes, the client will not know if the request has been actually successfully handled. In some cases, the client will resend the request which may lead to duplicated data. It leaves for the client to avoid such kind of duplication. </p><p>2.How about the leader crashes before inform its followers that the request has been committed?</p><p>If the leader crashes, a follower will be elected to be the next leader. The follower must have the latest state according to the mechanism of Raft. Therefore, the next leader definitely has the WAL for the request, and the request has definitely been replicated across a majority number of hosts. Therefore, it is safe to replicate its state to all followers. </p><p>3.Key feature of a consensus algorithm (or strong consistency)?</p><p>Under normal situations, if there’s a state change, the key step changing the state should be always handled by a certain node. The state changing should be replicated to a majority number of followers before informing the requester a success. Each read request goes to that certain node as well. Once there’s node failures or networking partitions, the service stop working until returning to the normal situation again.</p>]]></content>
    
    <summary type="html">
    
      It allows a collection of machines to work as a coherent group that can survive the failures of some of its members
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="Raft" scheme="liqul.github.io/blog/tags/Raft/"/>
    
      <category term="Consensus" scheme="liqul.github.io/blog/tags/Consensus/"/>
    
      <category term="Copycat" scheme="liqul.github.io/blog/tags/Copycat/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Using &quot;Select ... For Update&quot; for Uniqueness in Mysql</title>
    <link href="liqul.github.io/blog/using-select-for-update-for-uniqueness-in-mysql/"/>
    <id>liqul.github.io/blog/using-select-for-update-for-uniqueness-in-mysql/</id>
    <published>2017-03-31T06:25:39.000Z</published>
    <updated>2018-03-06T10:51:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>I encountered a deadlock recently. Similar questions have been asked on StackOverflow, e.g., <a href="http://stackoverflow.com/questions/21851119/deadlock-using-select-for-update-in-mysql" target="_blank" rel="noopener">this</a> and <a href="http://stackoverflow.com/questions/43251975/mysql-select-for-update-blocks-1st-insert-if-using-non-primary-key-in-where-clau" target="_blank" rel="noopener">this</a>. But the answers didn’t really explain why this happens. </p><p>The situation is quite easy to reproduce @ Mysql 5.7.17 (also tested on other versions in 5.5 or 5.6):</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`test`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">bigint</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="string">`val`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>),</span><br><span class="line">  <span class="keyword">KEY</span> <span class="string">`search`</span> (<span class="string">`val`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">4</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span> <span class="keyword">set</span> val=<span class="string">'pre-lock'</span>;</span><br></pre></td></tr></table></figure><p><strong>session1</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span> <span class="keyword">where</span> val=<span class="string">'pre-lock'</span> <span class="keyword">for</span> <span class="keyword">update</span>;</span><br></pre></td></tr></table></figure></p><p><strong>session2</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span> <span class="keyword">where</span> val=<span class="string">'pre-lock'</span> <span class="keyword">for</span> <span class="keyword">update</span>;</span><br></pre></td></tr></table></figure></p><p><strong>session1</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span> <span class="keyword">set</span> val=<span class="string">'/a/b/c'</span>;</span><br></pre></td></tr></table></figure></p><p><strong>session2</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR 1213 (40001): Deadlock found when trying to get <span class="keyword">lock</span>; try restarting transaction</span><br></pre></td></tr></table></figure></p><p>The result of show engine innodb status:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">LATEST DETECTED DEADLOCK</span><br><span class="line"><span class="comment">------------------------</span></span><br><span class="line">2017-04-06 23:54:03 0x7000057db000</span><br><span class="line">*** (1) TRANSACTION:</span><br><span class="line">TRANSACTION 1333, ACTIVE 18 sec starting index read</span><br><span class="line">mysql tables in <span class="keyword">use</span> <span class="number">1</span>, <span class="keyword">locked</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">LOCK</span> <span class="keyword">WAIT</span> <span class="number">2</span> <span class="keyword">lock</span> <span class="keyword">struct</span>(s), <span class="keyword">heap</span> <span class="keyword">size</span> <span class="number">1136</span>, <span class="number">1</span> <span class="keyword">row</span> <span class="keyword">lock</span>(s)</span><br><span class="line">MySQL <span class="keyword">thread</span> <span class="keyword">id</span> <span class="number">5</span>, OS <span class="keyword">thread</span> handle <span class="number">123145394155520</span>, <span class="keyword">query</span> <span class="keyword">id</span> <span class="number">62</span> localhost root Sending <span class="keyword">data</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span> <span class="keyword">where</span> val=<span class="string">'pre-lock'</span> <span class="keyword">for</span> <span class="keyword">update</span></span><br><span class="line">*** (<span class="number">1</span>) WAITING <span class="keyword">FOR</span> THIS <span class="keyword">LOCK</span> <span class="keyword">TO</span> BE GRANTED:</span><br><span class="line"><span class="built_in">RECORD</span> LOCKS <span class="keyword">space</span> <span class="keyword">id</span> <span class="number">24</span> page <span class="keyword">no</span> <span class="number">4</span> n bits <span class="number">72</span> <span class="keyword">index</span> <span class="keyword">search</span> <span class="keyword">of</span> <span class="keyword">table</span> <span class="string">`test_tnx`</span>.<span class="string">`test`</span> trx <span class="keyword">id</span> <span class="number">1333</span> lock_mode X waiting</span><br><span class="line"><span class="built_in">Record</span> <span class="keyword">lock</span>, <span class="keyword">heap</span> <span class="keyword">no</span> <span class="number">2</span> <span class="keyword">PHYSICAL</span> <span class="built_in">RECORD</span>: n_fields <span class="number">2</span>; compact format; info bits 0</span><br><span class="line"> 0: len 8; hex 7072652d6c6f636b; asc pre-<span class="keyword">lock</span>;;</span><br><span class="line"> 1: len 8; hex 8000000000000001; asc         ;;</span><br><span class="line"></span><br><span class="line">*** (2) TRANSACTION:</span><br><span class="line">TRANSACTION 1332, ACTIVE 29 sec inserting</span><br><span class="line">mysql tables in <span class="keyword">use</span> <span class="number">1</span>, <span class="keyword">locked</span> <span class="number">1</span></span><br><span class="line"><span class="number">4</span> <span class="keyword">lock</span> <span class="keyword">struct</span>(s), <span class="keyword">heap</span> <span class="keyword">size</span> <span class="number">1136</span>, <span class="number">4</span> <span class="keyword">row</span> <span class="keyword">lock</span>(s), <span class="keyword">undo</span> <span class="keyword">log</span> entries <span class="number">1</span></span><br><span class="line">MySQL <span class="keyword">thread</span> <span class="keyword">id</span> <span class="number">62</span>, OS <span class="keyword">thread</span> handle <span class="number">123145394434048</span>, <span class="keyword">query</span> <span class="keyword">id</span> <span class="number">63</span> localhost root <span class="keyword">update</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span> <span class="keyword">set</span> val=<span class="string">'/a/b/c'</span></span><br><span class="line">*** (<span class="number">2</span>) HOLDS THE <span class="keyword">LOCK</span>(S):</span><br><span class="line"><span class="built_in">RECORD</span> LOCKS <span class="keyword">space</span> <span class="keyword">id</span> <span class="number">24</span> page <span class="keyword">no</span> <span class="number">4</span> n bits <span class="number">72</span> <span class="keyword">index</span> <span class="keyword">search</span> <span class="keyword">of</span> <span class="keyword">table</span> <span class="string">`test_tnx`</span>.<span class="string">`test`</span> trx <span class="keyword">id</span> <span class="number">1332</span> lock_mode X</span><br><span class="line"><span class="built_in">Record</span> <span class="keyword">lock</span>, <span class="keyword">heap</span> <span class="keyword">no</span> <span class="number">1</span> <span class="keyword">PHYSICAL</span> <span class="built_in">RECORD</span>: n_fields <span class="number">1</span>; compact format; info bits 0</span><br><span class="line"> 0: len 8; hex 73757072656d756d; asc supremum;;</span><br><span class="line"></span><br><span class="line">Record <span class="keyword">lock</span>, <span class="keyword">heap</span> <span class="keyword">no</span> <span class="number">2</span> <span class="keyword">PHYSICAL</span> <span class="built_in">RECORD</span>: n_fields <span class="number">2</span>; compact format; info bits 0</span><br><span class="line"> 0: len 8; hex 7072652d6c6f636b; asc pre-<span class="keyword">lock</span>;;</span><br><span class="line"> 1: len 8; hex 8000000000000001; asc         ;;</span><br><span class="line"></span><br><span class="line">*** (2) WAITING FOR THIS LOCK TO BE GRANTED:</span><br><span class="line">RECORD LOCKS space id 24 page no 4 n bits 72 index search of table `test_tnx`.`test` trx id 1332 lock_mode X locks gap before rec <span class="keyword">insert</span> intention waiting</span><br><span class="line"><span class="built_in">Record</span> <span class="keyword">lock</span>, <span class="keyword">heap</span> <span class="keyword">no</span> <span class="number">2</span> <span class="keyword">PHYSICAL</span> <span class="built_in">RECORD</span>: n_fields <span class="number">2</span>; compact format; info bits 0</span><br><span class="line"> 0: len 8; hex 7072652d6c6f636b; asc pre-<span class="keyword">lock</span>;;</span><br><span class="line"> 1: len 8; hex 8000000000000001; asc         ;;</span><br><span class="line"></span><br><span class="line">*** WE ROLL BACK TRANSACTION (1)</span><br></pre></td></tr></table></figure><p>My objective is to use <code>select ... for update</code> as a uniqueness check for a following sequence of insertions. I expected that Tnx 2 would wait until Tnx 1 released the lock, and then continue its own business. However, Tnx 2 is rolled back due to deadlock. The innodb status looks quite confusing. Tnx 1 is holding and waiting for the same lock. </p><p>After some research, though I still cannot figure out the root cause, my perception is that the insertion in Tnx 1 acquires a gap lock which is somehow overlapping with the gap lock by the <code>select ... for update</code>. And therefore, this create a deadlock where Tnx 1 waits for Tnx 2 and Tnx 2 waits for Tnx 1. </p><p>During my research, I found that the right <a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-next-key-locking.html" target="_blank" rel="noopener">use case</a> for <code>select ... for update</code> is as follows:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> [<span class="keyword">table</span>] <span class="keyword">where</span> [condition] <span class="keyword">for</span> <span class="keyword">update</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> [<span class="keyword">table</span>] <span class="keyword">values</span> [belongs <span class="keyword">to</span> condition];</span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> [<span class="keyword">table</span>] <span class="keyword">where</span> [belongs <span class="keyword">to</span> condition];</span><br></pre></td></tr></table></figure><p>The rows being mutated should be explicitly locked by the <code>select ... for update</code>. Also, the condition should be as clear as possible. For example, put only an unique key in the condition. This is to make the gap lock with a simple and clear range, in order not to cause deadlocks.</p><p>Generally, using <code>select ... for update</code> is non-trivial since the underlying locking mechanism seems quite complicated. For my scenario, I got two workarounds:</p><ol><li>Disable gap locks by setting the <a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-isolation-levels.html" target="_blank" rel="noopener">isolation level</a> to <code>READ COMMITTED</code>.</li><li>Apply <code>select ... for update</code> on a row from another table, which avoid possible lock overlap.</li></ol>]]></content>
    
    <summary type="html">
    
      I encountered a deadlock recently. Similar questions have been asked on StackOverflow, e.g., this and this. But the answers didn&#39;t really explain why this happens.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="lock" scheme="liqul.github.io/blog/tags/lock/"/>
    
      <category term="Mysql" scheme="liqul.github.io/blog/tags/Mysql/"/>
    
      <category term="Deadlock" scheme="liqul.github.io/blog/tags/Deadlock/"/>
    
      <category term="Uniqueness" scheme="liqul.github.io/blog/tags/Uniqueness/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Implementing A Lock System</title>
    <link href="liqul.github.io/blog/implementing-a-lock-system/"/>
    <id>liqul.github.io/blog/implementing-a-lock-system/</id>
    <published>2017-03-31T06:25:39.000Z</published>
    <updated>2018-03-06T10:51:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I got the job of building a locking utility. I started by learning from existing locking services, i.e., zookeeper and mysql, since they already have been widely accepted. Zookeeper has this <a href="https://zookeeper.apache.org/doc/r3.1.2/recipes.html" target="_blank" rel="noopener">page</a> introducing how to build locks. I also find this <a href="https://blogs.oracle.com/mysqlinnodb/entry/introduction_to_transaction_locks_in" target="_blank" rel="noopener">page</a> details how lock implemented for mysql innodb table rows. After reading these materials, as well as some others. I found a locking utility could be simple, and also could be quite complicated. So I decided to make a note here to summarize my understandings. </p><p>A lock is essentially a flag claiming the right of a deterministic resource. In mysql, the locking of a range is mapped to a set of data pages, which is thus deterministic as well. The simplest form of lock is a single write lock of one resource, e.g., a file. One could implement this based on zookeeper by creating a node with a certain name. For example, if I want to lock the file “/home/liqul/file1”, I’d put a node with the same name of the file into zookeeper. If the creation returns with success, I got the lock for the file. In contrast, if I failed in creating the node, it means the lock of the file is already held by someone else. If I cannot obtain the lock, I may backoff for a while and retry afterwards. The one holding the lock should release it explicitly. Otherwise, the file can never be used by others any more. </p><p>I note that this is much simpler compared with the lock recipe in this <a href="https://zookeeper.apache.org/doc/r3.1.2/recipes.html" target="_blank" rel="noopener">page</a>. The zookeeper lock recipe brings two useful features: blocking and session-aware. Blocking means that if I failed to obtain the lock now, I will wait until the lock being released by all peers queuing before me. Session-aware means that if I crash, my application for the lock also disappears. The latter is useful to avoid forgetting to release the lock as discussed in the previous paragraph. To implement these two features, one should setup a client-server architecture. Also, to achieve blocking lock, one need a queue for each resource. Sometimes, we however prefer non-blocking locks, which is not discussed in the zookeeper recipe. </p><p>Read-write lock is an extension of the write-only lock. Zookeeper also has a dedicated recipe for it <a href="https://zookeeper.apache.org/doc/r3.1.2/recipes.html" target="_blank" rel="noopener">here</a>. Implementing a read-write lock is non-trivial. Let’s explain this problem with a concrete example. Suppose <em>A</em> wants to acquire a read lock of a file <em>F</em>, while <em>B</em> wants a write lock to <em>F</em> too. A naive implementation may be as follows:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1 *A* checks if there&apos;s any write locks to *F*</span><br><span class="line">2 *B* checks if there&apos;s any read locks to *F*</span><br><span class="line">3 *A* finds no write locks to *F*</span><br><span class="line">4 *B* finds no read locks to *F*</span><br><span class="line">5 *A* put a read lock of *F*</span><br><span class="line">6 *B* put a write lock of *F*</span><br></pre></td></tr></table></figure><p>The “check and then lock” pattern simply doesn’t work correctly. In zookeeper, they rely on sequential nodes and watcher to work around this problem, where each peer always first inserts a node and then check if itself obtains the lock. If not, the peer put a watcher onto the current holder of the lock. Another workaround is to first obtain a global write pre-lock before any operation. With a pre-lock the above procedure becomes:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1 *A* acquires the pre-lock</span><br><span class="line">2 *A* obtains the pre-lock</span><br><span class="line">3 *A* checks if there&apos;s any write locks to *F*</span><br><span class="line">4 *B* acquires the pre-lock</span><br><span class="line">5 *B* failed to obtain the pre-lock</span><br><span class="line">6 *A* finds no write locks to *F*</span><br><span class="line">7 *A* put a read lock of *F*</span><br><span class="line">8 *A* release the pre-lock</span><br></pre></td></tr></table></figure><p>One obvious drawback of the second workaround is that even two locks have no conflict, they still need to perform one after another. To avoid this problem, the lock utility need to maintain a conflict matrix for each pair of locks being processed or pending (should be marked separately). If a pending lock is not conflicting with any lock processed, it obtains the pre-lock right away. Otherwise, it is put into a queue waiting for all conflicting locks being clear. A short version is to only consider read and write locks separately. </p><p>Another extension is to achieve atomicity for a set of locks. For this purpose, one need to treat the whole set as “one” lock. And the handling of it is quite similar with what we have discussed above. For instance, if you want to implement with zookeeper, you may need to insert all the locks and then set watchers for a set of conflicting locks. Only after all conflicting locks being clear, you obtain the locks. Without zookeeper, one can also use the pre-lock solution as described above. A conflict matrix is necessary to avoid deadlock if you want to process the sets of locks in parallel.</p><p>In general, zookeeper is quite ready for customizing into your own locking service. However, it does has its own drawbacks. For example, it is not clear how to implement non-blocking read-write locks. If you have metadata for your locks, and you want to search in the metadata, zookeeper may be painful. At this time, using a mysql database may be a good choice, though you need to avoid some pitfalls discussed in this article.</p>]]></content>
    
    <summary type="html">
    
      Recently, I got the job of building a locking utility.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="lock" scheme="liqul.github.io/blog/tags/lock/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Multi-versioned Storage</title>
    <link href="liqul.github.io/blog/non-blocking-read/"/>
    <id>liqul.github.io/blog/non-blocking-read/</id>
    <published>2017-03-31T06:25:39.000Z</published>
    <updated>2018-03-06T10:51:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>I recently read the <a href="https://research.google.com/archive/spanner.html" target="_blank" rel="noopener">Spanner</a> paper. I realized that I cannot understand the idea of TrueTime and Non-blocking read well. Therefore, I did some research by googling the concept of non-blocking read, and came across this mysql <a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-consistent-read.html" target="_blank" rel="noopener">document</a>. After reading it, I realized that my understanding of multi-versioned storage is incorrect. So I decide to put some notes here.</p><p>The key points of multi-versioned storage are:  </p><ol><li>version -&gt; the creation wall clock time of the object (or a vector time)</li><li>timestamp -&gt; the query time of the object</li><li>the association between the metadata and content should never be changed</li></ol><p>Each object is associated with a set of metadata. The metadata contains a timestamp field indicating the version of this object. For a concrete example, let’s define a storage model as follows:</p><p><img src="/blog/assets/objstore1.png" width="500"></p><p>Each metadata contains three fields</p><table><thead><tr><th>Field</th><th style="text-align:center">Description</th></tr></thead><tbody><tr><td>name</td><td style="text-align:center">name of the object. objects with the same name are deem to be the same object</td></tr><tr><td>ctime</td><td style="text-align:center">creation time</td></tr><tr><td>deleted</td><td style="text-align:center">1 means a tombstone</td></tr><tr><td>extra</td><td style="text-align:center">some extra metadata for this object</td></tr></tbody></table><p>Let’s use typical operations to clarify the usage of this data model. </p><p><strong>Put</strong><br>Put is adding a new versioned object into the storage. In the figure above, the first “obj1” is inserted at 2017-04-01 11:30:12. Inserting another object with the same name is simply adding a new entry to the table pointing to the new content. When an object is requested from client, only the one with the latest timestamp is returned. Therefore, from 2017-04-01 11:30:12 to 2017-04-02 11:31:25, the first obj1 is visible. After 2017-04-02 11:31:25, the client see only the second obj1. With this data model, there is no need to block writes during reading this object, since each operation is based solely on its timestamp. </p><p><strong>Delete</strong><br>Delete is simply by putting a tombstone for a certain object. Like the third obj1 in the example. No content is presented for this entry. The objects with a tombstone as the latest entry will be filtered out if requested from clients.</p><p><strong>Update</strong><br>In this context, update is different from putting new contents into the object, but altering the object’s metadata (e.g., the extra field in the table). Updating the fields beyond the unique key is less a problem. If we need to update even the name of the object, we need to perform two steps: (1) delete the original object; (2) put a new object with the new metadata. One need to keep these two steps in an atomic transaction.</p><p><strong>Search</strong><br>Search is usually based on metadata to find a set of objects. The difference with multi-versioned storage is that we only return an object with the latest timestamp. This could be achieved with a select clause like </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT t.* FROM (SELECT * FROM table WHERE xxx AND ctime &lt; NOW() ORDER BY ctime DESC) t GROUP BY t.name</span><br></pre></td></tr></table></figure><p>We then filter out tombstones reside in the result set.</p><p><strong>Get</strong><br>Get is first searching for the latest object before the operation time. Then, the pointer of content is handed over to the client. The client should read the content as soon as possible. Otherwise, the content may be deleted due to recycling.  </p><p><strong>Compact</strong><br>Compact refers to merge a set of contents into a big one. This is useful for example for HDFS to relief the name node’s burden of storing a large number of small files. The implementation of compaction is a bit tricky. One first merge the target set of contents into a big file. Then, insert a new entry for each  related object within an atomic transaction. For clarification, let’s suppose we need to compact obj2 and obj3 in our example. We first create a new content with both contents from the original obj2 and obj3. Then, we add new entries for obj2 and obj3, respectively. The tricky part is that the ctime for these two entries are just 1 second larger than the original two. </p><p><img src="/blog/assets/objstore2.png" width="600"></p><p>This may sounds weired at first. But think about the situation that a new entry for obj2 is put after we started but not finished compaction. In this case, the new content could be covered by the compaction if the ctime is larger than the new entry. We add 1 to the ctime. So, the new entry will either be later, or conflict with the compaction, leading to a failure. Upon such failure, the client simply retry to submit the new content. This should not be a real problem since compaction is a rare operation. </p><p>One may wonder why not simply updating the pointers in the original entries for obj2 and obj3. This actually breaks the third key points we mentioned at the beginning. It is important not changing the association. For example, if we want to get an object during compaction, reading may fail since the old contents may be deleted. Also, stale contents may be produced. More importantly, we may need very complicated transaction controls. </p><p><strong>Recycle</strong><br>Recycle is used to delete all deleted objects. The deleted objects could be find by searching for tombstones in the table. If a tombstone is detected, all entries before that can be deleted physically, including the tombstone itself. Delete a single content is straightforward. However, if a content is merged into a big file, we can carry out a similar process like compaction to delete the content physically. Old-versioned entries can also be recycled. Both recycling for deleted and old-versioned entries follows a certain policy. We can delete an entry once it has been out dated for a few days. This duration shouldn’t be too soon. Otherwise, we may recycle content being or to be read. </p><p>One can see that, with this multi-versioned storage model, all operations are much simpler without dependency to a locking system. We even do not rely on transaction, if compaction is not necessary. Let’s return to the three key parts at the beginning of this note. With a timestamp field, we already get the sense of version. As discussed above, the operation timestamp is critical as we need it to determine which object should be put into the result set. If data is stored across multiple machines, we need to synchronize their clock precisely. TrueTime is a API expose the uncertainty of time among different machines, and thus is critical for such large scale storage implementation. Finally, the association should not be broken, otherwise, we need complicated mechanisms to fix the issues it incurs.</p>]]></content>
    
    <summary type="html">
    
      I recently read the Spanner paper. I realized that I cannot understand the idea of TrueTime and Non-blocking read well. Therefore, I did some research by googling the concept of non-blocking read, and came across this mysql document. After reading it, I realized that my understanding of multi-versioned storage is incorrect. So I decide to put some notes here.
    
    </summary>
    
      <category term="Tech" scheme="liqul.github.io/blog/categories/Tech/"/>
    
    
      <category term="big data" scheme="liqul.github.io/blog/tags/big-data/"/>
    
      <category term="storage" scheme="liqul.github.io/blog/tags/storage/"/>
    
      <category term="MVCC" scheme="liqul.github.io/blog/tags/MVCC/"/>
    
      <category term="non-blocking" scheme="liqul.github.io/blog/tags/non-blocking/"/>
    
  </entry>
  
</feed>
