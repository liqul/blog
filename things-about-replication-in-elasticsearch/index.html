<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Things about replication in Elasticsearch · Liqun's Homepage</title><meta name="description" content="Things about replication in Elasticsearch - Liqun Li"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/blog/favicon2.jpeg"><link rel="stylesheet" href="/blog/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="liqul.github.io/blog/atom.xml" title="Liqun's Homepage"></head><body><div class="wrap"><header><a href="/blog/" class="logo-link"><img src="/blog/favicon2.jpeg" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/blog/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/blog/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/blog/about/" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="https://scholar.google.com/citations?user=icgetesAAAAJ&amp;hl=en" target="_blank" class="nav-list-link">GOOGLE SCHOLAR</a></li><li class="nav-list-item"><a href="/blog/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Things about replication in Elasticsearch</h1><div class="post-info">Nov 10, 2017</div><div class="post-content"><h3><span id="updated-on-2017-11-10">Updated on 2017-11-10</span></h3><p>Elasticsearch is evolving fast in the past few years. There have been quite some discussions on data loss during node crashes, which can be found <a href="https://github.com/elastic/elasticsearch/issues/10933" target="_blank" rel="noopener">here</a> and <a href="https://github.com/elastic/elasticsearch/issues/14252" target="_blank" rel="noopener">here</a>. Most of the issues have been fixed as described <a href="https://www.elastic.co/guide/en/elasticsearch/resiliency/current/index.html" target="_blank" rel="noopener">here</a>. However, since Elasticsearch carried out a major upgrade to version 5+, some serious issues still remain for low versions, e.g., the stale replica problem described <a href="https://github.com/elastic/elasticsearch/issues/14671" target="_blank" rel="noopener">here</a>. </p>
<p>I already discussed in the original article about the two node issue. I recently carried out an experiment with 3 nodes which is actually the recommended minimum size for an Elasticsearch cluster. With 3 nodes, the quorum size is 2 and the minimum master nodes is 2 (discovery.zen.minimum_master_nodes). Therefore, there is always an overlap where some nodes have the latest state. Let me explain this with an example. The nodes are A, B, and C. We go through the following test steps:</p>
<ol>
<li>Create a new index with 2 replicas, i.e., 3 copies in total;</li>
<li>Shut down A;</li>
<li>Index 1 document on index B and C successfully;</li>
<li>Shut down B and C;</li>
<li>Turn on A;</li>
</ol>
<p>What about the state for the index? The replica on A will not be allocated as the primary shard since there is only one alive node less than the minimum master nodes 2. Now, we turn on B. As B has the latest state, B propagate the latest state to A. </p>
<p>Most of open sourced distributed system rely on a mature consensus approach such as Raft or Zookeeper. However, Elasticsearch decided to invent its own. This actually leads to most of those serious issues. </p>
<p>========</p>
<p>Replication is a key feature for Elasticsearch from two aspects: (1) When some machines fail, the alive ones can still serve requests; (2) Replication boosts the read speed since read can retrieve data from multiple nodes simultaneously. </p>
<p>Elasticsearch follows a primary-secondary fashion for replication. When a write request (e.g., create, index, update, delete) arrives, it is first forward to the primary replica. The primary replica finishes the request, and then, concurrently forward the requests to all alive secondary replicas. There are a few details about this process. </p>
<p>First, there is a concept of write consistency level in Elasticsearch, with available options one, quorum, and all. This concept is a bit different from what we normally find for other systems such as Kafka. It barely forces the primary replica to check if there are enough alive replicas available receiving a write request. For instance, suppose we have a cluster of 3 nodes with replica number 2, i.e., each shard is with one primary replica and 2 secondary replicas. If we set the write consistency level to quorum, when the primary replica receives a index request, it checks if there are at least 2 replicas available (i.e., &gt;=replicas/2+1). If the check passes, the primary replica will start the action of index, after which it forward the request to all replicas. One should note that the consistency level is only for the check. This means there is a chance when a replica fails after the check, and right before the action.</p>
<p>Second, we need to answer the question: when shall the primary replica respond to the client? It turns out that there are two modes, sync and async as discussed <a href="https://discuss.elastic.co/t/es-default-async-or-sync/19654" target="_blank" rel="noopener">here</a>. The sync mode means the primary replica only responds the client if “all” secondary replicas have finished the request. Note that the “all” here, which has nothing to do with the selected write consistency level. Under the async mode, the primary replica responds to the client right after itself finishing the request. The request is then forward to other replicas in an async way. This accelerate the response timing for the client, which however may lead to overload for the Elasticsearch cluster. Mean while, since the request propagates eventually to the replicas, there will be no read-write consistency guarantee even inside the same session if the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.3/search-request-preference.html" target="_blank" rel="noopener">read preference</a> is not set to primary. </p>
<p>In normal case, there is only one primary replica for each shard. Once the primary replica fails, a secondary replica is elected to serve as primary. In some special situations, the primary replica may lose connection to other replicas, leading to multiple primary replicas in the system, which is called the split brain problem as discussed <a href="https://qbox.io/blog/split-brain-problem-elasticsearch" target="_blank" rel="noopener">here</a>. The cue to this problem is by setting the discovery.zen.minimum_master_nodes to &gt;= half of nodes + 1. For example, if you have 3 nodes, the minimum_master_nodes should be set to 2. By setting the minimum_master_nodes we ensure that the service is only available if there are more than minimum_master_nodes living nodes within one master domain. In other words, there can not be two masters in the system. </p>
<p>Finally, I want to discuss the problem of stale shard which I read recently from <a href="https://www.elastic.co/blog/tracking-in-sync-shard-copies" target="_blank" rel="noopener">here</a>. Let’s start by use a concrete example. Say if we have two nodes and each shard has two replicas (one primary and the other secondary). We first index 10 documents with the secondary shard node turned off. Then, we turn off the primary shard node, and bring up the secondary shard node. The question here is whether the secondary shard will be promoted to primary? If it is, how about the 10 documents we indexed before? According to this <a href="https://www.elastic.co/blog/tracking-in-sync-shard-copies" target="_blank" rel="noopener">blog</a>, with Elasticsearch v5+, the primary shard will not only do the index, but also inform the master about in-sync shards. In this case, the answer to our questions are no. Because the secondary shard is not in in-sync state after being brought up. I didn’t experiment it myself about this since I don’t have a Elasticsearch v5+ environment. I only tested this with Elasticsearch 2.4.5 where I found different answer. After secondary shard node was brought up, the secondary shard was indeed promoted to primary, and the 10 documents were lost if I then brought up the previous primary shard node. This is indeed a problem if such special situation happens, which however should be quite rare in practice especially if you have more than 2 nodes, and with quorum write consistency level.</p>
</div></article></div></main><footer><div class="paginator"><a href="/blog/ssd/" class="prev">上一篇</a><a href="/blog/ming_lessons/" class="next">下一篇</a></div><div class="copyright"><p>© 2016 - 2018 <a href="liqul.github.io/blog">Liqun Li</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>